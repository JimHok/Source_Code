{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from module.periocular_cnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3b296e0a064278ba7dad85c08438a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris_data, iris_label = create_dataset('Iris-Dataset/CASIA-Iris-Thousand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data, iris_label, img_label = combine_LR(iris_data, iris_label, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pair, y_pair, label_pair = make_pairs(iris_data, iris_label.astype(int), img_label, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pair, X_test_pair, y_train_pair, y_test_pair, label_train_pair, label_test_pair = train_test_split(X_pair, y_pair, label_pair, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test, label_train, label_test = train_test_split(iris_data, iris_label, img_label, test_size=0.2, stratify=iris_label)\n",
    "# X_train_pair, y_train_pair, label_train_pair = make_pairs(X_train, y_train.astype(int), label_train, 5)\n",
    "# X_test_pair, y_test_pair, label_test_pair = make_pairs(X_test, y_test.astype(int), label_test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet101, ResNet50, VGG16, VGG19, InceptionV3, InceptionResNetV2\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(64,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the default graph\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# create a new session\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/cpu:0'):\n",
    "#     X_train_a = tf.convert_to_tensor(vgg16_preprocess_input(X_train_pair[:, 0]), np.float32)\n",
    "#     X_train_b = tf.convert_to_tensor(vgg16_preprocess_input(X_train_pair[:, 1]), np.float32)\n",
    "#     y_train_final = tf.convert_to_tensor(y_train_pair.reshape(-1,1), np.float32)\n",
    "\n",
    "#     X_test_a = tf.convert_to_tensor(vgg16_preprocess_input(X_test_pair[:, 0]), np.float32)\n",
    "#     X_test_b = tf.convert_to_tensor(vgg16_preprocess_input(X_test_pair[:, 1]), np.float32)\n",
    "#     y_test_final = tf.convert_to_tensor(y_test_pair.reshape(-1,1), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a = vgg16_preprocess_input(X_train_pair[:, 0])\n",
    "X_train_b = vgg16_preprocess_input(X_train_pair[:, 1])\n",
    "y_train_final = y_train_pair.reshape(-1)\n",
    "\n",
    "X_test_a = vgg16_preprocess_input(X_test_pair[:, 0])\n",
    "X_test_b = vgg16_preprocess_input(X_test_pair[:, 1])\n",
    "y_test_final = y_test_pair.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1033s 413ms/step\n",
      "2500/2500 [==============================] - 1031s 412ms/step\n",
      "125/125 [==============================] - 50s 398ms/step\n",
      "125/125 [==============================] - 51s 407ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    features_train_a = model_vgg.predict(X_train_a)\n",
    "    features_train_b = model_vgg.predict(X_train_b)\n",
    "    features_test_a = model_vgg.predict(X_test_a)\n",
    "    features_test_b = model_vgg.predict(X_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the features to a file\n",
    "# np.savez('temp_data/features_80_4.npz', \n",
    "#          features_train_a=features_train_a, \n",
    "#          features_train_b=features_train_b,\n",
    "#          label_train=y_train_final, \n",
    "#          img_label_train=label_train_pair,\n",
    "         \n",
    "#          features_test_a=features_test_a, \n",
    "#          features_test_b=features_test_b,\n",
    "#          label_test=y_test_final,\n",
    "#          img_label_test=label_test_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features from the file\n",
    "with np.load('temp_data/features_80_4.npz') as data:\n",
    "    features_train_a = data['features_train_a']\n",
    "    features_train_b = data['features_train_b']\n",
    "    y_train_final = data['label_train']\n",
    "    img_label_train = data['img_label_train']\n",
    "    \n",
    "    features_test_a = data['features_test_a']\n",
    "    features_test_b = data['features_test_b']\n",
    "    y_test_final = data['label_test']\n",
    "    img_label_test = data['img_label_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create all scores for score fusion with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.Iris_recognition import *\n",
    "from module.Periocular_recognition import *\n",
    "from module.score_fusion import *\n",
    "from module.iris_scores import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris_norm_L = np.load('temp_data/iris_norm_L_all.npy')\n",
    "# iris_norm_R = np.load('temp_data/iris_norm_R_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features from the file\n",
    "with np.load('temp_data/iris_norm_all.npz') as data:\n",
    "    iris_norm_L = data['iris_norm_L']\n",
    "    iris_norm_R = data['iris_norm_R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_file = \"checkpoint/fusion_scores_checkpoint.pkl\"\n",
    "# with open(checkpoint_file, \"rb\") as f:\n",
    "#     fusion_scores = pickle.load(f)\n",
    "    \n",
    "# len(fusion_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93adbdfa21af4d1495088db32cbc43f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 4000/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fusion_scores_test = get_fusion_scores_mp(iris_norm_L, iris_norm_R, img_label_test, 'fusion_scores_test_cp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(fusion_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a981ee3dcdfc49dc970c4cd5cd5e028f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 26%|##5       | 20700/80000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fusion_scores_train = get_fusion_scores_mp(iris_norm_L, iris_norm_R, img_label_train, 'fusion_scores_train_cp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the features to a file\n",
    "# np.savez('temp_data/fusion_scores_enhanced_80_4.npz',\n",
    "#          fusion_scores_train=fusion_scores_train, \n",
    "#          fusion_scores_test=fusion_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features from the file\n",
    "with np.load('temp_data/fusion_scores_enhanced_80_4.npz') as data:\n",
    "    fusion_scores_train = data['fusion_scores_train']\n",
    "    fusion_scores_test = data['fusion_scores_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification by machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"sklearnex\")\n",
    "logger.setLevel(logging.WARNING)  # Set the logger's logging level to WARNING or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = feature_preprocessing(features_train_a, features_test_a, features_train_b, features_test_b, fusion_scores_train, fusion_scores_test, use_fusion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('temp_data/features_final_.npz',\n",
    "#          X_train_final=X_train_scaled,\n",
    "#          y_train_final=y_train_final,\n",
    "#          X_test_final=X_test_scaled,\n",
    "#          y_test_final=y_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('temp_data/features_final_.npz') as data:\n",
    "    X_train_final = data['X_train_final']\n",
    "    y_train_final = data['y_train_final']\n",
    "    X_test_final = data['X_test_final']\n",
    "    y_test_final = data['y_test_final']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for best hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   8.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   7.7s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   7.2s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   7.1s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   7.4s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  26.8s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  26.8s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  27.6s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  25.6s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  28.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   5.6s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   5.9s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   6.2s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   6.2s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   7.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   7.6s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   7.7s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   7.3s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   7.3s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   7.3s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  26.6s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  27.7s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  29.4s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  29.6s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  30.9s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   8.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   7.8s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   8.2s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   7.9s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   7.7s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  20.6s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  21.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  21.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  20.9s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  20.2s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  27.7s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  28.8s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  26.6s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  25.2s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  29.4s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   6.2s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.5s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.3s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.7s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  11.6s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.6s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  24.3s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  24.6s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  28.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  26.6s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  23.6s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   7.8s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   7.4s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   7.6s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   8.1s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   8.1s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   8.1s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   7.9s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   8.2s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   7.9s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  27.2s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  26.5s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  28.4s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  25.9s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  28.5s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   5.7s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   5.7s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   5.9s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   5.7s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   7.4s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   7.6s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   7.6s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   7.5s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   7.4s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  26.6s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  26.8s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  28.4s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  27.7s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  29.6s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   7.7s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   8.5s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   8.4s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   8.5s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   5.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  28.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  29.5s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  29.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  27.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  28.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  27.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  27.2s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  25.6s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  25.5s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  30.5s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.6s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  18.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  18.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  19.4s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  18.3s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  18.2s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  26.2s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  24.4s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  25.6s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  26.1s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  24.7s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   6.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   6.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   8.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   7.4s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   7.5s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   7.5s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   7.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   7.2s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  27.9s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  26.3s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  29.4s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  25.7s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  29.3s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   5.8s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.3s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.4s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   8.1s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   7.7s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   7.6s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   7.5s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   7.8s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  26.9s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  27.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  28.7s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  27.9s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  31.1s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   8.3s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   8.5s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   8.6s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   7.4s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  39.2s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  41.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  40.2s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  41.3s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  39.8s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  27.8s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  28.5s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  27.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  26.7s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  31.4s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.5s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.7s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.5s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=  27.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.1s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.1s\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "param = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid_search = get_best_param(X_train_scaled, y_train_final, svm.SVC(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "Best Score:  0.8922500000000001\n",
      "Best Estimator:  SVC(C=10, gamma=0.01, kernel='poly')\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters and score\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "print(\"Best Estimator: \", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.0001, verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an SVM classifier with a Gaussian kernel\n",
    "clf = svm.SVC(kernel='rbf', C=10, gamma=0.0001, verbose=2)\n",
    "\n",
    "# train the classifier\n",
    "clf.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(clf, open('model/svm_VGG16_fusion_enha_84.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open('model/svm_VGG16_fusion_enha_84.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an SVM classifier with a Gaussian kernel\n",
    "clf = svm.SVC(kernel='rbf', C=10, gamma=0.0001, verbose=2)\n",
    "\n",
    "X = np.concatenate((X_train_scaled, X_test_scaled), axis=0)\n",
    "y = np.concatenate((y_train_final, y_test_final), axis=0)\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro']\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.97244048 0.97244048 0.97261905 0.97119048 0.96428571]\n",
      "Precision: [0.97244241 0.97244064 0.97264648 0.97119432 0.9644039 ]\n",
      "Recall: [0.97244048 0.97244048 0.97261905 0.97119048 0.96428571]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', scores['test_accuracy'])\n",
    "print('Precision:', scores['test_precision_macro'])\n",
    "print('Recall:', scores['test_recall_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      8461\n",
      "           1       0.97      0.97      0.97      8339\n",
      "\n",
      "    accuracy                           0.97     16800\n",
      "   macro avg       0.97      0.97      0.97     16800\n",
      "weighted avg       0.97      0.97      0.97     16800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.48      0.60      2000\n",
      "           1       0.63      0.88      0.73      2000\n",
      "\n",
      "    accuracy                           0.68      4000\n",
      "   macro avg       0.71      0.68      0.66      4000\n",
      "weighted avg       0.71      0.68      0.66      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = get_best_param(X_train_scaled, y_train_final, RandomForestClassifier(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9399375000000001\n",
      "Best Estimator:  RandomForestClassifier(min_samples_split=5, n_estimators=200)\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters and score\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "print(\"Best Estimator: \", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=5, n_estimators=200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Random Forest classifier with 100 trees\n",
    "rfc = RandomForestClassifier(min_samples_split=5, n_estimators=200)\n",
    "\n",
    "# Train the classifier on your data\n",
    "rfc.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(rfc, open('model/rfc_VGG16_fusion_enha_84.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = pickle.load(open('model/rfc_VGG16_fusion_enha_84.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test data\n",
    "y_predict = rfc.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      8461\n",
      "           1       0.99      0.96      0.98      8339\n",
      "\n",
      "    accuracy                           0.98     16800\n",
      "   macro avg       0.98      0.98      0.98     16800\n",
      "weighted avg       0.98      0.98      0.98     16800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'solver': ['liblinear', 'saga']\n",
    "# }\n",
    "# grid_search = get_best_param(X_train_scaled, y_train_final, LogisticRegression(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9376874999999998\n",
      "Best Estimator:  LogisticRegression(C=0.1, penalty='l1', solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# # print the best parameters and score\n",
    "# print(\"Best Score: \", grid_search.best_score_)\n",
    "# print(\"Best Estimator: \", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Logistic Regression classifier\n",
    "lr = LogisticRegression(C=0.1, penalty='l1', solver='liblinear')\n",
    "\n",
    "# Train the classifier on your data\n",
    "lr.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(lr, open('model/lr_VGG16_fusion_enha_84.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pickle.load(open('model/lr_VGG16_fusion_enha.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test data\n",
    "y_predict = lr.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      8461\n",
      "           1       0.96      0.96      0.96      8339\n",
      "\n",
      "    accuracy                           0.96     16800\n",
      "   macro avg       0.96      0.96      0.96     16800\n",
      "weighted avg       0.96      0.96      0.96     16800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Flatten, Lambda, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(64,128,3))\n",
    "\n",
    "input_dim = X_train_pair.shape[2:]\n",
    "\n",
    "img_a = Input(shape=input_dim)\n",
    "img_b = Input(shape=input_dim)\n",
    "\n",
    "feat_vecs_a = model_vgg(img_a)\n",
    "feat_vecs_b = model_vgg(img_b)\n",
    "\n",
    "flatten_a = Flatten()(feat_vecs_a)\n",
    "flatten_b = Flatten()(feat_vecs_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance)([flatten_a, flatten_b])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model_vgg = Model(inputs=[img_a, img_b], outputs=outputs)\n",
    "\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model_vgg.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 73s 146ms/step - loss: 0.6932 - accuracy: 0.4972\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 0.6932 - accuracy: 0.4972\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 74s 149ms/step - loss: 0.6932 - accuracy: 0.4909\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 0.6932 - accuracy: 0.4951\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 0.6932 - accuracy: 0.4936\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4959\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4921\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4970\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4984\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4936\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4989\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4985\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4984\n",
      "Epoch 15/100\n",
      "326/500 [==================>...........] - ETA: 26s - loss: 0.6932 - accuracy: 0.4975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28180/1909033650.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mX_train_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_b\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_final\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# reducing batch size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \"\"\"\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \"\"\"\n\u001b[0;32m   1156\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model_vgg.fit(\n",
    "\t[X_train_a, X_train_b], y_train_final,\n",
    "\tbatch_size=32, # reducing batch size\n",
    "\tepochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model(inputShape, embeddingDim=48):\n",
    "\t# specify the inputs for the feature extractor network\n",
    "\tinputs = Input(inputShape)\n",
    "\t# define the first set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
    "\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\tx = Dropout(0.3)(x)\n",
    "\t# second set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "\tx = MaxPooling2D(pool_size=2)(x)\n",
    "\tx = Dropout(0.3)(x)\n",
    " \t# prepare the final outputs\n",
    "\tpooledOutput = GlobalAveragePooling2D()(x)\n",
    "\toutputs = Dense(embeddingDim)(pooledOutput)\n",
    "\t# build the model\n",
    "\tmodel = Model(inputs, outputs)\n",
    "\t# return the model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgA = Input(shape=X_train_pair.shape[2:])\n",
    "imgB = Input(shape=X_train_pair.shape[2:])\n",
    "featureExtractor = build_siamese_model(X_train_pair.shape[2:])\n",
    "featsA = featureExtractor(imgA)\n",
    "featsB = featureExtractor(imgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    X_train_a = tf.convert_to_tensor(X_train_pair[:, 0], np.float32)\n",
    "    X_train_b = tf.convert_to_tensor(X_train_pair[:, 1], np.float32)\n",
    "    y_train_final = tf.convert_to_tensor(y_train_pair.reshape(-1,1), np.float32)\n",
    "    \n",
    "    X_test_a = tf.convert_to_tensor(X_test_pair[:, 0], np.float32)\n",
    "    X_test_b = tf.convert_to_tensor(X_test_pair[:, 1], np.float32)\n",
    "    y_test_final = tf.convert_to_tensor(y_test_pair.reshape(-1,1), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 14s 26ms/step - loss: 0.7163 - accuracy: 0.4863 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6934 - accuracy: 0.4931 - val_loss: 0.6950 - val_accuracy: 0.4970\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6934 - accuracy: 0.4963 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4945 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4934 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6933 - val_accuracy: 0.4988\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6934 - val_accuracy: 0.4978\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4972 - val_loss: 0.6933 - val_accuracy: 0.4983\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4939 - val_loss: 0.6937 - val_accuracy: 0.4460\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6934 - accuracy: 0.5021 - val_loss: 0.6933 - val_accuracy: 0.4985\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6937 - val_accuracy: 0.4995\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4945 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4956 - val_loss: 0.6939 - val_accuracy: 0.3473\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4939 - val_loss: 0.6932 - val_accuracy: 0.4602\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.4950\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4905 - val_loss: 0.6946 - val_accuracy: 0.2918\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6941 - val_accuracy: 0.3918\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6933 - val_accuracy: 0.4692\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6943 - val_accuracy: 0.2965\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6937 - val_accuracy: 0.3670\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6936 - val_accuracy: 0.4565\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6933 - val_accuracy: 0.4248\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6934 - val_accuracy: 0.4692\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6935 - val_accuracy: 0.3620\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6933 - val_accuracy: 0.3915\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.4437\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.4297\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6932 - val_accuracy: 0.4902\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4954 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6935 - val_accuracy: 0.3957\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6937 - val_accuracy: 0.3285\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6935 - val_accuracy: 0.4588\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6935 - val_accuracy: 0.4958\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6933 - val_accuracy: 0.4365\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6937 - val_accuracy: 0.3803\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6940 - val_accuracy: 0.3100\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6937 - val_accuracy: 0.3877\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6935 - val_accuracy: 0.4720\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4954 - val_loss: 0.6944 - val_accuracy: 0.3860\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6947 - val_accuracy: 0.3828\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6936 - val_accuracy: 0.4515\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6949 - val_accuracy: 0.4182\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6936 - val_accuracy: 0.4510\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6934 - val_accuracy: 0.4850\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6931 - accuracy: 0.5003 - val_loss: 0.6938 - val_accuracy: 0.4245\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6969 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6946 - val_accuracy: 0.3970\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6981 - val_accuracy: 0.2915\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6931 - accuracy: 0.4996 - val_loss: 0.6985 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6977 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6956 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6962 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4936 - val_loss: 0.6963 - val_accuracy: 0.3638\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6971 - val_accuracy: 0.3640\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6964 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6978 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6968 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "439/500 [=========================>....] - ETA: 1s - loss: 0.6932 - accuracy: 0.4968"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28180/948365459.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_b\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \tepochs=100)\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \"\"\"\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \"\"\"\n\u001b[0;32m   1156\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(\n",
    "\t[X_train_a, X_train_b], y_train_final,\n",
    "\tvalidation_data=([X_test_a, X_test_b], y_test_final),\n",
    "\tbatch_size=32, \n",
    "\tepochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test_a, X_test_b, y_test_final):\n",
    "    # evaluate the model on the test data\n",
    "    print(\"[INFO] evaluating model...\")\n",
    "    loss, accuracy = model.evaluate([X_test_a, X_test_b], y_test_final, verbose=0)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "    # make predictions on the test data\n",
    "    print(\"[INFO] making predictions...\")\n",
    "    y_pred = model.predict([X_test_a, X_test_b])\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # print the classification report\n",
    "    print(\"[INFO] classification report...\")\n",
    "    print(classification_report(y_test_final, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating model...\n",
      "Test Loss: 3.5463\n",
      "Test Accuracy: 50.00%\n",
      "[INFO] making predictions...\n",
      "125/125 [==============================] - 1s 9ms/step\n",
      "[INFO] classification report...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      2000\n",
      "         1.0       0.50      1.00      0.67      2000\n",
      "\n",
      "    accuracy                           0.50      4000\n",
      "   macro avg       0.25      0.50      0.33      4000\n",
      "weighted avg       0.25      0.50      0.33      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_model(model, X_test_a, X_test_b, y_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from module.periocular_cnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf966c5f9574f55903ca9e961d982e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris_data, iris_label = create_dataset('Iris-Dataset/CASIA-Iris-Thousand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data, iris_label, img_label = combine_LR(iris_data, iris_label, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, label_train, label_test = train_test_split(iris_data, iris_label, img_label, test_size=0.2, stratify=iris_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(images, labels, img_label, set=1):\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "    imageLabels = []\n",
    "\n",
    "    numClasses = len(np.unique(labels))\n",
    "    idx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
    "    # loop over all images\n",
    "    for idxA in range(len(images)):\n",
    "        # grab the current image and label belonging to the current\n",
    "        # iteration\n",
    "        currentImage = images[idxA]\n",
    "        label = labels[idxA]\n",
    "        for _ in range(set):\n",
    "            posIdx = idx[label]\n",
    "            while True:\n",
    "                # randomly pick an image that belongs to the *same* class\n",
    "                idxB = np.random.choice(posIdx)\n",
    "                posIdx = np.delete(posIdx, np.where(posIdx == idxB))\n",
    "                if idxB != idxA:\n",
    "                    break\n",
    "            posImage = images[idxB]\n",
    "            # prepare a positive pair and update the images and labels\n",
    "            # lists, respectively\n",
    "            pairImages.append([currentImage, posImage])\n",
    "            pairLabels.append([1])\n",
    "            imageLabels.append([str(labels[idxA]).zfill(\n",
    "                3) + img_label[idxA], str(labels[idxB]).zfill(3) + img_label[idxB]])\n",
    "\n",
    "            # grab the indices for each of the class labels *not* equal to\n",
    "            # the current label and randomly pick an image corresponding\n",
    "            # to a label *not* equal to the current label\n",
    "            negIdx = np.where(labels != label)[0]\n",
    "            while True:\n",
    "                idxC = np.random.choice(negIdx)\n",
    "                negIdx = np.delete(negIdx, np.where(negIdx == idxC))\n",
    "                if idxC != idxA:\n",
    "                    break\n",
    "            negImage = images[idxC]\n",
    "            # prepare a negative pair of images and update our lists\n",
    "            pairImages.append([currentImage, negImage])\n",
    "            pairLabels.append([0])\n",
    "            imageLabels.append([str(labels[idxA]).zfill(\n",
    "                3) + img_label[idxA], str(labels[idxC]).zfill(3) + img_label[idxC]])\n",
    "\n",
    "    # return a 2-tuple of our image pairs and labels\n",
    "    return (np.array(pairImages), np.array(pairLabels), np.array(imageLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pair, y_train_pair, label_train_pair = make_pairs(X_train, y_train.astype(int), label_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['70003', '70005'],\n",
       "       ['70003', '01002'],\n",
       "       ['70003', '70009'],\n",
       "       ['70003', '27005'],\n",
       "       ['70003', '70004'],\n",
       "       ['70003', '99403'],\n",
       "       ['70003', '70001'],\n",
       "       ['70003', '95403'],\n",
       "       ['53109', '53103'],\n",
       "       ['53109', '80603'],\n",
       "       ['53109', '53107'],\n",
       "       ['53109', '31100'],\n",
       "       ['53109', '53107'],\n",
       "       ['53109', '72104'],\n",
       "       ['53109', '53107'],\n",
       "       ['53109', '03106'],\n",
       "       ['71600', '71608'],\n",
       "       ['71600', '19304'],\n",
       "       ['71600', '71608'],\n",
       "       ['71600', '45900'],\n",
       "       ['71600', '71603'],\n",
       "       ['71600', '73604'],\n",
       "       ['71600', '71608'],\n",
       "       ['71600', '09500'],\n",
       "       ['26407', '26401'],\n",
       "       ['26407', '72201'],\n",
       "       ['26407', '26405'],\n",
       "       ['26407', '67902'],\n",
       "       ['26407', '26409'],\n",
       "       ['26407', '24005'],\n",
       "       ['26407', '26406'],\n",
       "       ['26407', '00401'],\n",
       "       ['41708', '41709'],\n",
       "       ['41708', '36609'],\n",
       "       ['41708', '41701'],\n",
       "       ['41708', '27602'],\n",
       "       ['41708', '41701'],\n",
       "       ['41708', '99207'],\n",
       "       ['41708', '41707'],\n",
       "       ['41708', '59300']], dtype='<U5')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train_pair[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pair, y_test_pair, label_test_pair = make_pairs(X_test, y_test.astype(int), label_test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet101, ResNet50, VGG16, VGG19, InceptionV3, InceptionResNetV2\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(64,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the default graph\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# create a new session\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/cpu:0'):\n",
    "#     X_train_a = tf.convert_to_tensor(vgg16_preprocess_input(X_train_pair[:, 0]), np.float32)\n",
    "#     X_train_b = tf.convert_to_tensor(vgg16_preprocess_input(X_train_pair[:, 1]), np.float32)\n",
    "#     y_train_final = tf.convert_to_tensor(y_train_pair.reshape(-1,1), np.float32)\n",
    "\n",
    "#     X_test_a = tf.convert_to_tensor(vgg16_preprocess_input(X_test_pair[:, 0]), np.float32)\n",
    "#     X_test_b = tf.convert_to_tensor(vgg16_preprocess_input(X_test_pair[:, 1]), np.float32)\n",
    "#     y_test_final = tf.convert_to_tensor(y_test_pair.reshape(-1,1), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a = vgg16_preprocess_input(X_train_pair[:, 0])\n",
    "X_train_b = vgg16_preprocess_input(X_train_pair[:, 1])\n",
    "y_train_final = y_train_pair.reshape(-1)\n",
    "\n",
    "X_test_a = vgg16_preprocess_input(X_test_pair[:, 0])\n",
    "X_test_b = vgg16_preprocess_input(X_test_pair[:, 1])\n",
    "y_test_final = y_test_pair.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 201s 400ms/step\n",
      "500/500 [==============================] - 195s 390ms/step\n",
      "125/125 [==============================] - 49s 394ms/step\n",
      "125/125 [==============================] - 50s 400ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    features_train_a = model_vgg.predict(X_train_a)\n",
    "    features_train_b = model_vgg.predict(X_train_b)\n",
    "    features_test_a = model_vgg.predict(X_test_a)\n",
    "    features_test_b = model_vgg.predict(X_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the features to a file\n",
    "# np.savez('temp_data/features.npz', \n",
    "#          features_train_a=features_train_a, \n",
    "#          features_train_b=features_train_b,\n",
    "#          label_train=y_train_final, \n",
    "#          img_label_train=label_train_pair,\n",
    "         \n",
    "#          features_test_a=features_test_a, \n",
    "#          features_test_b=features_test_b,\n",
    "#          label_test=y_test_final,\n",
    "#          img_label_test=label_test_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features from the file\n",
    "with np.load('temp_data/features.npz') as data:\n",
    "    features_train_a = data['features_train_a']\n",
    "    features_train_b = data['features_train_b']\n",
    "    y_train_final = data['label_train']\n",
    "    img_label_train = data['img_label_train']\n",
    "    \n",
    "    features_test_a = data['features_test_a']\n",
    "    features_test_b = data['features_test_b']\n",
    "    y_test_final = data['label_test']\n",
    "    img_label_test = data['img_label_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create all scores for score fusion with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.Iris_recognition import *\n",
    "from module.Periocular_recognition import *\n",
    "from module.score_fusion import *\n",
    "from module.iris_scores import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris_norm_L = np.load('temp_data/iris_norm_L_all.npy')\n",
    "# iris_norm_R = np.load('temp_data/iris_norm_R_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features from the file\n",
    "with np.load('temp_data/iris_norm_seg_all.npz') as data:\n",
    "    iris_norm_L = data['iris_norm_L']\n",
    "    iris_norm_R = data['iris_norm_R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(img_label_train[1][1][:-2]), int(img_label_train[1][1][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee28367f8044fc6b25c17a31a6eca25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fusion_scores_test = get_fusion_scores_multi_process(iris_norm_L, iris_norm_R, img_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.48042439, 0.4695479 ],\n",
       "        [0.6637621 , 0.64544693],\n",
       "        [0.24162694, 0.23444535],\n",
       "        [0.6106777 , 0.56270615]]),\n",
       " array([[0.47102681, 0.4792403 ],\n",
       "        [0.67007214, 0.65663108],\n",
       "        [0.234933  , 0.23932232],\n",
       "        [0.49411765, 0.61073425]]),\n",
       " array([[0.47221925, 0.4864391 ],\n",
       "        [0.65483775, 0.65654579],\n",
       "        [0.23570958, 0.24289384],\n",
       "        [0.51260077, 0.62048526]]),\n",
       " array([[0.47750997, 0.48117461],\n",
       "        [0.64857168, 0.64967694],\n",
       "        [0.23863372, 0.24034806],\n",
       "        [0.61069655, 0.64306159]]),\n",
       " array([[0.36684976, 0.33543101],\n",
       "        [0.5406613 , 0.50859663],\n",
       "        [0.18301652, 0.16722259],\n",
       "        [0.33455314, 0.3616    ]]),\n",
       " array([[0.47916308, 0.47110735],\n",
       "        [0.65417531, 0.6486172 ],\n",
       "        [0.2424945 , 0.24121714],\n",
       "        [0.60560753, 0.6377363 ]]),\n",
       " array([[0.47404397, 0.47169168],\n",
       "        [0.6444365 , 0.64716893],\n",
       "        [0.23711786, 0.24405764],\n",
       "        [0.55813233, 0.62938523]]),\n",
       " array([[0.47492788, 0.47947068],\n",
       "        [0.63695378, 0.63738308],\n",
       "        [0.24131202, 0.24005709],\n",
       "        [0.60850659, 0.63804432]]),\n",
       " array([[0.45893489, 0.41691843],\n",
       "        [0.63504994, 0.58900943],\n",
       "        [0.22916336, 0.20833078],\n",
       "        [0.60225768, 0.55920756]]),\n",
       " array([[0.47865412, 0.46784041],\n",
       "        [0.65917351, 0.63901979],\n",
       "        [0.24120441, 0.24066973],\n",
       "        [0.61041375, 0.60820399]]),\n",
       " array([[0.47044512, 0.43353643],\n",
       "        [0.638534  , 0.60247106],\n",
       "        [0.23538443, 0.21653654],\n",
       "        [0.6279344 , 0.58012452]]),\n",
       " array([[0.48129442, 0.474905  ],\n",
       "        [0.65265295, 0.64356595],\n",
       "        [0.24104945, 0.23736401],\n",
       "        [0.63661177, 0.63822544]]),\n",
       " array([[0.47803324, 0.47566562],\n",
       "        [0.65630428, 0.64909588],\n",
       "        [0.24153805, 0.23772356],\n",
       "        [0.59944744, 0.62478344]]),\n",
       " array([[0.48548686, 0.48248532],\n",
       "        [0.65153329, 0.65393928],\n",
       "        [0.24606279, 0.24106453],\n",
       "        [0.40436307, 0.6291467 ]]),\n",
       " array([[0.45674954, 0.47221151],\n",
       "        [0.62241012, 0.65145081],\n",
       "        [0.22815378, 0.23595139],\n",
       "        [0.6054746 , 0.59967727]]),\n",
       " array([[0.47955673, 0.4788933 ],\n",
       "        [0.64385659, 0.64910802],\n",
       "        [0.24074218, 0.2402437 ],\n",
       "        [0.63782691, 0.63185741]]),\n",
       " array([[0.33789176, 0.46905113],\n",
       "        [0.51995651, 0.6382941 ],\n",
       "        [0.16842632, 0.23432259],\n",
       "        [0.27403125, 0.59363841]]),\n",
       " array([[0.47661595, 0.47156342],\n",
       "        [0.66796226, 0.64193928],\n",
       "        [0.23921013, 0.23559964],\n",
       "        [0.59589464, 0.6379175 ]]),\n",
       " array([[0.45491298, 0.48475722],\n",
       "        [0.62688755, 0.6674158 ],\n",
       "        [0.22727627, 0.24204508],\n",
       "        [0.58914301, 0.58338521]]),\n",
       " array([[0.47630705, 0.47946733],\n",
       "        [0.6466277 , 0.65159962],\n",
       "        [0.24472204, 0.23953036],\n",
       "        [0.59710653, 0.6160479 ]]),\n",
       " array([[0.43594104, 0.43176126],\n",
       "        [0.60611756, 0.6019768 ],\n",
       "        [0.21780853, 0.21557571],\n",
       "        [0.56167655, 0.56867295]]),\n",
       " array([[0.45688324, 0.45266142],\n",
       "        [0.63436863, 0.6360436 ],\n",
       "        [0.22756787, 0.23069949],\n",
       "        [0.51484431, 0.57375656]]),\n",
       " array([[0.40754441, 0.46807749],\n",
       "        [0.58941799, 0.66422458],\n",
       "        [0.20360123, 0.23308764],\n",
       "        [0.56284736, 0.52691544]]),\n",
       " array([[0.48476117, 0.48193584],\n",
       "        [0.65961677, 0.65338782],\n",
       "        [0.24511635, 0.24233145],\n",
       "        [0.63401099, 0.61741197]]),\n",
       " array([[0.41807779, 0.43011187],\n",
       "        [0.59731607, 0.60802185],\n",
       "        [0.20828816, 0.21479454],\n",
       "        [0.3960151 , 0.54433799]]),\n",
       " array([[0.47071121, 0.46575373],\n",
       "        [0.64506518, 0.64734375],\n",
       "        [0.243051  , 0.23942849],\n",
       "        [0.61088502, 0.57874502]]),\n",
       " array([[0.47498647, 0.46430473],\n",
       "        [0.64197458, 0.63551507],\n",
       "        [0.23630617, 0.23192326],\n",
       "        [0.58287549, 0.6138185 ]]),\n",
       " array([[0.48235503, 0.48101082],\n",
       "        [0.65733952, 0.66915315],\n",
       "        [0.24066891, 0.24356757],\n",
       "        [0.59649123, 0.62230414]]),\n",
       " array([[0.44619811, 0.43156887],\n",
       "        [0.61577061, 0.60358727],\n",
       "        [0.22297143, 0.21567046],\n",
       "        [0.6074469 , 0.59414042]]),\n",
       " array([[0.47825029, 0.48240141],\n",
       "        [0.64455675, 0.64920526],\n",
       "        [0.24257208, 0.24093098],\n",
       "        [0.63090622, 0.64886262]]),\n",
       " array([[0.46130489, 0.42566608],\n",
       "        [0.65485409, 0.60325256],\n",
       "        [0.23834105, 0.21241294],\n",
       "        [0.48118539, 0.45284501]]),\n",
       " array([[0.46851863, 0.47985932],\n",
       "        [0.6648879 , 0.67501548],\n",
       "        [0.23371551, 0.24488138],\n",
       "        [0.47557799, 0.60046196]]),\n",
       " array([[0.40754441, 0.46807749],\n",
       "        [0.58941799, 0.66422458],\n",
       "        [0.20360804, 0.23375203],\n",
       "        [0.56284736, 0.52691544]]),\n",
       " array([[0.47126366, 0.48658843],\n",
       "        [0.64816269, 0.67257931],\n",
       "        [0.24191846, 0.24419012],\n",
       "        [0.62193333, 0.64516214]]),\n",
       " array([[0.4789903 , 0.48218373],\n",
       "        [0.67036256, 0.65689909],\n",
       "        [0.23906692, 0.24092629],\n",
       "        [0.46483666, 0.60733326]]),\n",
       " array([[0.48117715, 0.48166536],\n",
       "        [0.67935508, 0.66178173],\n",
       "        [0.24032406, 0.24056521],\n",
       "        [0.51417627, 0.57825169]]),\n",
       " array([[0.48018534, 0.44364281],\n",
       "        [0.65508302, 0.61604577],\n",
       "        [0.23972116, 0.2216582 ],\n",
       "        [0.61037604, 0.61069655]]),\n",
       " array([[0.4742999 , 0.46018786],\n",
       "        [0.63888815, 0.62604804],\n",
       "        [0.24107235, 0.23858855],\n",
       "        [0.63613964, 0.62406278]]),\n",
       " array([[0.45429144, 0.44053109],\n",
       "        [0.62601769, 0.62270671],\n",
       "        [0.22698121, 0.22005679],\n",
       "        [0.58756673, 0.60422005]]),\n",
       " array([[0.48755043, 0.47307112],\n",
       "        [0.66171462, 0.64975202],\n",
       "        [0.24328963, 0.24181289],\n",
       "        [0.61018743, 0.62345239]]),\n",
       " array([[0.44869775, 0.45400898],\n",
       "        [0.62642466, 0.62802047],\n",
       "        [0.22412007, 0.22656099],\n",
       "        [0.57184698, 0.58629925]]),\n",
       " array([[0.4668666 , 0.47105841],\n",
       "        [0.63778202, 0.64214816],\n",
       "        [0.24113602, 0.23835317],\n",
       "        [0.61486852, 0.62210022]]),\n",
       " array([[0.48870125, 0.40623866],\n",
       "        [0.64855923, 0.57777459],\n",
       "        [0.24465295, 0.20303387],\n",
       "        [0.64385231, 0.56476096]]),\n",
       " array([[0.47409306, 0.47330591],\n",
       "        [0.63946115, 0.64251755],\n",
       "        [0.24103041, 0.23650898],\n",
       "        [0.62912835, 0.62448788]]),\n",
       " array([[0.43971415, 0.47069006],\n",
       "        [0.61294168, 0.64208662],\n",
       "        [0.2194169 , 0.23867687],\n",
       "        [0.4389768 , 0.63699287]]),\n",
       " array([[0.46350033, 0.46696642],\n",
       "        [0.64344866, 0.64622525],\n",
       "        [0.24382425, 0.23318534],\n",
       "        [0.51531803, 0.51952521]]),\n",
       " array([[0.45786147, 0.43333605],\n",
       "        [0.63998282, 0.60338522],\n",
       "        [0.22864417, 0.21651769],\n",
       "        [0.57900142, 0.58723545]]),\n",
       " array([[0.47583552, 0.48159154],\n",
       "        [0.66007161, 0.64848534],\n",
       "        [0.23923984, 0.24097205],\n",
       "        [0.58641634, 0.64034098]]),\n",
       " array([[0.42827641, 0.36727628],\n",
       "        [0.59548856, 0.5359446 ],\n",
       "        [0.21391807, 0.18350548],\n",
       "        [0.59278804, 0.52095791]]),\n",
       " array([[0.4828544 , 0.48101109],\n",
       "        [0.65330125, 0.65169418],\n",
       "        [0.24231996, 0.24304213],\n",
       "        [0.64124305, 0.62605662]]),\n",
       " array([[0.46320836, 0.44643514],\n",
       "        [0.6486965 , 0.61887231],\n",
       "        [0.24518242, 0.22299958],\n",
       "        [0.5028802 , 0.59827796]]),\n",
       " array([[0.47084057, 0.47535329],\n",
       "        [0.65674468, 0.65647555],\n",
       "        [0.23767963, 0.2395056 ],\n",
       "        [0.49846767, 0.61507459]]),\n",
       " array([[0.46979299, 0.47469412],\n",
       "        [0.67866951, 0.66323924],\n",
       "        [0.23414767, 0.2378614 ],\n",
       "        [0.35686778, 0.57653224]]),\n",
       " array([[0.47290389, 0.46833092],\n",
       "        [0.65342163, 0.6526914 ],\n",
       "        [0.23629084, 0.23608741],\n",
       "        [0.60490463, 0.57528453]]),\n",
       " array([[0.44514388, 0.41533282],\n",
       "        [0.63551162, 0.59378206],\n",
       "        [0.22218017, 0.2073506 ],\n",
       "        [0.44965935, 0.45433962]]),\n",
       " array([[0.48003952, 0.47526644],\n",
       "        [0.64538776, 0.64379494],\n",
       "        [0.24455106, 0.24278251],\n",
       "        [0.63483049, 0.63165631]]),\n",
       " array([[0.45377965, 0.41286591],\n",
       "        [0.63324218, 0.58573529],\n",
       "        [0.2267258 , 0.20606834],\n",
       "        [0.60988556, 0.56007875]]),\n",
       " array([[0.47011191, 0.47260574],\n",
       "        [0.64040903, 0.64111837],\n",
       "        [0.24441691, 0.24189016],\n",
       "        [0.63577624, 0.6338652 ]]),\n",
       " array([[0.49480731, 0.35800971],\n",
       "        [0.64537961, 0.52739228],\n",
       "        [0.24785022, 0.17885992],\n",
       "        [0.47205228, 0.50739742]]),\n",
       " array([[0.46797476, 0.47750316],\n",
       "        [0.65814063, 0.64606231],\n",
       "        [0.23913735, 0.23859851],\n",
       "        [0.55328407, 0.62833874]]),\n",
       " array([[0.48748644, 0.41321689],\n",
       "        [0.6667044 , 0.58494547],\n",
       "        [0.24260965, 0.20646161],\n",
       "        [0.62686727, 0.55538626]]),\n",
       " array([[0.4652928 , 0.47572773],\n",
       "        [0.6360871 , 0.65171504],\n",
       "        [0.24564074, 0.2423576 ],\n",
       "        [0.6082229 , 0.5960294 ]]),\n",
       " array([[0.40949181, 0.46235907],\n",
       "        [0.59409509, 0.63070984],\n",
       "        [0.2063119 , 0.23098078],\n",
       "        [0.20659217, 0.57333928]]),\n",
       " array([[0.46092192, 0.46902797],\n",
       "        [0.65157686, 0.64910054],\n",
       "        [0.22994963, 0.23813839],\n",
       "        [0.39193455, 0.57100992]]),\n",
       " array([[0.48680634, 0.45703433],\n",
       "        [0.65897327, 0.62921013],\n",
       "        [0.24390311, 0.22835549],\n",
       "        [0.62498657, 0.62404429]]),\n",
       " array([[0.469416  , 0.47510721],\n",
       "        [0.64230259, 0.6418561 ],\n",
       "        [0.24862845, 0.23741097],\n",
       "        [0.63364646, 0.62487578]]),\n",
       " array([[0.47768852, 0.43013905],\n",
       "        [0.64993849, 0.61264056],\n",
       "        [0.23855243, 0.21828672],\n",
       "        [0.61464365, 0.57262336]]),\n",
       " array([[0.48448511, 0.47739178],\n",
       "        [0.65425791, 0.64725515],\n",
       "        [0.24260141, 0.23859588],\n",
       "        [0.64192783, 0.6426479 ]]),\n",
       " array([[0.48951427, 0.46597052],\n",
       "        [0.66849383, 0.64582603],\n",
       "        [0.2484215 , 0.23351637],\n",
       "        [0.59075458, 0.50867995]]),\n",
       " array([[0.47759611, 0.47001144],\n",
       "        [0.65602428, 0.65147096],\n",
       "        [0.24456014, 0.24466962],\n",
       "        [0.58929851, 0.62009487]]),\n",
       " array([[0.4610552 , 0.363103  ],\n",
       "        [0.65516322, 0.53131428],\n",
       "        [0.24325029, 0.18149341],\n",
       "        [0.44733211, 0.51645804]]),\n",
       " array([[0.4848637 , 0.48211624],\n",
       "        [0.67029189, 0.64782291],\n",
       "        [0.24210968, 0.24084773],\n",
       "        [0.56228238, 0.6371924 ]]),\n",
       " array([[0.47248949, 0.47926989],\n",
       "        [0.64783803, 0.64326721],\n",
       "        [0.24037637, 0.24265387],\n",
       "        [0.63941963, 0.60200961]]),\n",
       " array([[0.48450148, 0.48523878],\n",
       "        [0.65182745, 0.65677029],\n",
       "        [0.24205306, 0.24651684],\n",
       "        [0.64800634, 0.62865102]]),\n",
       " array([[0.45940793, 0.45833333],\n",
       "        [0.64093092, 0.63712173],\n",
       "        [0.23110245, 0.22904674],\n",
       "        [0.50619985, 0.59305872]]),\n",
       " array([[0.47333021, 0.4605598 ],\n",
       "        [0.65639258, 0.65493793],\n",
       "        [0.23754936, 0.22925424],\n",
       "        [0.54114429, 0.58163887]]),\n",
       " array([[0.4444605 , 0.4402234 ],\n",
       "        [0.62258148, 0.61091636],\n",
       "        [0.22197156, 0.21999617],\n",
       "        [0.59199472, 0.60693539]]),\n",
       " array([[0.4645962 , 0.47967674],\n",
       "        [0.64070028, 0.6504008 ],\n",
       "        [0.23379911, 0.23960552],\n",
       "        [0.61757995, 0.64007012]]),\n",
       " array([[0.47730928, 0.39484228],\n",
       "        [0.65410664, 0.56709639],\n",
       "        [0.23874456, 0.19730555],\n",
       "        [0.64421142, 0.56387529]]),\n",
       " array([[0.46693953, 0.47667323],\n",
       "        [0.64736165, 0.63443198],\n",
       "        [0.23312037, 0.24224082],\n",
       "        [0.60361097, 0.64217994]]),\n",
       " array([[0.47798664, 0.4446688 ],\n",
       "        [0.64981807, 0.62355729],\n",
       "        [0.23885854, 0.22219566],\n",
       "        [0.6206525 , 0.56703051]]),\n",
       " array([[0.48576379, 0.46711079],\n",
       "        [0.65361382, 0.63880605],\n",
       "        [0.24273994, 0.24536256],\n",
       "        [0.65023397, 0.62640679]]),\n",
       " array([[0.48291969, 0.45978917],\n",
       "        [0.67502061, 0.63588266],\n",
       "        [0.24243835, 0.22966546],\n",
       "        [0.57122925, 0.59359978]]),\n",
       " array([[0.47907152, 0.48411982],\n",
       "        [0.67117957, 0.65957198],\n",
       "        [0.24161576, 0.24314253],\n",
       "        [0.56883298, 0.60818507]]),\n",
       " array([[0.46759071, 0.45595961],\n",
       "        [0.63827253, 0.62936944],\n",
       "        [0.24553771, 0.22784804],\n",
       "        [0.62070823, 0.60524667]]),\n",
       " array([[0.48568691, 0.47440316],\n",
       "        [0.6515769 , 0.66306359],\n",
       "        [0.24368893, 0.2412838 ],\n",
       "        [0.63503066, 0.61197712]]),\n",
       " array([[0.46358411, 0.36987396],\n",
       "        [0.64402336, 0.54661726],\n",
       "        [0.23163356, 0.18477339],\n",
       "        [0.59371567, 0.49118878]]),\n",
       " array([[0.47969715, 0.47506484],\n",
       "        [0.65804997, 0.64911668],\n",
       "        [0.2395704 , 0.23781906],\n",
       "        [0.61400612, 0.64149542]]),\n",
       " array([[0.45657794, 0.45662664],\n",
       "        [0.65670511, 0.65318244],\n",
       "        [0.22807395, 0.22806168],\n",
       "        [0.54284657, 0.48224343]]),\n",
       " array([[0.45624914, 0.47488759],\n",
       "        [0.64106356, 0.67613073],\n",
       "        [0.22791722, 0.24310462],\n",
       "        [0.56056453, 0.58412953]]),\n",
       " array([[0.46477348, 0.45700879],\n",
       "        [0.64958611, 0.62916873],\n",
       "        [0.2322428 , 0.22832864],\n",
       "        [0.5818353 , 0.59383153]]),\n",
       " array([[0.48263652, 0.47928763],\n",
       "        [0.66170026, 0.6545112 ],\n",
       "        [0.24117639, 0.24264914],\n",
       "        [0.61295479, 0.62334135]]),\n",
       " array([[0.45819058, 0.44933608],\n",
       "        [0.65384725, 0.63633044],\n",
       "        [0.22931929, 0.22453126],\n",
       "        [0.62000189, 0.58000638]]),\n",
       " array([[0.47514406, 0.47857143],\n",
       "        [0.6660504 , 0.65347207],\n",
       "        [0.23744374, 0.23914764],\n",
       "        [0.62765858, 0.63925691]]),\n",
       " array([[0.38338155, 0.42439269],\n",
       "        [0.55844156, 0.59747809],\n",
       "        [0.19150735, 0.2119713 ],\n",
       "        [0.51505967, 0.55012955]]),\n",
       " array([[0.4899055 , 0.48373501],\n",
       "        [0.66829429, 0.65455955],\n",
       "        [0.2445848 , 0.24393043],\n",
       "        [0.60575941, 0.62335986]]),\n",
       " array([[0.458721  , 0.46800514],\n",
       "        [0.63695087, 0.64358953],\n",
       "        [0.22925831, 0.23391038],\n",
       "        [0.59710653, 0.62526347]]),\n",
       " array([[0.48228396, 0.46873217],\n",
       "        [0.65957628, 0.64551416],\n",
       "        [0.24078549, 0.23859152],\n",
       "        [0.60790125, 0.58645537]]),\n",
       " array([[0.40173387, 0.47958396],\n",
       "        [0.57488596, 0.65543186],\n",
       "        [0.20076339, 0.23971927],\n",
       "        [0.55748236, 0.63079638]]),\n",
       " array([[0.47127085, 0.47506396],\n",
       "        [0.64597371, 0.64545053],\n",
       "        [0.24512651, 0.23737627],\n",
       "        [0.62719863, 0.62725384]]),\n",
       " array([[0.45515179, 0.45205695],\n",
       "        [0.64721547, 0.62520575],\n",
       "        [0.22938733, 0.22588943],\n",
       "        [0.42589888, 0.56443902]]),\n",
       " array([[0.47398264, 0.47898403],\n",
       "        [0.66200646, 0.64189911],\n",
       "        [0.23682759, 0.23930447],\n",
       "        [0.62282294, 0.63704729]]),\n",
       " array([[0.45559451, 0.41597997],\n",
       "        [0.65095797, 0.60578787],\n",
       "        [0.22721915, 0.2069358 ],\n",
       "        [0.46695112, 0.40808395]]),\n",
       " array([[0.47961206, 0.47826654],\n",
       "        [0.66797386, 0.65603645],\n",
       "        [0.23964564, 0.24141484],\n",
       "        [0.52736032, 0.50689685]]),\n",
       " array([[0.37002154, 0.45894716],\n",
       "        [0.53996121, 0.62049089],\n",
       "        [0.18476765, 0.22920774],\n",
       "        [0.47951653, 0.61862429]]),\n",
       " array([[0.4669693 , 0.4875851 ],\n",
       "        [0.65363551, 0.65283252],\n",
       "        [0.24124387, 0.24364642],\n",
       "        [0.59344524, 0.64460622]]),\n",
       " array([[0.47861979, 0.48083552],\n",
       "        [0.6459775 , 0.65155981],\n",
       "        [0.24042516, 0.24019706],\n",
       "        [0.63849703, 0.62797117]]),\n",
       " array([[0.48816266, 0.46415707],\n",
       "        [0.65471136, 0.63246199],\n",
       "        [0.24431111, 0.23563533],\n",
       "        [0.65227691, 0.63304455]]),\n",
       " array([[0.43167514, 0.47213284],\n",
       "        [0.60204254, 0.64191196],\n",
       "        [0.21569863, 0.23596497],\n",
       "        [0.58951225, 0.63412031]]),\n",
       " array([[0.47361998, 0.48351387],\n",
       "        [0.64636651, 0.65307216],\n",
       "        [0.23646856, 0.24322538],\n",
       "        [0.62524501, 0.64500079]]),\n",
       " array([[0.43241279, 0.40293745],\n",
       "        [0.62126246, 0.57062572],\n",
       "        [0.2465448 , 0.20130427],\n",
       "        [0.4072173 , 0.55567153]]),\n",
       " array([[0.48189341, 0.46532014],\n",
       "        [0.65818996, 0.63249506],\n",
       "        [0.24074677, 0.23810629],\n",
       "        [0.6296787 , 0.6206525 ]]),\n",
       " array([[0.34749789, 0.29978649],\n",
       "        [0.526631  , 0.46828099],\n",
       "        [0.17354292, 0.14974829],\n",
       "        [0.46825824, 0.4167968 ]]),\n",
       " array([[0.48159248, 0.48103806],\n",
       "        [0.6521815 , 0.66009623],\n",
       "        [0.23922995, 0.24053382],\n",
       "        [0.60939473, 0.58690402]]),\n",
       " array([[0.41588165, 0.42139831],\n",
       "        [0.58771875, 0.60068311],\n",
       "        [0.20770031, 0.21049232],\n",
       "        [0.53728913, 0.55565116]]),\n",
       " array([[0.46621121, 0.4810847 ],\n",
       "        [0.63960251, 0.66284199],\n",
       "        [0.24088517, 0.24006087],\n",
       "        [0.6135182 , 0.61481231]]),\n",
       " array([[0.47082444, 0.46690635],\n",
       "        [0.66362417, 0.65120072],\n",
       "        [0.23524803, 0.23332996],\n",
       "        [0.56753165, 0.59259463]]),\n",
       " array([[0.48190026, 0.46960607],\n",
       "        [0.65823029, 0.65292076],\n",
       "        [0.24458626, 0.23462648],\n",
       "        [0.60903583, 0.60846877]]),\n",
       " array([[0.45493005, 0.47938882],\n",
       "        [0.63786189, 0.66192842],\n",
       "        [0.22727718, 0.23956007],\n",
       "        [0.53977127, 0.60336338]]),\n",
       " array([[0.48146534, 0.48101266],\n",
       "        [0.65932411, 0.65906266],\n",
       "        [0.24055725, 0.24035859],\n",
       "        [0.62163654, 0.63583076]]),\n",
       " array([[0.42108825, 0.44985531],\n",
       "        [0.5912368 , 0.62673501],\n",
       "        [0.21043634, 0.22479567],\n",
       "        [0.5848144 , 0.59656817]]),\n",
       " array([[0.4834228 , 0.48102612],\n",
       "        [0.65100154, 0.65531366],\n",
       "        [0.24156262, 0.24041849],\n",
       "        [0.64722046, 0.61272929]]),\n",
       " array([[0.43004926, 0.38981741],\n",
       "        [0.604889  , 0.5680256 ],\n",
       "        [0.21491406, 0.19477049],\n",
       "        [0.5977405 , 0.5448758 ]]),\n",
       " array([[0.48219833, 0.47560635],\n",
       "        [0.64897894, 0.64823847],\n",
       "        [0.24306145, 0.23814294],\n",
       "        [0.64219794, 0.63450281]]),\n",
       " array([[0.46695425, 0.43848218],\n",
       "        [0.65159046, 0.60731539],\n",
       "        [0.2363317 , 0.21877736],\n",
       "        [0.36369447, 0.36526181]]),\n",
       " array([[0.452773  , 0.48251301],\n",
       "        [0.64517775, 0.6631469 ],\n",
       "        [0.2286633 , 0.24112013],\n",
       "        [0.36366832, 0.64039514]]),\n",
       " array([[0.41152413, 0.46057993],\n",
       "        [0.58766512, 0.64617424],\n",
       "        [0.20557193, 0.22863158],\n",
       "        [0.545847  , 0.46701997]]),\n",
       " array([[0.48735749, 0.48173398],\n",
       "        [0.65465132, 0.65752793],\n",
       "        [0.24483678, 0.24212515],\n",
       "        [0.6371924 , 0.64257592]]),\n",
       " array([[0.47946088, 0.4781772 ],\n",
       "        [0.66871696, 0.65320619],\n",
       "        [0.24347862, 0.240738  ],\n",
       "        [0.51738167, 0.62039233]]),\n",
       " array([[0.48313772, 0.48517142],\n",
       "        [0.67194978, 0.65966528],\n",
       "        [0.24401904, 0.24484968],\n",
       "        [0.40518315, 0.61310507]]),\n",
       " array([[0.46771758, 0.40010154],\n",
       "        [0.64866634, 0.58410984],\n",
       "        [0.23356151, 0.19977513],\n",
       "        [0.55815263, 0.48853858]]),\n",
       " array([[0.47052745, 0.47081686],\n",
       "        [0.66617901, 0.64542655],\n",
       "        [0.23450736, 0.24081232],\n",
       "        [0.55809172, 0.56576607]]),\n",
       " array([[0.46408286, 0.4148864 ],\n",
       "        [0.63885147, 0.58373092],\n",
       "        [0.24045709, 0.20719457],\n",
       "        [0.55051949, 0.55318187]]),\n",
       " array([[0.47004678, 0.47733771],\n",
       "        [0.64432492, 0.64489065],\n",
       "        [0.24018451, 0.23842779],\n",
       "        [0.59539388, 0.61387479]]),\n",
       " array([[0.40413617, 0.439187  ],\n",
       "        [0.57206167, 0.61148887],\n",
       "        [0.20191639, 0.21951267],\n",
       "        [0.52725442, 0.59481564]]),\n",
       " array([[0.47089397, 0.47958492],\n",
       "        [0.65236992, 0.65301768],\n",
       "        [0.24320811, 0.23958858],\n",
       "        [0.578528  , 0.61333044]]),\n",
       " array([[0.43142109, 0.45522956],\n",
       "        [0.61518618, 0.63066651],\n",
       "        [0.2154533 , 0.22746428],\n",
       "        [0.52287808, 0.59216894]]),\n",
       " array([[0.47761034, 0.48402933],\n",
       "        [0.64374168, 0.65597398],\n",
       "        [0.24282151, 0.24182588],\n",
       "        [0.60583534, 0.62673837]]),\n",
       " array([[0.32645812, 0.45541362],\n",
       "        [0.49756998, 0.63897533],\n",
       "        [0.16313966, 0.22746697],\n",
       "        [0.48017098, 0.6044293 ]]),\n",
       " array([[0.47038678, 0.48835327],\n",
       "        [0.64583045, 0.66292406],\n",
       "        [0.2384277 , 0.24436922],\n",
       "        [0.62642522, 0.65101635]]),\n",
       " array([[0.39285864, 0.35067382],\n",
       "        [0.57156827, 0.52368864],\n",
       "        [0.19621719, 0.17523842],\n",
       "        [0.5351339 , 0.50121484]]),\n",
       " array([[0.47863533, 0.47271912],\n",
       "        [0.65372454, 0.64933393],\n",
       "        [0.24145657, 0.23613605],\n",
       "        [0.64544889, 0.62369291]]),\n",
       " array([[0.46500801, 0.43244993],\n",
       "        [0.64418503, 0.60699682],\n",
       "        [0.23206636, 0.21607279],\n",
       "        [0.60248659, 0.58906526]]),\n",
       " array([[0.47713201, 0.4779741 ],\n",
       "        [0.65084459, 0.65153556],\n",
       "        [0.24129639, 0.24303179],\n",
       "        [0.6221373 , 0.63278903]]),\n",
       " array([[0.40979213, 0.40520678],\n",
       "        [0.58135957, 0.57708001],\n",
       "        [0.20470908, 0.20242125],\n",
       "        [0.5623833 , 0.55199525]]),\n",
       " array([[0.47700701, 0.47775833],\n",
       "        [0.65276335, 0.6470799 ],\n",
       "        [0.23795829, 0.24166378],\n",
       "        [0.61655273, 0.61808367]]),\n",
       " array([[0.46528689, 0.43665548],\n",
       "        [0.63038952, 0.60407535],\n",
       "        [0.23244846, 0.21812123],\n",
       "        [0.6144562 , 0.57799503]]),\n",
       " array([[0.47746333, 0.48410883],\n",
       "        [0.65625621, 0.6493101 ],\n",
       "        [0.24163903, 0.24411037],\n",
       "        [0.62206314, 0.63286204]]),\n",
       " array([[0.45511682, 0.48501752],\n",
       "        [0.63234829, 0.67092325],\n",
       "        [0.22744787, 0.24212772],\n",
       "        [0.5615149 , 0.55469301]]),\n",
       " array([[0.46625473, 0.48476358],\n",
       "        [0.64920161, 0.66205799],\n",
       "        [0.23473882, 0.24389028],\n",
       "        [0.53015057, 0.63289855]]),\n",
       " array([[0.47281824, 0.46039715],\n",
       "        [0.65326199, 0.63755431],\n",
       "        [0.23623982, 0.22995602],\n",
       "        [0.5548154 , 0.57266315]]),\n",
       " array([[0.48266685, 0.47366254],\n",
       "        [0.65541956, 0.64420025],\n",
       "        [0.2411634 , 0.23665957],\n",
       "        [0.59213023, 0.64106273]]),\n",
       " array([[0.39721532, 0.43276272],\n",
       "        [0.57454996, 0.6138461 ],\n",
       "        [0.19827222, 0.21605076],\n",
       "        [0.41576806, 0.50933124]]),\n",
       " array([[0.47659689, 0.48038008],\n",
       "        [0.65514387, 0.65660211],\n",
       "        [0.23806615, 0.24137498],\n",
       "        [0.61903413, 0.62747463]]),\n",
       " array([[0.47910227, 0.30847762],\n",
       "        [0.66209862, 0.46898864],\n",
       "        [0.24096774, 0.15409   ],\n",
       "        [0.58933737, 0.45569162]]),\n",
       " array([[0.48220989, 0.48490974],\n",
       "        [0.66348529, 0.64862236],\n",
       "        [0.24096845, 0.24233733],\n",
       "        [0.6316746 , 0.64243196]]),\n",
       " array([[0.45870662, 0.33043033],\n",
       "        [0.63392133, 0.50206444],\n",
       "        [0.22922448, 0.1651187 ],\n",
       "        [0.58358116, 0.44930719]]),\n",
       " array([[0.47937283, 0.47190874],\n",
       "        [0.65250838, 0.64257184],\n",
       "        [0.23950447, 0.24396834],\n",
       "        [0.59724106, 0.62302665]]),\n",
       " array([[0.43574491, 0.46942903],\n",
       "        [0.63209857, 0.64613562],\n",
       "        [0.21661935, 0.23460356],\n",
       "        [0.48210845, 0.59764448]]),\n",
       " array([[0.4765067 , 0.46804272],\n",
       "        [0.65662443, 0.64075498],\n",
       "        [0.23810703, 0.23386004],\n",
       "        [0.61655273, 0.62903658]]),\n",
       " array([[0.43612314, 0.46173481],\n",
       "        [0.6327727 , 0.6555676 ],\n",
       "        [0.21785231, 0.2364384 ],\n",
       "        [0.52309112, 0.58495129]]),\n",
       " array([[0.49717011, 0.48187095],\n",
       "        [0.66637098, 0.66229972],\n",
       "        [0.24733704, 0.24058549],\n",
       "        [0.59069639, 0.58330682]]),\n",
       " array([[0.39664793, 0.45861364],\n",
       "        [0.57016814, 0.62916588],\n",
       "        [0.19823488, 0.22922137],\n",
       "        [0.5453099 , 0.62578004]]),\n",
       " array([[0.48625153, 0.48169602],\n",
       "        [0.6615973 , 0.65812426],\n",
       "        [0.24295898, 0.24321075],\n",
       "        [0.60712488, 0.6463621 ]]),\n",
       " array([[0.41773757, 0.42748521],\n",
       "        [0.58685545, 0.59673151],\n",
       "        [0.20868616, 0.21359026],\n",
       "        [0.55037585, 0.57224523]]),\n",
       " array([[0.49057666, 0.47280869],\n",
       "        [0.66040642, 0.64126522],\n",
       "        [0.24617059, 0.23628945],\n",
       "        [0.62975204, 0.62614879]]),\n",
       " array([[0.47151625, 0.47350823],\n",
       "        [0.64130348, 0.6384006 ],\n",
       "        [0.23553929, 0.23899261],\n",
       "        [0.63775442, 0.63708357]]),\n",
       " array([[0.48311051, 0.45845914],\n",
       "        [0.65730277, 0.64824389],\n",
       "        [0.24117061, 0.22837658],\n",
       "        [0.64600413, 0.55029376]]),\n",
       " array([[0.2644606 , 0.45758039],\n",
       "        [0.41217146, 0.62667769],\n",
       "        [0.13212563, 0.22863312],\n",
       "        [0.40187281, 0.61507459]]),\n",
       " array([[0.48643481, 0.47850438],\n",
       "        [0.64921564, 0.64376111],\n",
       "        [0.24418871, 0.24417443],\n",
       "        [0.64135122, 0.64306159]]),\n",
       " array([[0.45171958, 0.46809475],\n",
       "        [0.61922031, 0.63828129],\n",
       "        [0.22573954, 0.23395979],\n",
       "        [0.6113183 , 0.63381052]]),\n",
       " array([[0.48084092, 0.47094747],\n",
       "        [0.65304845, 0.63418853],\n",
       "        [0.24236394, 0.2441543 ],\n",
       "        [0.63817111, 0.63519439]]),\n",
       " array([[0.46704155, 0.43925234],\n",
       "        [0.66388383, 0.6218471 ],\n",
       "        [0.23328762, 0.21941825],\n",
       "        [0.45200302, 0.54301244]]),\n",
       " array([[0.45875988, 0.48533361],\n",
       "        [0.63161354, 0.66280185],\n",
       "        [0.23204635, 0.24474344],\n",
       "        [0.50506584, 0.61894101]]),\n",
       " array([[0.42739902, 0.45013697],\n",
       "        [0.6038651 , 0.63899551],\n",
       "        [0.2134206 , 0.2246709 ],\n",
       "        [0.47473785, 0.42468809]]),\n",
       " array([[0.45460233, 0.46354167],\n",
       "        [0.64260997, 0.64983139],\n",
       "        [0.22666539, 0.23165079],\n",
       "        [0.49218854, 0.48181589]]),\n",
       " array([[0.48273254, 0.45472409],\n",
       "        [0.65270878, 0.61554747],\n",
       "        [0.24113806, 0.22710133],\n",
       "        [0.60750371, 0.61393108]]),\n",
       " array([[0.48094691, 0.48535202],\n",
       "        [0.64886619, 0.64637248],\n",
       "        [0.24070067, 0.24264799],\n",
       "        [0.6429537 , 0.65000264]]),\n",
       " array([[0.47386979, 0.42016017],\n",
       "        [0.65088792, 0.60587097],\n",
       "        [0.23938616, 0.20993468],\n",
       "        [0.60130308, 0.5367666 ]]),\n",
       " array([[0.47901851, 0.48372647],\n",
       "        [0.64963339, 0.66092073],\n",
       "        [0.24050167, 0.24162575],\n",
       "        [0.62061533, 0.60780662]]),\n",
       " array([[0.45975452, 0.46503181],\n",
       "        [0.64100815, 0.64662573],\n",
       "        [0.22976056, 0.23225206],\n",
       "        [0.57534399, 0.57407433]]),\n",
       " array([[0.47553982, 0.4864072 ],\n",
       "        [0.65690766, 0.65884353],\n",
       "        [0.23736118, 0.24485337],\n",
       "        [0.54104036, 0.59079337]]),\n",
       " array([[0.34729501, 0.40659386],\n",
       "        [0.50866945, 0.57468556],\n",
       "        [0.17340871, 0.20308618],\n",
       "        [0.4859686 , 0.55183142]]),\n",
       " array([[0.47532615, 0.48051921],\n",
       "        [0.6423038 , 0.65165883],\n",
       "        [0.23751398, 0.24280304],\n",
       "        [0.62852245, 0.62254506]]),\n",
       " array([[0.48062079, 0.47206816],\n",
       "        [0.66341766, 0.64852032],\n",
       "        [0.24166612, 0.23589835],\n",
       "        [0.62984372, 0.62901822]]),\n",
       " array([[0.47080425, 0.45974145],\n",
       "        [0.65304637, 0.64562298],\n",
       "        [0.23524006, 0.2371462 ],\n",
       "        [0.62613036, 0.54112351]]),\n",
       " array([[0.44700759, 0.40152324],\n",
       "        [0.62678356, 0.5779328 ],\n",
       "        [0.2230734 , 0.20065598],\n",
       "        [0.57647288, 0.56777207]]),\n",
       " array([[0.48290491, 0.47040076],\n",
       "        [0.65646501, 0.64208809],\n",
       "        [0.24303523, 0.23504367],\n",
       "        [0.61983449, 0.63130881]]),\n",
       " array([[0.40167723, 0.45090659],\n",
       "        [0.60032595, 0.62165555],\n",
       "        [0.19975592, 0.22521162],\n",
       "        [0.46409983, 0.60646145]]),\n",
       " array([[0.4718148 , 0.47254243],\n",
       "        [0.66086623, 0.63874912],\n",
       "        [0.23744491, 0.24379911],\n",
       "        [0.50384267, 0.63123563]]),\n",
       " array([[0.46634869, 0.39284298],\n",
       "        [0.65684229, 0.56517399],\n",
       "        [0.23172914, 0.19623381],\n",
       "        [0.61951818, 0.55805112]]),\n",
       " array([[0.47357085, 0.47770714],\n",
       "        [0.64244559, 0.64868553],\n",
       "        [0.2365114 , 0.23856134],\n",
       "        [0.6296787 , 0.6079391 ]]),\n",
       " array([[0.47566964, 0.42585158],\n",
       "        [0.65441094, 0.5939189 ],\n",
       "        [0.24218201, 0.21280167],\n",
       "        [0.62809984, 0.59007545]]),\n",
       " array([[0.48082008, 0.47737494],\n",
       "        [0.6478173 , 0.64387128],\n",
       "        [0.24026732, 0.23852194],\n",
       "        [0.64491114, 0.63811677]]),\n",
       " array([[0.3262016 , 0.39553748],\n",
       "        [0.49405806, 0.57151804],\n",
       "        [0.16291828, 0.19753539],\n",
       "        [0.45820284, 0.54468968]]),\n",
       " array([[0.48321004, 0.47034233],\n",
       "        [0.65248744, 0.64509228],\n",
       "        [0.24407849, 0.24248768],\n",
       "        [0.6115066 , 0.61274809]]),\n",
       " array([[0.46100142, 0.33365546],\n",
       "        [0.6344909 , 0.49810256],\n",
       "        [0.23029551, 0.16669537],\n",
       "        [0.53753981, 0.47337349]]),\n",
       " array([[0.46252259, 0.48264611],\n",
       "        [0.63842513, 0.65249642],\n",
       "        [0.23574796, 0.24462494],\n",
       "        [0.61101691, 0.62408127]]),\n",
       " array([[0.46394874, 0.46868898],\n",
       "        [0.67793299, 0.66678792],\n",
       "        [0.23514114, 0.23496225],\n",
       "        [0.22803648, 0.56508275]]),\n",
       " array([[0.48375649, 0.47662597],\n",
       "        [0.6878487 , 0.66695041],\n",
       "        [0.24379827, 0.23813781],\n",
       "        [0.4933865 , 0.59990703]]),\n",
       " array([[0.48269256, 0.46829543],\n",
       "        [0.66729849, 0.64980472],\n",
       "        [0.24242209, 0.24153634],\n",
       "        [0.60437224, 0.57771852]]),\n",
       " array([[0.46907329, 0.47586098],\n",
       "        [0.64447643, 0.64613527],\n",
       "        [0.24209393, 0.23780448],\n",
       "        [0.59131679, 0.63956424]]),\n",
       " array([[0.44527643, 0.42900977],\n",
       "        [0.61564295, 0.60246226],\n",
       "        [0.22251053, 0.21435007],\n",
       "        [0.60454341, 0.57288197]]),\n",
       " array([[0.4759569 , 0.48237226],\n",
       "        [0.66537729, 0.65500042],\n",
       "        [0.24431084, 0.24285638],\n",
       "        [0.60078706, 0.62850408]]),\n",
       " array([[0.47678315, 0.47520223],\n",
       "        [0.64194215, 0.64407366],\n",
       "        [0.23820872, 0.23744011],\n",
       "        [0.63655731, 0.64196385]]),\n",
       " array([[0.47537014, 0.47711468],\n",
       "        [0.64395253, 0.64315221],\n",
       "        [0.2430661 , 0.2442725 ],\n",
       "        [0.64086433, 0.64349301]]),\n",
       " array([[0.47727733, 0.446956  ],\n",
       "        [0.67260079, 0.62584843],\n",
       "        [0.23741624, 0.22332198],\n",
       "        [0.29855111, 0.51585599]]),\n",
       " array([[0.45085328, 0.46480793],\n",
       "        [0.65234273, 0.64060525],\n",
       "        [0.22518461, 0.24439726],\n",
       "        [0.45207322, 0.53620184]]),\n",
       " array([[0.48743612, 0.48315122],\n",
       "        [0.66839923, 0.65089854],\n",
       "        [0.24453649, 0.24405979],\n",
       "        [0.61212762, 0.64246795]]),\n",
       " array([[0.48671576, 0.47436994],\n",
       "        [0.66211704, 0.65085749],\n",
       "        [0.24462774, 0.23997206],\n",
       "        [0.6074469 , 0.62554025]]),\n",
       " array([[0.33750552, 0.38717093],\n",
       "        [0.49958366, 0.55794658],\n",
       "        [0.16864325, 0.19337771],\n",
       "        [0.4940955 , 0.54187136]]),\n",
       " array([[0.48039294, 0.48123499],\n",
       "        [0.64184502, 0.64678329],\n",
       "        [0.2400204 , 0.24388774],\n",
       "        [0.63760943, 0.64621893]]),\n",
       " array([[0.46420347, 0.46735039],\n",
       "        [0.6534611 , 0.64613361],\n",
       "        [0.23181822, 0.23356752],\n",
       "        [0.42024067, 0.60302042]]),\n",
       " array([[0.44748551, 0.45903406],\n",
       "        [0.64312358, 0.65160953],\n",
       "        [0.2410967 , 0.22855474],\n",
       "        [0.39942479, 0.50878854]]),\n",
       " array([[0.46129684, 0.49095859],\n",
       "        [0.6470292 , 0.66003259],\n",
       "        [0.23051345, 0.2476415 ],\n",
       "        [0.57302118, 0.65098081]]),\n",
       " array([[0.48392203, 0.4932599 ],\n",
       "        [0.66416312, 0.66113106],\n",
       "        [0.24502842, 0.24649028],\n",
       "        [0.5848144 , 0.63043013]]),\n",
       " array([[0.47671413, 0.4280876 ],\n",
       "        [0.66429955, 0.60359173],\n",
       "        [0.23811998, 0.21386305],\n",
       "        [0.55140121, 0.57387574]]),\n",
       " array([[0.48166071, 0.48540131],\n",
       "        [0.66161703, 0.65558228],\n",
       "        [0.24067379, 0.24236599],\n",
       "        [0.6234894 , 0.62809984]]),\n",
       " array([[0.48395267, 0.44264816],\n",
       "        [0.67158723, 0.6106729 ],\n",
       "        [0.24077773, 0.22121702],\n",
       "        [0.63621229, 0.60967794]]),\n",
       " array([[0.4789258 , 0.4771603 ],\n",
       "        [0.6523553 , 0.65334717],\n",
       "        [0.23880001, 0.24183316],\n",
       "        [0.63123563, 0.63637574]]),\n",
       " array([[0.41238833, 0.47350208],\n",
       "        [0.58412306, 0.64881049],\n",
       "        [0.20611254, 0.24222907],\n",
       "        [0.57722448, 0.63730122]]),\n",
       " array([[0.47517335, 0.47870081],\n",
       "        [0.63669372, 0.64001179],\n",
       "        [0.23978285, 0.243932  ],\n",
       "        [0.63553992, 0.63632126]]),\n",
       " array([[0.39760219, 0.45705128],\n",
       "        [0.56443321, 0.62727848],\n",
       "        [0.19863789, 0.22841619],\n",
       "        [0.55027324, 0.61651535]]),\n",
       " array([[0.46786975, 0.4675632 ],\n",
       "        [0.63574736, 0.64200033],\n",
       "        [0.23377002, 0.24045277],\n",
       "        [0.61601049, 0.62219292]]),\n",
       " array([[0.36575688, 0.42798879],\n",
       "        [0.53325783, 0.59759944],\n",
       "        [0.18272262, 0.21383259],\n",
       "        [0.50774544, 0.57108968]]),\n",
       " array([[0.48238885, 0.48197437],\n",
       "        [0.64855963, 0.64987084],\n",
       "        [0.24120269, 0.24131099],\n",
       "        [0.62489425, 0.62504196]]),\n",
       " array([[0.48143814, 0.47886124],\n",
       "        [0.65361017, 0.65256479],\n",
       "        [0.24421855, 0.23925565],\n",
       "        [0.63579441, 0.64122502]]),\n",
       " array([[0.47985558, 0.47243473],\n",
       "        [0.65322025, 0.65409321],\n",
       "        [0.24299278, 0.23934203],\n",
       "        [0.57138871, 0.54270141]]),\n",
       " array([[0.35908761, 0.41649965],\n",
       "        [0.53039806, 0.59433274],\n",
       "        [0.1793427 , 0.20816882],\n",
       "        [0.49475959, 0.56915295]]),\n",
       " array([[0.4787074 , 0.4754276 ],\n",
       "        [0.64631703, 0.645314  ],\n",
       "        [0.23923678, 0.23755385],\n",
       "        [0.64174769, 0.64059368]]),\n",
       " array([[0.44757739, 0.43676109],\n",
       "        [0.61435251, 0.60577214],\n",
       "        [0.22364644, 0.21825177],\n",
       "        [0.60503767, 0.60143681]]),\n",
       " array([[0.48509072, 0.4733748 ],\n",
       "        [0.65118502, 0.64128839],\n",
       "        [0.24236296, 0.23637487],\n",
       "        [0.6355581 , 0.63088792]]),\n",
       " array([[0.45435444, 0.4187229 ],\n",
       "        [0.63570949, 0.59120127],\n",
       "        [0.22617032, 0.20926592],\n",
       "        [0.61443745, 0.58653342]]),\n",
       " array([[0.48589607, 0.4793486 ],\n",
       "        [0.64947341, 0.6462493 ],\n",
       "        [0.24312529, 0.24154908],\n",
       "        [0.65026955, 0.64500079]]),\n",
       " array([[0.46528689, 0.43665548],\n",
       "        [0.63038952, 0.60407535],\n",
       "        [0.23249495, 0.21814644],\n",
       "        [0.6144562 , 0.57799503]]),\n",
       " array([[0.48738671, 0.4804825 ],\n",
       "        [0.6577516 , 0.64577686],\n",
       "        [0.24350584, 0.24137988],\n",
       "        [0.62622251, 0.6433672 ]]),\n",
       " array([[0.47617251, 0.44008102],\n",
       "        [0.65828432, 0.61163191],\n",
       "        [0.23794118, 0.21993202],\n",
       "        [0.61475609, 0.60829856]]),\n",
       " array([[0.47349454, 0.48360044],\n",
       "        [0.66365769, 0.66029337],\n",
       "        [0.23646729, 0.24151222],\n",
       "        [0.56913296, 0.6494863 ]]),\n",
       " array([[0.48900465, 0.47164106],\n",
       "        [0.67578181, 0.66694252],\n",
       "        [0.24340649, 0.23605541],\n",
       "        [0.63373761, 0.54838252]]),\n",
       " array([[0.46818677, 0.46931937],\n",
       "        [0.64233556, 0.64317338],\n",
       "        [0.23374445, 0.2345053 ],\n",
       "        [0.62106114, 0.62714341]]),\n",
       " array([[0.46742397, 0.48088283],\n",
       "        [0.64813763, 0.66267161],\n",
       "        [0.23352565, 0.24034862],\n",
       "        [0.57248407, 0.63413853]]),\n",
       " array([[0.47934705, 0.48909645],\n",
       "        [0.65433404, 0.66816131],\n",
       "        [0.23957172, 0.2444628 ],\n",
       "        [0.64079216, 0.63419319]]),\n",
       " array([[0.43902439, 0.42831182],\n",
       "        [0.62784857, 0.61179735],\n",
       "        [0.21914961, 0.21370303],\n",
       "        [0.41731066, 0.57192664]]),\n",
       " array([[0.48234621, 0.45968862],\n",
       "        [0.65526985, 0.63752798],\n",
       "        [0.24097607, 0.23444521],\n",
       "        [0.52181194, 0.61052689]]),\n",
       " array([[0.41909272, 0.45796808],\n",
       "        [0.60254435, 0.64483447],\n",
       "        [0.20930113, 0.22851584],\n",
       "        [0.49442762, 0.52185461]]),\n",
       " array([[0.46837441, 0.46620953],\n",
       "        [0.65337162, 0.64410548],\n",
       "        [0.23391179, 0.2399317 ],\n",
       "        [0.5279954 , 0.53758158]]),\n",
       " array([[0.41152413, 0.46057993],\n",
       "        [0.58766512, 0.64617424],\n",
       "        [0.20552187, 0.22996405],\n",
       "        [0.545847  , 0.46701997]]),\n",
       " array([[0.48088917, 0.48655063],\n",
       "        [0.6602922 , 0.67578509],\n",
       "        [0.24225839, 0.24477861],\n",
       "        [0.61160073, 0.62679362]]),\n",
       " array([[0.43313   , 0.44071007],\n",
       "        [0.61983334, 0.62602676],\n",
       "        [0.21622306, 0.2201594 ],\n",
       "        [0.53599257, 0.508441  ]]),\n",
       " array([[0.4848123 , 0.47980082],\n",
       "        [0.65470027, 0.64909352],\n",
       "        [0.2466704 , 0.23964508],\n",
       "        [0.62260065, 0.604182  ]]),\n",
       " array([[0.47554293, 0.44841319],\n",
       "        [0.64929171, 0.62761011],\n",
       "        [0.23770763, 0.22407695],\n",
       "        [0.63110755, 0.59593314]]),\n",
       " array([[0.47851053, 0.46903004],\n",
       "        [0.64891578, 0.64947299],\n",
       "        [0.24058182, 0.24039276],\n",
       "        [0.59468065, 0.61267291]]),\n",
       " array([[0.47036123, 0.46356582],\n",
       "        [0.65022797, 0.6473812 ],\n",
       "        [0.23485614, 0.23162607],\n",
       "        [0.58100992, 0.57758022]]),\n",
       " array([[0.48290982, 0.47521203],\n",
       "        [0.65774217, 0.65654364],\n",
       "        [0.24250596, 0.24058154],\n",
       "        [0.6097912 , 0.61748663]]),\n",
       " array([[0.47468097, 0.40869931],\n",
       "        [0.64075486, 0.58312847],\n",
       "        [0.23866146, 0.20425006],\n",
       "        [0.62570627, 0.56981243]]),\n",
       " array([[0.47701334, 0.47806318],\n",
       "        [0.64102357, 0.64975335],\n",
       "        [0.24150143, 0.24305607],\n",
       "        [0.63508524, 0.63771818]]),\n",
       " array([[0.31592917, 0.42471807],\n",
       "        [0.48104273, 0.59498599],\n",
       "        [0.15781998, 0.21219331],\n",
       "        [0.46690521, 0.58643586]]),\n",
       " array([[0.47635398, 0.47548224],\n",
       "        [0.64841707, 0.64568094],\n",
       "        [0.24015003, 0.23763816],\n",
       "        [0.62565094, 0.63846082]]),\n",
       " array([[0.47193489, 0.44858249],\n",
       "        [0.66846652, 0.62116432],\n",
       "        [0.23456558, 0.24581053],\n",
       "        [0.61813962, 0.60579738]]),\n",
       " array([[0.46989784, 0.46816001],\n",
       "        [0.64343409, 0.63673568],\n",
       "        [0.2467427 , 0.23705561],\n",
       "        [0.62330434, 0.63475768]]),\n",
       " array([[0.45097713, 0.4285282 ],\n",
       "        [0.66630982, 0.60231365],\n",
       "        [0.22474358, 0.21413514],\n",
       "        [0.34253249, 0.58647488]]),\n",
       " array([[0.46661872, 0.47280936],\n",
       "        [0.65668354, 0.64698712],\n",
       "        [0.23944757, 0.24152669],\n",
       "        [0.60220044, 0.62648049]]),\n",
       " array([[0.44614536, 0.47253855],\n",
       "        [0.62001875, 0.63702026],\n",
       "        [0.22293588, 0.23608661],\n",
       "        [0.59781731, 0.63650284]]),\n",
       " array([[0.48037939, 0.47380626],\n",
       "        [0.66840361, 0.63538033],\n",
       "        [0.24540577, 0.23657942],\n",
       "        [0.62934854, 0.62912835]]),\n",
       " array([[0.45619036, 0.47031468],\n",
       "        [0.62867553, 0.64217181],\n",
       "        [0.22790998, 0.23498115],\n",
       "        [0.60273449, 0.61914587]]),\n",
       " array([[0.46724843, 0.48542601],\n",
       "        [0.6596636 , 0.65721897],\n",
       "        [0.23263988, 0.24375147],\n",
       "        [0.586748  , 0.58557675]]),\n",
       " array([[0.46217199, 0.44004376],\n",
       "        [0.6531546 , 0.61743936],\n",
       "        [0.23673322, 0.21941815],\n",
       "        [0.4823784 , 0.38143711]]),\n",
       " array([[0.4763934 , 0.47818858],\n",
       "        [0.64186232, 0.66385227],\n",
       "        [0.24225273, 0.23885263],\n",
       "        [0.61212762, 0.59837389]]),\n",
       " array([[0.48046859, 0.45363173],\n",
       "        [0.65265888, 0.62560157],\n",
       "        [0.24172654, 0.22661463],\n",
       "        [0.62743784, 0.59550947]]),\n",
       " array([[0.48157381, 0.46916806],\n",
       "        [0.65637907, 0.64082798],\n",
       "        [0.2400753 , 0.23422666],\n",
       "        [0.62332285, 0.60954579]]),\n",
       " array([[0.4714557 , 0.41384712],\n",
       "        [0.70222148, 0.59460502],\n",
       "        [0.23446837, 0.20645615],\n",
       "        [0.49568833, 0.53072   ]]),\n",
       " array([[0.48526901, 0.47171343],\n",
       "        [0.72584572, 0.65101799],\n",
       "        [0.24286897, 0.23547102],\n",
       "        [0.6043342 , 0.57984883]]),\n",
       " array([[0.44368621, 0.45399615],\n",
       "        [0.61914719, 0.63347202],\n",
       "        [0.22171523, 0.23297919],\n",
       "        [0.59938997, 0.62258212]]),\n",
       " array([[0.47846375, 0.47504998],\n",
       "        [0.65022628, 0.65180444],\n",
       "        [0.23913765, 0.23736999],\n",
       "        [0.63818922, 0.64259392]]),\n",
       " array([[0.46124351, 0.45414142],\n",
       "        [0.62509429, 0.62317453],\n",
       "        [0.23041021, 0.22695192],\n",
       "        [0.60820399, 0.61597308]]),\n",
       " array([[0.47691759, 0.48406177],\n",
       "        [0.64059878, 0.64723464],\n",
       "        [0.23832216, 0.24318633],\n",
       "        [0.63920266, 0.64528761]]),\n",
       " array([[0.42198793, 0.43297532],\n",
       "        [0.61180966, 0.62576962],\n",
       "        [0.21047643, 0.21621621],\n",
       "        [0.32477178, 0.49345299]]),\n",
       " array([[0.49139579, 0.48133853],\n",
       "        [0.66168898, 0.65671391],\n",
       "        [0.24554678, 0.24054711],\n",
       "        [0.52001734, 0.62819173]]),\n",
       " array([[0.42119345, 0.48023174],\n",
       "        [0.59214088, 0.64866912],\n",
       "        [0.21043473, 0.23991021],\n",
       "        [0.57738261, 0.62230414]]),\n",
       " array([[0.47800763, 0.47701822],\n",
       "        [0.64154402, 0.64346307],\n",
       "        [0.23881497, 0.24345108],\n",
       "        [0.63399277, 0.61681435]]),\n",
       " array([[0.37108784, 0.38641279],\n",
       "        [0.54126387, 0.5644377 ],\n",
       "        [0.18542584, 0.19309957],\n",
       "        [0.52324022, 0.52500576]]),\n",
       " array([[0.4855348 , 0.47772639],\n",
       "        [0.66117005, 0.64493063],\n",
       "        [0.24227392, 0.23863423],\n",
       "        [0.62910999, 0.6414053 ]]),\n",
       " array([[0.45894957, 0.4421698 ],\n",
       "        [0.64316259, 0.61634345],\n",
       "        [0.22923679, 0.22076479],\n",
       "        [0.57391547, 0.59547094]]),\n",
       " array([[0.47260219, 0.47692399],\n",
       "        [0.64963745, 0.64651623],\n",
       "        [0.24415189, 0.24000604],\n",
       "        [0.62997204, 0.6415675 ]]),\n",
       " array([[0.45214528, 0.43814366],\n",
       "        [0.62841708, 0.61308411],\n",
       "        [0.22592604, 0.21891582],\n",
       "        [0.5873329 , 0.5685529 ]]),\n",
       " array([[0.47694932, 0.46551284],\n",
       "        [0.65198049, 0.63819169],\n",
       "        [0.24037462, 0.23614408],\n",
       "        [0.58661146, 0.58295393]]),\n",
       " array([[0.38833798, 0.42622136],\n",
       "        [0.5618164 , 0.60156096],\n",
       "        [0.19406383, 0.21301965],\n",
       "        [0.54035408, 0.59005604]]),\n",
       " array([[0.49013224, 0.48327324],\n",
       "        [0.66054549, 0.66540018],\n",
       "        [0.24791746, 0.24146173],\n",
       "        [0.63811677, 0.64055758]]),\n",
       " array([[0.47652458, 0.42729604],\n",
       "        [0.65795236, 0.60286738],\n",
       "        [0.23798381, 0.21336384],\n",
       "        [0.55839622, 0.51294637]]),\n",
       " array([[0.47431931, 0.46580759],\n",
       "        [0.66804103, 0.6353602 ],\n",
       "        [0.23894234, 0.23546951],\n",
       "        [0.55408077, 0.61205237]]),\n",
       " array([[0.38017849, 0.39694053],\n",
       "        [0.55565853, 0.57020904],\n",
       "        [0.18983509, 0.19824411],\n",
       "        [0.48044162, 0.51091366]]),\n",
       " array([[0.47761892, 0.4799149 ],\n",
       "        [0.65901549, 0.64816901],\n",
       "        [0.24166573, 0.24360443],\n",
       "        [0.5904442 , 0.62013206]]),\n",
       " array([[0.46327802, 0.45480158],\n",
       "        [0.64469781, 0.62234435],\n",
       "        [0.23150838, 0.22726892],\n",
       "        [0.6042581 , 0.61548654]]),\n",
       " array([[0.48141357, 0.46965053],\n",
       "        [0.6597149 , 0.63597165],\n",
       "        [0.24052503, 0.24013297],\n",
       "        [0.58087226, 0.63099774]]),\n",
       " array([[0.34982006, 0.34040323],\n",
       "        [0.52277234, 0.50705748],\n",
       "        [0.17473508, 0.17010003],\n",
       "        [0.46598655, 0.49597556]]),\n",
       " array([[0.47867873, 0.48227394],\n",
       "        [0.648912  , 0.64878869],\n",
       "        [0.24025431, 0.24102902],\n",
       "        [0.62892644, 0.63675697]]),\n",
       " array([[0.44085052, 0.47405175],\n",
       "        [0.61467972, 0.65451544],\n",
       "        [0.22031641, 0.23681281],\n",
       "        [0.57234476, 0.55819324]]),\n",
       " array([[0.4836439 , 0.47997302],\n",
       "        [0.65304256, 0.65764126],\n",
       "        [0.24214383, 0.23986883],\n",
       "        [0.62745624, 0.6289448 ]]),\n",
       " array([[0.48319473, 0.46732799],\n",
       "        [0.65668876, 0.64062726],\n",
       "        [0.24264177, 0.23356376],\n",
       "        [0.60703014, 0.60378233]]),\n",
       " array([[0.48200514, 0.48768408],\n",
       "        [0.65757323, 0.66080708],\n",
       "        [0.24085161, 0.24508687],\n",
       "        [0.61761728, 0.60593024]]),\n",
       " array([[0.40890705, 0.45376835],\n",
       "        [0.57996215, 0.62301555],\n",
       "        [0.2043458 , 0.22673891],\n",
       "        [0.55391742, 0.61769192]]),\n",
       " array([[0.46914651, 0.4667094 ],\n",
       "        [0.6399066 , 0.64416245],\n",
       "        [0.23406976, 0.23297767],\n",
       "        [0.60461947, 0.62550336]]),\n",
       " array([[0.33885224, 0.38104156],\n",
       "        [0.50790783, 0.55894568],\n",
       "        [0.16933493, 0.19036636],\n",
       "        [0.47675716, 0.50055643]]),\n",
       " array([[0.47814521, 0.48926243],\n",
       "        [0.67211276, 0.66151912],\n",
       "        [0.24158309, 0.24452359],\n",
       "        [0.61511205, 0.63853323]]),\n",
       " array([[0.47095885, 0.33360656],\n",
       "        [0.64944935, 0.49808781],\n",
       "        [0.23662308, 0.16666815],\n",
       "        [0.56494198, 0.48251334]]),\n",
       " array([[0.4762832 , 0.47289989],\n",
       "        [0.66046241, 0.64092249],\n",
       "        [0.24043708, 0.23622341],\n",
       "        [0.49846767, 0.62478344]]),\n",
       " array([[0.47323053, 0.47566061],\n",
       "        [0.64378515, 0.65276482],\n",
       "        [0.23925101, 0.24294895],\n",
       "        [0.61107343, 0.58150134]]),\n",
       " array([[0.47373642, 0.47178478],\n",
       "        [0.65318484, 0.64161709],\n",
       "        [0.23613368, 0.23965397],\n",
       "        [0.55546778, 0.63209501]]),\n",
       " array([[0.41002232, 0.4654527 ],\n",
       "        [0.58082733, 0.63561347],\n",
       "        [0.20488362, 0.23247162],\n",
       "        [0.57322001, 0.6176546 ]]),\n",
       " array([[0.47035343, 0.479265  ],\n",
       "        [0.64613816, 0.64842812],\n",
       "        [0.23438133, 0.24195485],\n",
       "        [0.62824686, 0.63395632]]),\n",
       " array([[0.3524653 , 0.36698049],\n",
       "        [0.53126445, 0.53966393],\n",
       "        [0.1753901 , 0.18301372],\n",
       "        [0.30443926, 0.31764339]]),\n",
       " array([[0.48105333, 0.46893863],\n",
       "        [0.667516  , 0.65387805],\n",
       "        [0.24042225, 0.24286178],\n",
       "        [0.62094971, 0.5873329 ]]),\n",
       " array([[0.40392653, 0.38927343],\n",
       "        [0.57215644, 0.56585767],\n",
       "        [0.20184734, 0.19454913],\n",
       "        [0.56381487, 0.53208905]]),\n",
       " array([[0.47345853, 0.45833143],\n",
       "        [0.64263196, 0.63239196],\n",
       "        [0.24142894, 0.24522405],\n",
       "        [0.63390165, 0.56218144]]),\n",
       " array([[0.4417112 , 0.46567698],\n",
       "        [0.62151595, 0.63377364],\n",
       "        [0.23906548, 0.23946428],\n",
       "        [0.47698371, 0.58389457]]),\n",
       " array([[0.48616001, 0.48577722],\n",
       "        [0.65356473, 0.64989335],\n",
       "        [0.24618323, 0.24240366],\n",
       "        [0.63878661, 0.61830743]]),\n",
       " array([[0.45335725, 0.450556  ],\n",
       "        [0.62003235, 0.62218932],\n",
       "        [0.22650087, 0.22517637],\n",
       "        [0.61989029, 0.61415618]]),\n",
       " array([[0.47015837, 0.47493497],\n",
       "        [0.63205699, 0.6409595 ],\n",
       "        [0.23531247, 0.24066884],\n",
       "        [0.63592162, 0.64014236]]),\n",
       " array([[0.4740222 , 0.46541713],\n",
       "        [0.65588235, 0.63099951],\n",
       "        [0.2431832 , 0.2324889 ],\n",
       "        [0.58534227, 0.5972987 ]]),\n",
       " array([[0.48146734, 0.48080069],\n",
       "        [0.66576797, 0.64660269],\n",
       "        [0.24463312, 0.24170212],\n",
       "        [0.63744628, 0.62945861]]),\n",
       " array([[0.46325836, 0.44445117],\n",
       "        [0.63718723, 0.62041081],\n",
       "        [0.23145954, 0.22210769],\n",
       "        [0.57536381, 0.60145591]]),\n",
       " array([[0.46890137, 0.48396785],\n",
       "        [0.63834091, 0.65720506],\n",
       "        [0.24127559, 0.24213721],\n",
       "        [0.62067108, 0.62063392]]),\n",
       " array([[0.46077358, 0.47220735],\n",
       "        [0.6370688 , 0.64274505],\n",
       "        [0.23009027, 0.24527463],\n",
       "        [0.56590667, 0.61877335]]),\n",
       " array([[0.47657238, 0.47453798],\n",
       "        [0.6567381 , 0.64899095],\n",
       "        [0.24196027, 0.23987032],\n",
       "        [0.595259  , 0.62578004]]),\n",
       " array([[0.42726153, 0.440408  ],\n",
       "        [0.61613366, 0.61392907],\n",
       "        [0.21316536, 0.22007837],\n",
       "        [0.52093655, 0.60967794]]),\n",
       " array([[0.47335462, 0.47745395],\n",
       "        [0.64706541, 0.6453334 ],\n",
       "        [0.24186745, 0.23988743],\n",
       "        [0.62235975, 0.64390619]]),\n",
       " array([[0.43756297, 0.33476557],\n",
       "        [0.61231054, 0.50547179],\n",
       "        [0.21768815, 0.16695594],\n",
       "        [0.42696284, 0.4337718 ]]),\n",
       " array([[0.48142639, 0.48351899],\n",
       "        [0.66393139, 0.65159264],\n",
       "        [0.24086066, 0.24162903],\n",
       "        [0.61728128, 0.62648049]]),\n",
       " array([[0.4633687 , 0.44586297],\n",
       "        [0.65193227, 0.63345571],\n",
       "        [0.23126195, 0.22259819],\n",
       "        [0.56534409, 0.50787591]]),\n",
       " array([[0.47783843, 0.47136574],\n",
       "        [0.64431871, 0.64134175],\n",
       "        [0.24037779, 0.23544433],\n",
       "        [0.61985309, 0.59017251]]),\n",
       " array([[0.46747218, 0.46916923],\n",
       "        [0.67527099, 0.67513837],\n",
       "        [0.24677354, 0.23552995],\n",
       "        [0.44617766, 0.45894534]]),\n",
       " array([[0.48128176, 0.47377049],\n",
       "        [0.67310274, 0.65804531],\n",
       "        [0.24219312, 0.23668941],\n",
       "        [0.49956775, 0.60668898]]),\n",
       " array([[0.44300834, 0.38327642],\n",
       "        [0.6198288 , 0.55495255],\n",
       "        [0.2211912 , 0.19140649],\n",
       "        [0.61094155, 0.55226138]]),\n",
       " array([[0.46981788, 0.48472602],\n",
       "        [0.6439309 , 0.66949408],\n",
       "        [0.23418638, 0.24272247],\n",
       "        [0.61920173, 0.64664834]]),\n",
       " array([[0.45999835, 0.46132695],\n",
       "        [0.63769152, 0.62549619],\n",
       "        [0.22965265, 0.23439512],\n",
       "        [0.6069733 , 0.62589069]]),\n",
       " array([[0.48033169, 0.47376087],\n",
       "        [0.6473297 , 0.63589214],\n",
       "        [0.23997587, 0.23972274],\n",
       "        [0.62094971, 0.62767697]]),\n",
       " array([[0.48460496, 0.40323231],\n",
       "        [0.66325963, 0.58021332],\n",
       "        [0.24208966, 0.20144891],\n",
       "        [0.5757403 , 0.47603173]]),\n",
       " array([[0.46706883, 0.45815967],\n",
       "        [0.66643149, 0.63458516],\n",
       "        [0.23268758, 0.23600092],\n",
       "        [0.53906295, 0.53496624]]),\n",
       " array([[0.42127143, 0.44103783],\n",
       "        [0.59192286, 0.61662818],\n",
       "        [0.21049128, 0.22025943],\n",
       "        [0.585225  , 0.59906422]]),\n",
       " array([[0.47426861, 0.48763889],\n",
       "        [0.6468677 , 0.65326139],\n",
       "        [0.23901002, 0.24503869],\n",
       "        [0.63992562, 0.64866648]]),\n",
       " array([[0.4153068 , 0.46550039],\n",
       "        [0.58854935, 0.63419235],\n",
       "        [0.20740531, 0.23257263],\n",
       "        [0.56084775, 0.61728128]]),\n",
       " array([[0.47920927, 0.46851344],\n",
       "        [0.64438034, 0.63556382],\n",
       "        [0.24131966, 0.23524949],\n",
       "        [0.63457564, 0.61728128]]),\n",
       " array([[0.45569252, 0.44521241],\n",
       "        [0.63771266, 0.6124058 ],\n",
       "        [0.22763557, 0.22236347],\n",
       "        [0.53672478, 0.58422741]]),\n",
       " array([[0.47758962, 0.47409315],\n",
       "        [0.65054971, 0.64094742],\n",
       "        [0.24645964, 0.23691882],\n",
       "        [0.5956443 , 0.60625281]]),\n",
       " array([[0.46937508, 0.3871877 ],\n",
       "        [0.64055421, 0.56473128],\n",
       "        [0.23674373, 0.19347965],\n",
       "        [0.58491218, 0.54278436]]),\n",
       " array([[0.48196762, 0.48183122],\n",
       "        [0.65517912, 0.65339313],\n",
       "        [0.24083632, 0.24075073],\n",
       "        [0.62837548, 0.6416576 ]]),\n",
       " array([[0.46899517, 0.4554298 ],\n",
       "        [0.65830157, 0.63450637],\n",
       "        [0.23348519, 0.22717452],\n",
       "        [0.53402242, 0.60206687]]),\n",
       " array([[0.47923221, 0.4738003 ],\n",
       "        [0.65609688, 0.65549693],\n",
       "        [0.24080255, 0.23628428],\n",
       "        [0.57009202, 0.61966705]]),\n",
       " array([[0.45665615, 0.41924521],\n",
       "        [0.62810475, 0.59037515],\n",
       "        [0.22821481, 0.20939371],\n",
       "        [0.58990071, 0.51251434]]),\n",
       " array([[0.46834133, 0.4617772 ],\n",
       "        [0.64004711, 0.63813923],\n",
       "        [0.23588301, 0.23039383],\n",
       "        [0.54029166, 0.54838252]]),\n",
       " array([[0.47617271, 0.43115009],\n",
       "        [0.65116833, 0.60940936],\n",
       "        [0.23783919, 0.21512759],\n",
       "        [0.54431729, 0.47788926]]),\n",
       " array([[0.46581316, 0.45117241],\n",
       "        [0.6571237 , 0.61724745],\n",
       "        [0.23257536, 0.22526454],\n",
       "        [0.49109985, 0.55420326]]),\n",
       " array([[0.4407645 , 0.39734772],\n",
       "        [0.62169565, 0.57283657],\n",
       "        [0.22025968, 0.19849143],\n",
       "        [0.5658665 , 0.54743532]]),\n",
       " array([[0.48765017, 0.48597035],\n",
       "        [0.65993974, 0.65971176],\n",
       "        [0.24504678, 0.24281779],\n",
       "        [0.62398882, 0.62380389]]),\n",
       " array([[0.42726153, 0.440408  ],\n",
       "        [0.61613366, 0.61392907],\n",
       "        [0.21348307, 0.22009269],\n",
       "        [0.52093655, 0.60967794]]),\n",
       " array([[0.48370659, 0.48583981],\n",
       "        [0.66547449, 0.65247853],\n",
       "        [0.24167327, 0.24286317],\n",
       "        [0.60025152, 0.652135  ]]),\n",
       " array([[0.45      , 0.3789577 ],\n",
       "        [0.62354153, 0.5553291 ],\n",
       "        [0.22482909, 0.18937885],\n",
       "        [0.60854441, 0.53143644]]),\n",
       " array([[0.47697158, 0.46994482],\n",
       "        [0.6442414 , 0.64175369],\n",
       "        [0.24277111, 0.23888687],\n",
       "        [0.63608514, 0.63548538]]),\n",
       " array([[0.34734063, 0.46092356],\n",
       "        [0.52776838, 0.62858687],\n",
       "        [0.17327955, 0.22973488],\n",
       "        [0.35155106, 0.42833901]]),\n",
       " array([[0.47609171, 0.48643023],\n",
       "        [0.65062481, 0.68373461],\n",
       "        [0.23793398, 0.24246094],\n",
       "        [0.58850125, 0.36999777]]),\n",
       " array([[0.43614573, 0.44700561],\n",
       "        [0.658418  , 0.62865463],\n",
       "        [0.23222653, 0.22309897],\n",
       "        [0.26734349, 0.48534154]]),\n",
       " array([[0.47047595, 0.46414094],\n",
       "        [0.66583991, 0.64358291],\n",
       "        [0.24281604, 0.23279465],\n",
       "        [0.44766164, 0.51727433]]),\n",
       " array([[0.47236055, 0.42520764],\n",
       "        [0.64352089, 0.60044488],\n",
       "        [0.24332544, 0.21250234],\n",
       "        [0.61201475, 0.57748142]]),\n",
       " array([[0.4803605 , 0.48251433],\n",
       "        [0.6475385 , 0.65305104],\n",
       "        [0.24112382, 0.2429006 ],\n",
       "        [0.62927515, 0.63039349]]),\n",
       " array([[0.42708705, 0.47180932],\n",
       "        [0.62143879, 0.64540447],\n",
       "        [0.22591651, 0.23568375],\n",
       "        [0.27667452, 0.59676049]]),\n",
       " array([[0.45147726, 0.45140052],\n",
       "        [0.64297425, 0.63573142],\n",
       "        [0.2446662 , 0.2249061 ],\n",
       "        [0.38314938, 0.46777693]]),\n",
       " array([[0.44258752, 0.42833449],\n",
       "        [0.62706675, 0.6062719 ],\n",
       "        [0.22108889, 0.21359784],\n",
       "        [0.52941176, 0.50517496]]),\n",
       " array([[0.4752061 , 0.4711907 ],\n",
       "        [0.64958445, 0.64525919],\n",
       "        [0.24253604, 0.23547353],\n",
       "        [0.62100543, 0.63103434]]),\n",
       " array([[0.48904982, 0.47724459],\n",
       "        [0.67176016, 0.6509947 ],\n",
       "        [0.24430751, 0.23829052],\n",
       "        [0.55471341, 0.54698187]]),\n",
       " array([[0.48611534, 0.47960354],\n",
       "        [0.65830238, 0.65512322],\n",
       "        [0.24332775, 0.23967478],\n",
       "        [0.59131679, 0.62771375]]),\n",
       " array([[0.46091398, 0.41118813],\n",
       "        [0.63406218, 0.59322086],\n",
       "        [0.24252697, 0.20535748],\n",
       "        [0.56606733, 0.54832079]]),\n",
       " array([[0.47782241, 0.4671175 ],\n",
       "        [0.64985355, 0.64112307],\n",
       "        [0.23874409, 0.23918788],\n",
       "        [0.62133962, 0.60307759]]),\n",
       " array([[0.40138481, 0.47482461],\n",
       "        [0.56856684, 0.65641228],\n",
       "        [0.200535  , 0.23693723],\n",
       "        [0.54400682, 0.59369635]]),\n",
       " array([[0.47240538, 0.48750765],\n",
       "        [0.64357793, 0.6595874 ],\n",
       "        [0.23578008, 0.2435443 ],\n",
       "        [0.60237215, 0.63107095]]),\n",
       " array([[0.45408285, 0.42551101],\n",
       "        [0.62983182, 0.60409052],\n",
       "        [0.22693143, 0.21261437],\n",
       "        [0.61703852, 0.594372  ]]),\n",
       " array([[0.4779918 , 0.47312928],\n",
       "        [0.64463409, 0.64243169],\n",
       "        [0.24523061, 0.23643274],\n",
       "        [0.63862373, 0.63923882]]),\n",
       " array([[0.42768834, 0.47403545],\n",
       "        [0.60438663, 0.64890944],\n",
       "        [0.21366606, 0.23821694],\n",
       "        [0.54615669, 0.61366836]]),\n",
       " array([[0.47761628, 0.4767836 ],\n",
       "        [0.64632743, 0.64586059],\n",
       "        [0.23861433, 0.23869329],\n",
       "        [0.61998329, 0.64010624]]),\n",
       " array([[0.36325397, 0.45201238],\n",
       "        [0.53452171, 0.62657359],\n",
       "        [0.18148905, 0.22581908],\n",
       "        [0.50449819, 0.59917921]]),\n",
       " array([[0.48434343, 0.48717273],\n",
       "        [0.65118489, 0.65691177],\n",
       "        [0.24207161, 0.24396076],\n",
       "        [0.636521  , 0.6360488 ]]),\n",
       " array([[0.48332219, 0.46661516],\n",
       "        [0.66059186, 0.63406548],\n",
       "        [0.24168196, 0.23317753],\n",
       "        [0.60897915, 0.61901551]]),\n",
       " array([[0.47332543, 0.47177732],\n",
       "        [0.64967746, 0.64371907],\n",
       "        [0.24528804, 0.23565874],\n",
       "        [0.60790125, 0.62276738]]),\n",
       " array([[0.4597456 , 0.44132599],\n",
       "        [0.66596217, 0.61491921],\n",
       "        [0.22999692, 0.21993788],\n",
       "        [0.38712218, 0.49118878]]),\n",
       " array([[0.48566323, 0.47506483],\n",
       "        [0.65613169, 0.640567  ],\n",
       "        [0.24578126, 0.24225736],\n",
       "        [0.63677512, 0.63493968]]),\n",
       " array([[0.38346453, 0.33220155],\n",
       "        [0.55274023, 0.50144049],\n",
       "        [0.19151689, 0.16602173],\n",
       "        [0.53311941, 0.48800295]]),\n",
       " array([[0.48043728, 0.4784264 ],\n",
       "        [0.64171194, 0.64421721],\n",
       "        [0.24085704, 0.24050691],\n",
       "        [0.64127911, 0.63377407]]),\n",
       " array([[0.45678781, 0.48010125],\n",
       "        [0.62560579, 0.68308801],\n",
       "        [0.22827718, 0.23948705],\n",
       "        [0.60004101, 0.59649123]]),\n",
       " array([[0.47603267, 0.47850143],\n",
       "        [0.65433332, 0.66474743],\n",
       "        [0.23762033, 0.23907146],\n",
       "        [0.60613898, 0.62802631]]),\n",
       " array([[0.45741352, 0.47148084],\n",
       "        [0.6212377 , 0.66090393],\n",
       "        [0.22857704, 0.23560376],\n",
       "        [0.58840396, 0.59925585]]),\n",
       " array([[0.48663893, 0.47967564],\n",
       "        [0.65019055, 0.66791445],\n",
       "        [0.24460958, 0.24287637],\n",
       "        [0.60300136, 0.61589825]]),\n",
       " array([[0.41627827, 0.4432903 ],\n",
       "        [0.59927932, 0.61880064],\n",
       "        [0.20764527, 0.22119888],\n",
       "        [0.44066454, 0.48397365]]),\n",
       " array([[0.46960692, 0.47969997],\n",
       "        [0.64730394, 0.66217192],\n",
       "        [0.23452206, 0.24122087],\n",
       "        [0.57809376, 0.60093999]]),\n",
       " array([[0.46601041, 0.37025964],\n",
       "        [0.63701539, 0.53821301],\n",
       "        [0.23286445, 0.18493929],\n",
       "        [0.6218406 , 0.53764424]]),\n",
       " array([[0.48054061, 0.46813396],\n",
       "        [0.64814865, 0.6354648 ],\n",
       "        [0.24010918, 0.2389109 ],\n",
       "        [0.63701101, 0.63196708]]),\n",
       " array([[0.37202115, 0.38610131],\n",
       "        [0.5423769 , 0.55580235],\n",
       "        [0.18590144, 0.19292953],\n",
       "        [0.5265339 , 0.54685815]]),\n",
       " array([[0.47595635, 0.47066715],\n",
       "        [0.64635452, 0.64281222],\n",
       "        [0.2416024 , 0.24029824],\n",
       "        [0.61888513, 0.62931184]]),\n",
       " array([[0.43780927, 0.46574838],\n",
       "        [0.6252705 , 0.64980557],\n",
       "        [0.21866637, 0.23261731],\n",
       "        [0.46642305, 0.56622795]]),\n",
       " array([[0.46803827, 0.48187053],\n",
       "        [0.6486537 , 0.6657259 ],\n",
       "        [0.23375333, 0.24078024],\n",
       "        [0.578528  , 0.58966766]]),\n",
       " array([[0.46795669, 0.48546825],\n",
       "        [0.64517563, 0.65953529],\n",
       "        [0.23369739, 0.24500674],\n",
       "        [0.56811254, 0.64467798]]),\n",
       " array([[0.48224647, 0.46962165],\n",
       "        [0.65404117, 0.64332811],\n",
       "        [0.24343031, 0.23553448],\n",
       "        [0.61556141, 0.63351882]]),\n",
       " array([[0.46393918, 0.41936143],\n",
       "        [0.63697999, 0.60358075],\n",
       "        [0.23175148, 0.2092095 ],\n",
       "        [0.58993955, 0.48561034]]),\n",
       " array([[0.47708465, 0.48219389],\n",
       "        [0.64627554, 0.65656388],\n",
       "        [0.23991824, 0.24102434],\n",
       "        [0.60385848, 0.59984959]]),\n",
       " array([[0.44757739, 0.43676109],\n",
       "        [0.61435251, 0.60577214],\n",
       "        [0.22367511, 0.21823336],\n",
       "        [0.60503767, 0.60143681]]),\n",
       " array([[0.47347856, 0.4738478 ],\n",
       "        [0.64049406, 0.64320649],\n",
       "        [0.23659306, 0.23728166],\n",
       "        [0.6271066 , 0.63535809]]),\n",
       " array([[0.38173867, 0.30040489],\n",
       "        [0.54536961, 0.46122617],\n",
       "        [0.19068124, 0.15011279],\n",
       "        [0.5346308 , 0.44239603]]),\n",
       " array([[0.46890486, 0.46188043],\n",
       "        [0.65685197, 0.63442333],\n",
       "        [0.24068186, 0.23048866],\n",
       "        [0.61453119, 0.60555056]]),\n",
       " array([[0.48493484, 0.47726341],\n",
       "        [0.66492372, 0.67020007],\n",
       "        [0.24169617, 0.23828459],\n",
       "        [0.62261918, 0.53335052]]),\n",
       " array([[0.47953193, 0.47372534],\n",
       "        [0.65069641, 0.65834043],\n",
       "        [0.23962427, 0.23671807],\n",
       "        [0.6325882 , 0.60924364]]),\n",
       " array([[0.44731227, 0.46707932],\n",
       "        [0.63806349, 0.65089212],\n",
       "        [0.22347409, 0.23335363],\n",
       "        [0.51180095, 0.60174236]]),\n",
       " array([[0.47949239, 0.47529157],\n",
       "        [0.66817229, 0.65216674],\n",
       "        [0.24044713, 0.24199664],\n",
       "        [0.61302993, 0.63317227]]),\n",
       " array([[0.4795406 , 0.45653109],\n",
       "        [0.65163318, 0.62371767],\n",
       "        [0.23964077, 0.22808772],\n",
       "        [0.64297168, 0.62636994]]),\n",
       " array([[0.48560681, 0.48164545],\n",
       "        [0.65820475, 0.64939387],\n",
       "        [0.24646556, 0.24059475],\n",
       "        [0.6477921 , 0.64886262]]),\n",
       " array([[0.45996843, 0.33777311],\n",
       "        [0.64597745, 0.51339103],\n",
       "        [0.24250803, 0.16869053],\n",
       "        [0.49637309, 0.42512419]]),\n",
       " array([[0.47410155, 0.45921626],\n",
       "        [0.65597074, 0.63577344],\n",
       "        [0.23734105, 0.22913669],\n",
       "        [0.58723545, 0.52236652]]),\n",
       " array([[0.47667117, 0.4701952 ],\n",
       "        [0.64165175, 0.64937642],\n",
       "        [0.23816748, 0.23449501],\n",
       "        [0.59846981, 0.57419346]]),\n",
       " array([[0.47958148, 0.47992844],\n",
       "        [0.6555241 , 0.65665672],\n",
       "        [0.24465749, 0.23984915],\n",
       "        [0.61413742, 0.60105467]]),\n",
       " array([[0.41238833, 0.47350208],\n",
       "        [0.58412306, 0.64881049],\n",
       "        [0.20611128, 0.24224073],\n",
       "        [0.57722448, 0.63730122]]),\n",
       " array([[0.47425539, 0.48330348],\n",
       "        [0.64336566, 0.65263893],\n",
       "        [0.24139579, 0.24155993],\n",
       "        [0.63735562, 0.64345706]]),\n",
       " array([[0.46896394, 0.44978178],\n",
       "        [0.65627815, 0.64013538],\n",
       "        [0.23916958, 0.22433886],\n",
       "        [0.52481452, 0.47793451]]),\n",
       " array([[0.47561329, 0.48337691],\n",
       "        [0.63991414, 0.66095346],\n",
       "        [0.2387924 , 0.2415548 ],\n",
       "        [0.6169638 , 0.62535574]]),\n",
       " array([[0.46483716, 0.37300386],\n",
       "        [0.65637596, 0.56337196],\n",
       "        [0.23477812, 0.18634973],\n",
       "        [0.43480122, 0.43652187]]),\n",
       " array([[0.47315436, 0.45148061],\n",
       "        [0.65853385, 0.63324992],\n",
       "        [0.240959  , 0.22553785],\n",
       "        [0.487802  , 0.49752032]]),\n",
       " array([[0.47760243, 0.36097973],\n",
       "        [0.64682473, 0.52917324],\n",
       "        [0.23864936, 0.18041796],\n",
       "        [0.62445092, 0.50064425]]),\n",
       " array([[0.48939873, 0.4844581 ],\n",
       "        [0.67225596, 0.67238458],\n",
       "        [0.2480291 , 0.24133053],\n",
       "        [0.58902637, 0.60537964]]),\n",
       " array([[0.41388269, 0.44730089],\n",
       "        [0.58776717, 0.62678996],\n",
       "        [0.20671337, 0.22347012],\n",
       "        [0.54704372, 0.55207715]]),\n",
       " array([[0.47479061, 0.47691995],\n",
       "        [0.64721597, 0.65167636],\n",
       "        [0.23863471, 0.23835581],\n",
       "        [0.62022502, 0.62870611]]),\n",
       " array([[0.47249015, 0.46317026],\n",
       "        [0.65184576, 0.64162097],\n",
       "        [0.23577939, 0.23777778],\n",
       "        [0.52481452, 0.45265798]]),\n",
       " array([[0.47788809, 0.48528527],\n",
       "        [0.65727797, 0.66618501],\n",
       "        [0.24707101, 0.24341474],\n",
       "        [0.6056455 , 0.53484046]]),\n",
       " array([[0.43969446, 0.39526557],\n",
       "        [0.61539825, 0.56827954],\n",
       "        [0.21962066, 0.19753875],\n",
       "        [0.578528  , 0.53647382]]),\n",
       " array([[0.48231741, 0.48126883],\n",
       "        [0.66728576, 0.65432905],\n",
       "        [0.24247801, 0.24345105],\n",
       "        [0.61881061, 0.59739477]]),\n",
       " array([[0.40553766, 0.40937383],\n",
       "        [0.57683384, 0.5772843 ],\n",
       "        [0.20265382, 0.20442704],\n",
       "        [0.5494107 , 0.55634349]]),\n",
       " array([[0.46707138, 0.48325252],\n",
       "        [0.65256939, 0.65150773],\n",
       "        [0.23245778, 0.2414796 ],\n",
       "        [0.60703014, 0.63319051]]),\n",
       " array([[0.46772458, 0.46936617],\n",
       "        [0.64461024, 0.64774574],\n",
       "        [0.23357075, 0.23439072],\n",
       "        [0.53095187, 0.62953198]]),\n",
       " array([[0.48102435, 0.47613151],\n",
       "        [0.66427847, 0.64868836],\n",
       "        [0.24314096, 0.23785814],\n",
       "        [0.56757173, 0.63535809]]),\n",
       " array([[0.40920044, 0.30607311],\n",
       "        [0.57752565, 0.46097149],\n",
       "        [0.20442981, 0.15289453],\n",
       "        [0.57613638, 0.46644602]]),\n",
       " array([[0.48071809, 0.48676175],\n",
       "        [0.67339992, 0.64996317],\n",
       "        [0.22030705, 0.24339839],\n",
       "        [0.58106891, 0.65101635]]),\n",
       " array([[0.46998886, 0.38757492],\n",
       "        [0.63951726, 0.55422036],\n",
       "        [0.23639938, 0.19363744],\n",
       "        [0.61595437, 0.54421382]]),\n",
       " array([[0.47479459, 0.47999088],\n",
       "        [0.65326683, 0.64571827],\n",
       "        [0.24246865, 0.23981223],\n",
       "        [0.54768253, 0.62271181]]),\n",
       " array([[0.41892663, 0.46594926],\n",
       "        [0.60115286, 0.64127997],\n",
       "        [0.20903334, 0.24131733],\n",
       "        [0.57272284, 0.63335469]]),\n",
       " array([[0.4795845 , 0.4731821 ],\n",
       "        [0.6539373 , 0.64337844],\n",
       "        [0.24466365, 0.243743  ],\n",
       "        [0.63844272, 0.6410988 ]]),\n",
       " array([[0.34413391, 0.38      ],\n",
       "        [0.51264071, 0.5480343 ],\n",
       "        [0.17196665, 0.18977799],\n",
       "        [0.48303038, 0.53695475]]),\n",
       " array([[0.48867785, 0.48958994],\n",
       "        [0.68910885, 0.65637876],\n",
       "        [0.24086194, 0.24596597],\n",
       "        [0.61033832, 0.64896958]]),\n",
       " array([[0.28160824, 0.38503273],\n",
       "        [0.43989712, 0.55714517],\n",
       "        [0.14074106, 0.19226366],\n",
       "        [0.4175797 , 0.5023547 ]]),\n",
       " array([[0.47644231, 0.48268904],\n",
       "        [0.64507273, 0.65452345],\n",
       "        [0.24100675, 0.24190125],\n",
       "        [0.61608531, 0.57290186]]),\n",
       " array([[0.47617251, 0.44008102],\n",
       "        [0.65828432, 0.61163191],\n",
       "        [0.2374966 , 0.21993732],\n",
       "        [0.61475609, 0.60829856]]),\n",
       " array([[0.48522576, 0.48717388],\n",
       "        [0.66826703, 0.66807559],\n",
       "        [0.24201867, 0.24307074],\n",
       "        [0.62705138, 0.64727407]]),\n",
       " array([[0.44628137, 0.40218741],\n",
       "        [0.63481206, 0.59306076],\n",
       "        [0.22274155, 0.20089002],\n",
       "        [0.31979654, 0.41989939]]),\n",
       " array([[0.45323759, 0.47888291],\n",
       "        [0.65043517, 0.65609959],\n",
       "        [0.22499682, 0.24372646],\n",
       "        [0.49635101, 0.64552056]]),\n",
       " array([[0.43799217, 0.43306589],\n",
       "        [0.61288955, 0.6052588 ],\n",
       "        [0.21886865, 0.21643709],\n",
       "        [0.59518191, 0.59944744]]),\n",
       " array([[0.47777686, 0.46942168],\n",
       "        [0.64901419, 0.64080188],\n",
       "        [0.23916038, 0.23458989],\n",
       "        [0.6208197 , 0.63317227]]),\n",
       " array([[0.44303213, 0.46035589],\n",
       "        [0.61516799, 0.63192737],\n",
       "        [0.22139608, 0.23003658],\n",
       "        [0.60229584, 0.62708819]]),\n",
       " array([[0.47632549, 0.46836116],\n",
       "        [0.64448951, 0.63605251],\n",
       "        [0.23790743, 0.23398075],\n",
       "        [0.62955032, 0.63446639]]),\n",
       " array([[0.47768852, 0.43013905],\n",
       "        [0.64993849, 0.61264056],\n",
       "        [0.23864103, 0.215155  ],\n",
       "        [0.61464365, 0.57262336]]),\n",
       " array([[0.45416667, 0.47549538],\n",
       "        [0.64099254, 0.65576608],\n",
       "        [0.23787567, 0.23901882],\n",
       "        [0.50456371, 0.58902637]]),\n",
       " array([[0.45012057, 0.45027558],\n",
       "        [0.627477  , 0.61771958],\n",
       "        [0.22481184, 0.22496896],\n",
       "        [0.58717698, 0.61148777]]),\n",
       " array([[0.46706471, 0.48327528],\n",
       "        [0.64361545, 0.65259922],\n",
       "        [0.23340261, 0.24294022],\n",
       "        [0.5977405 , 0.64575343]]),\n",
       " array([[0.46112275, 0.46148724],\n",
       "        [0.63151553, 0.63716326],\n",
       "        [0.23039189, 0.23055622],\n",
       "        [0.6013604 , 0.57758022]]),\n",
       " array([[0.48376438, 0.4749823 ],\n",
       "        [0.65466891, 0.64506651],\n",
       "        [0.24177439, 0.23724359],\n",
       "        [0.62863265, 0.64100863]]),\n",
       " array([[0.43305675, 0.38046387],\n",
       "        [0.6004683 , 0.54951684],\n",
       "        [0.21632567, 0.19011625],\n",
       "        [0.57722448, 0.53643198]]),\n",
       " array([[0.4762032 , 0.47779504],\n",
       "        [0.64004972, 0.63779674],\n",
       "        [0.23793178, 0.2385479 ],\n",
       "        [0.62315625, 0.63815299]]),\n",
       " array([[0.39801952, 0.39824867],\n",
       "        [0.56880761, 0.56917153],\n",
       "        [0.19884497, 0.19900786],\n",
       "        [0.54654876, 0.56385515]]),\n",
       " array([[0.48228201, 0.4713812 ],\n",
       "        [0.64461134, 0.63776437],\n",
       "        [0.2408231 , 0.23542636],\n",
       "        [0.62951364, 0.63617597]]),\n",
       " array([[0.35907077, 0.44114387],\n",
       "        [0.52449234, 0.61370841],\n",
       "        [0.17936513, 0.22039928],\n",
       "        [0.51307593, 0.59125865]]),\n",
       " array([[0.48994146, 0.48771019],\n",
       "        [0.67482398, 0.65334663],\n",
       "        [0.24386813, 0.24477135],\n",
       "        [0.63412031, 0.64171166]]),\n",
       " array([[0.47718978, 0.39579374],\n",
       "        [0.65722283, 0.57033318],\n",
       "        [0.23804918, 0.19779338],\n",
       "        [0.62016924, 0.53597163]]),\n",
       " array([[0.4746167 , 0.47291012],\n",
       "        [0.6427467 , 0.65340672],\n",
       "        [0.23710804, 0.24383662],\n",
       "        [0.6251158 , 0.60034718]]),\n",
       " array([[0.4068526 , 0.33801834],\n",
       "        [0.58359052, 0.50568165],\n",
       "        [0.20331078, 0.16888772],\n",
       "        [0.56268598, 0.49754237]]),\n",
       " array([[0.47800267, 0.47766582],\n",
       "        [0.64722936, 0.64774346],\n",
       "        [0.24180293, 0.24293547],\n",
       "        [0.62622251, 0.63978109]]),\n",
       " array([[0.48647854, 0.4476791 ],\n",
       "        [0.62857763, 0.61995819],\n",
       "        [0.24313864, 0.22362958],\n",
       "        [0.62310071, 0.60530366]]),\n",
       " array([[0.47768793, 0.48822966],\n",
       "        [0.63447233, 0.65270036],\n",
       "        [0.23745172, 0.24447957],\n",
       "        [0.4628779 , 0.64668411]]),\n",
       " array([[0.47511377, 0.4612889 ],\n",
       "        [0.64364937, 0.62680962],\n",
       "        [0.23735099, 0.23052894],\n",
       "        [0.6271066 , 0.62057817]]),\n",
       " array([[0.4674567 , 0.47191011],\n",
       "        [0.64374878, 0.63965679],\n",
       "        [0.24153061, 0.23578009],\n",
       "        [0.62282294, 0.63568535]]),\n",
       " array([[0.47001229, 0.44854516],\n",
       "        [0.64394181, 0.63170134],\n",
       "        [0.23486533, 0.22409161],\n",
       "        [0.60414395, 0.56385515]]),\n",
       " array([[0.46945953, 0.46205209],\n",
       "        [0.67410948, 0.64827471],\n",
       "        [0.23481609, 0.23474049],\n",
       "        [0.52351703, 0.54918462]]),\n",
       " array([[0.46382959, 0.44105188],\n",
       "        [0.63592021, 0.6186534 ],\n",
       "        [0.23171533, 0.22021556],\n",
       "        [0.56859292, 0.53154174]]),\n",
       " array([[0.46977299, 0.4647004 ],\n",
       "        [0.64379319, 0.64190593],\n",
       "        [0.2409095 , 0.24203031],\n",
       "        [0.53952135, 0.58935681]]),\n",
       " array([[0.43235924, 0.39025171],\n",
       "        [0.59784826, 0.56356912],\n",
       "        [0.21604539, 0.19494414],\n",
       "        [0.5894151 , 0.55170853]]),\n",
       " array([[0.46721446, 0.48154857],\n",
       "        [0.64038774, 0.65432466],\n",
       "        [0.23316474, 0.24180752],\n",
       "        [0.61729995, 0.64010624]]),\n",
       " array([[0.4777372 , 0.46061823],\n",
       "        [0.65410872, 0.63728568],\n",
       "        [0.23861941, 0.23004159],\n",
       "        [0.62518964, 0.58367911]]),\n",
       " array([[0.48276748, 0.47005976],\n",
       "        [0.65934241, 0.64166971],\n",
       "        [0.24106552, 0.24330068],\n",
       "        [0.5573401 , 0.61644058]]),\n",
       " array([[0.39941298, 0.45874302],\n",
       "        [0.57380552, 0.62618779],\n",
       "        [0.19958142, 0.22923332],\n",
       "        [0.56462013, 0.62601975]]),\n",
       " array([[0.47494835, 0.47594312],\n",
       "        [0.64378619, 0.66260621],\n",
       "        [0.23733787, 0.24332542],\n",
       "        [0.63661177, 0.64005206]]),\n",
       " array([[0.4710094 , 0.35156321],\n",
       "        [0.65620649, 0.52524427],\n",
       "        [0.23444914, 0.17561851],\n",
       "        [0.50800635, 0.4631086 ]]),\n",
       " array([[0.46777352, 0.48493599],\n",
       "        [0.64014482, 0.65134255],\n",
       "        [0.24388395, 0.24224762],\n",
       "        [0.60973457, 0.63856943]]),\n",
       " array([[0.45744543, 0.46392355],\n",
       "        [0.6530537 , 0.63817451],\n",
       "        [0.2308873 , 0.23178414],\n",
       "        [0.42906235, 0.60555056]]),\n",
       " array([[0.47257182, 0.47657506],\n",
       "        [0.66790191, 0.64425192],\n",
       "        [0.23924544, 0.24204157],\n",
       "        [0.52708495, 0.63324524]]),\n",
       " array([[0.48143503, 0.4760728 ],\n",
       "        [0.64207501, 0.65240412],\n",
       "        [0.24053752, 0.23790448],\n",
       "        [0.62764018, 0.64324138]]),\n",
       " array([[0.48452694, 0.47494703],\n",
       "        [0.66419096, 0.65528909],\n",
       "        [0.24218   , 0.2419795 ],\n",
       "        [0.49723368, 0.6420719 ]]),\n",
       " array([[0.47230125, 0.45860861],\n",
       "        [0.63667839, 0.63174342],\n",
       "        [0.23765328, 0.22922619],\n",
       "        [0.63523077, 0.62080112]]),\n",
       " array([[0.47974699, 0.48159184],\n",
       "        [0.64664748, 0.65330417],\n",
       "        [0.24287648, 0.24060182],\n",
       "        [0.63907606, 0.63097944]]),\n",
       " array([[0.46896394, 0.44978178],\n",
       "        [0.65627815, 0.64013538],\n",
       "        [0.23709428, 0.2243601 ],\n",
       "        [0.52481452, 0.47793451]]),\n",
       " array([[0.48619342, 0.48186933],\n",
       "        [0.66604522, 0.65201567],\n",
       "        [0.24278993, 0.24305586],\n",
       "        [0.60395365, 0.62859592]]),\n",
       " array([[0.41314469, 0.43812716],\n",
       "        [0.58414437, 0.61086239],\n",
       "        [0.2064685 , 0.21892457],\n",
       "        [0.57355789, 0.59785571]]),\n",
       " array([[0.48087432, 0.48035038],\n",
       "        [0.64819856, 0.64822555],\n",
       "        [0.24141484, 0.24085346],\n",
       "        [0.64349301, 0.64457034]]),\n",
       " array([[0.47276993, 0.45203055],\n",
       "        [0.64501831, 0.62392599],\n",
       "        [0.23608916, 0.22590121],\n",
       "        [0.58022295, 0.61488726]]),\n",
       " array([[0.47045501, 0.47880126],\n",
       "        [0.63869806, 0.64686602],\n",
       "        [0.23957439, 0.23924743],\n",
       "        [0.62100543, 0.63969074]]),\n",
       " array([[0.48700173, 0.39872751],\n",
       "        [0.66314129, 0.57350714],\n",
       "        [0.24733416, 0.19892462],\n",
       "        [0.58690402, 0.50776719]]),\n",
       " array([[0.46307616, 0.46555073],\n",
       "        [0.65650805, 0.64806411],\n",
       "        [0.23268996, 0.2324495 ],\n",
       "        [0.53636922, 0.56453964]]),\n",
       " array([[0.48061212, 0.48000167],\n",
       "        [0.66710735, 0.66945874],\n",
       "        [0.24015404, 0.24240838],\n",
       "        [0.61447495, 0.62028079]]),\n",
       " array([[0.48069613, 0.48049534],\n",
       "        [0.67101394, 0.66768231],\n",
       "        [0.2406058 , 0.24220504],\n",
       "        [0.58156028, 0.62011346]]),\n",
       " array([[0.4198776 , 0.44484645],\n",
       "        [0.59046514, 0.61883303],\n",
       "        [0.20977148, 0.22233558],\n",
       "        [0.57890281, 0.58461879]]),\n",
       " array([[0.47851807, 0.48641656],\n",
       "        [0.64571584, 0.65043662],\n",
       "        [0.24072445, 0.24309486],\n",
       "        [0.63286204, 0.63945578]]),\n",
       " array([[0.28160824, 0.38503273],\n",
       "        [0.43989712, 0.55714517],\n",
       "        [0.14071522, 0.19218753],\n",
       "        [0.4175797 , 0.5023547 ]]),\n",
       " array([[0.47870528, 0.47292214],\n",
       "        [0.64400306, 0.6384733 ],\n",
       "        [0.24317218, 0.23789872],\n",
       "        [0.62923845, 0.62708819]]),\n",
       " array([[0.43324392, 0.48348118],\n",
       "        [0.61418373, 0.64457032],\n",
       "        [0.21631317, 0.24162041],\n",
       "        [0.52898925, 0.62003908]]),\n",
       " array([[0.47098527, 0.48347834],\n",
       "        [0.65564754, 0.65705771],\n",
       "        [0.23529096, 0.24138845],\n",
       "        [0.61210881, 0.61175131]]),\n",
       " array([[0.46522015, 0.41703701],\n",
       "        [0.64438024, 0.58962129],\n",
       "        [0.23245549, 0.2084126 ],\n",
       "        [0.57220541, 0.57470944]]),\n",
       " array([[0.48226542, 0.48057979],\n",
       "        [0.67159901, 0.65414295],\n",
       "        [0.24466688, 0.24561324],\n",
       "        [0.56373429, 0.63169288]]),\n",
       " array([[0.47733565, 0.43456356],\n",
       "        [0.64460647, 0.60326385],\n",
       "        [0.24234632, 0.21712147],\n",
       "        [0.64075608, 0.60099734]]),\n",
       " array([[0.47536485, 0.47229982],\n",
       "        [0.66177651, 0.64005012],\n",
       "        [0.24315141, 0.24262623],\n",
       "        [0.63575806, 0.63842461]]),\n",
       " array([[0.43677571, 0.3496234 ],\n",
       "        [0.6249672 , 0.53422399],\n",
       "        [0.21793157, 0.17460647],\n",
       "        [0.37743622, 0.47335073]]),\n",
       " array([[0.4840049 , 0.48145069],\n",
       "        [0.66273215, 0.65243052],\n",
       "        [0.24363251, 0.24104705],\n",
       "        [0.64693446, 0.6440678 ]]),\n",
       " array([[0.47051359, 0.38533289],\n",
       "        [0.66415893, 0.55936691],\n",
       "        [0.23504016, 0.19241432],\n",
       "        [0.56143407, 0.53274108]]),\n",
       " array([[0.47941115, 0.47951762],\n",
       "        [0.66333004, 0.65452315],\n",
       "        [0.2417205 , 0.23945947],\n",
       "        [0.58330682, 0.61888513]]),\n",
       " array([[0.45569252, 0.44521241],\n",
       "        [0.63771266, 0.6124058 ],\n",
       "        [0.22732844, 0.22237596],\n",
       "        [0.53672478, 0.58422741]]),\n",
       " array([[0.46443075, 0.47999349],\n",
       "        [0.65279008, 0.64451664],\n",
       "        [0.23173317, 0.24289962],\n",
       "        [0.55975471, 0.63116244]]),\n",
       " array([[0.33785147, 0.44013248],\n",
       "        [0.50932416, 0.61444732],\n",
       "        [0.16884964, 0.21993321],\n",
       "        [0.4625548 , 0.58424698]]),\n",
       " array([[0.47598901, 0.47091272],\n",
       "        [0.64484297, 0.64412395],\n",
       "        [0.24130575, 0.24174314],\n",
       "        [0.59423692, 0.62245241]]),\n",
       " array([[0.46715304, 0.41059223],\n",
       "        [0.67536697, 0.58906112],\n",
       "        [0.23296653, 0.20513844],\n",
       "        [0.41038219, 0.5484031 ]]),\n",
       " array([[0.46940058, 0.47749288],\n",
       "        [0.66435358, 0.65141588],\n",
       "        [0.24256221, 0.23860555],\n",
       "        [0.53440009, 0.62852245]]),\n",
       " array([[0.33611523, 0.45332378],\n",
       "        [0.49783299, 0.62456256],\n",
       "        [0.16794896, 0.22643356],\n",
       "        [0.48321014, 0.57937598]]),\n",
       " array([[0.46704689, 0.48316355],\n",
       "        [0.63701057, 0.65074071],\n",
       "        [0.23312865, 0.24151728],\n",
       "        [0.60319192, 0.62758501]]),\n",
       " array([[0.4344865 , 0.40496133],\n",
       "        [0.61151954, 0.5807805 ],\n",
       "        [0.2170804 , 0.20234722],\n",
       "        [0.59392808, 0.56602717]]),\n",
       " array([[0.47820119, 0.48380018],\n",
       "        [0.64315769, 0.65620349],\n",
       "        [0.24340684, 0.24552719],\n",
       "        [0.63269775, 0.64280981]]),\n",
       " array([[0.48243268, 0.47584764],\n",
       "        [0.65959549, 0.65319753],\n",
       "        [0.24087426, 0.23776784],\n",
       "        [0.58725494, 0.59365773]]),\n",
       " array([[0.47521916, 0.46362457],\n",
       "        [0.65513176, 0.64446115],\n",
       "        [0.24402126, 0.23154347],\n",
       "        [0.60539863, 0.59026956]]),\n",
       " array([[0.47520947, 0.44000886],\n",
       "        [0.67943639, 0.61465619],\n",
       "        [0.23995922, 0.21979774],\n",
       "        [0.41045622, 0.55900481]]),\n",
       " array([[0.4703708 , 0.47916577],\n",
       "        [0.66401287, 0.65651305],\n",
       "        [0.23444871, 0.23931746],\n",
       "        [0.47696106, 0.58008514]]),\n",
       " array([[0.47339679, 0.44771077],\n",
       "        [0.65377393, 0.64919207],\n",
       "        [0.23905692, 0.23294035],\n",
       "        [0.59311671, 0.29557749]]),\n",
       " array([[0.46590858, 0.49140664],\n",
       "        [0.65594137, 0.67030701],\n",
       "        [0.23211039, 0.24532541],\n",
       "        [0.57886337, 0.42831489]]),\n",
       " array([[0.46144805, 0.35525583],\n",
       "        [0.63096992, 0.52492651],\n",
       "        [0.23059237, 0.1774926 ],\n",
       "        [0.63021028, 0.51718845]]),\n",
       " array([[0.48265351, 0.47763345],\n",
       "        [0.65605408, 0.64758311],\n",
       "        [0.24397923, 0.23868271],\n",
       "        [0.63952809, 0.64181975]]),\n",
       " array([[0.48062079, 0.47206816],\n",
       "        [0.66341766, 0.64852032],\n",
       "        [0.23954819, 0.23549321],\n",
       "        [0.62984372, 0.62901822]]),\n",
       " array([[0.47982128, 0.470164  ],\n",
       "        [0.64743985, 0.63927247],\n",
       "        [0.24055665, 0.23945049],\n",
       "        [0.62159943, 0.63457564]]),\n",
       " array([[0.46831939, 0.44741462],\n",
       "        [0.63763047, 0.61903936],\n",
       "        [0.23403232, 0.2235424 ],\n",
       "        [0.62953198, 0.58966766]]),\n",
       " array([[0.49008819, 0.47848183],\n",
       "        [0.65733316, 0.65240465],\n",
       "        [0.24619371, 0.23908231],\n",
       "        [0.65037629, 0.63331821]]),\n",
       " array([[0.43912405, 0.46193022],\n",
       "        [0.63698721, 0.62414695],\n",
       "        [0.21866215, 0.23068637],\n",
       "        [0.54400682, 0.60013671]]),\n",
       " array([[0.47862865, 0.47056698],\n",
       "        [0.65352587, 0.63163285],\n",
       "        [0.24034304, 0.23701762],\n",
       "        [0.60988556, 0.6279344 ]]),\n",
       " array([[0.37561858, 0.39404418],\n",
       "        [0.5543734 , 0.56905418],\n",
       "        [0.18762343, 0.19665324],\n",
       "        [0.47136801, 0.45945539]]),\n",
       " array([[0.48864742, 0.4774809 ],\n",
       "        [0.65962454, 0.64383247],\n",
       "        [0.24772211, 0.23853623],\n",
       "        [0.64017848, 0.60952691]]),\n",
       " array([[0.43768366, 0.45182175],\n",
       "        [0.61676305, 0.62833109],\n",
       "        [0.2185051 , 0.2257435 ],\n",
       "        [0.50462922, 0.54384119]]),\n",
       " array([[0.4727347 , 0.47522029],\n",
       "        [0.65794049, 0.6630456 ],\n",
       "        [0.23604269, 0.24168112],\n",
       "        [0.55528436, 0.53387549]]),\n",
       " array([[0.44892953, 0.41512371],\n",
       "        [0.62676555, 0.58941665],\n",
       "        [0.22423804, 0.20742674],\n",
       "        [0.60382041, 0.56177755]]),\n",
       " array([[0.48441073, 0.47718224],\n",
       "        [0.65298403, 0.65335131],\n",
       "        [0.24202294, 0.23838867],\n",
       "        [0.6255956 , 0.60667002]]),\n",
       " array([[0.36774916, 0.40616987],\n",
       "        [0.55465478, 0.58546571],\n",
       "        [0.18340807, 0.20293347],\n",
       "        [0.48565513, 0.57365723]]),\n",
       " array([[0.47457802, 0.46596105],\n",
       "        [0.64275109, 0.63946443],\n",
       "        [0.24061124, 0.23284808],\n",
       "        [0.61881061, 0.63176601]]),\n",
       " array([[0.4717439 , 0.40025273],\n",
       "        [0.64305028, 0.57344255],\n",
       "        [0.23565556, 0.19998896],\n",
       "        [0.60784447, 0.54795026]]),\n",
       " array([[0.48491361, 0.48201586],\n",
       "        [0.66177608, 0.65560374],\n",
       "        [0.24203011, 0.24149064],\n",
       "        [0.62020643, 0.62287851]]),\n",
       " array([[0.46697421, 0.37415611],\n",
       "        [0.64786005, 0.54618357],\n",
       "        [0.23337386, 0.18683444],\n",
       "        [0.54689939, 0.49763054]]),\n",
       " array([[0.48104043, 0.47247687],\n",
       "        [0.66186208, 0.64516129],\n",
       "        [0.24018027, 0.24266717],\n",
       "        [0.59058001, 0.61513078]]),\n",
       " array([[0.4068526 , 0.33801834],\n",
       "        [0.58359052, 0.50568165],\n",
       "        [0.20330774, 0.1689213 ],\n",
       "        [0.56268598, 0.49754237]]),\n",
       " array([[0.46644601, 0.47875772],\n",
       "        [0.63775303, 0.64549577],\n",
       "        [0.24413807, 0.23970326],\n",
       "        [0.62982538, 0.64234196]]),\n",
       " array([[0.46695425, 0.43848218],\n",
       "        [0.65159046, 0.60731539],\n",
       "        [0.23668168, 0.2188708 ],\n",
       "        [0.36369447, 0.36526181]]),\n",
       " array([[0.45859435, 0.47310138],\n",
       "        [0.65593806, 0.64163569],\n",
       "        [0.22885318, 0.23610589],\n",
       "        [0.49169993, 0.39894931]]),\n",
       " array([[0.47566518, 0.47411423],\n",
       "        [0.65039686, 0.64805369],\n",
       "        [0.23742231, 0.23963455],\n",
       "        [0.6204295 , 0.64082825]]),\n",
       " array([[0.47666386, 0.477486  ],\n",
       "        [0.64119435, 0.65130287],\n",
       "        [0.24282962, 0.23986267],\n",
       "        [0.63348235, 0.64226995]]),\n",
       " array([[0.46973513, 0.43348128],\n",
       "        [0.64448346, 0.61049953],\n",
       "        [0.23464311, 0.21664456],\n",
       "        [0.62228561, 0.60246752]]),\n",
       " array([[0.48886858, 0.47347741],\n",
       "        [0.67516692, 0.6492282 ],\n",
       "        [0.24279271, 0.23658544],\n",
       "        [0.63951001, 0.64010624]]),\n",
       " array([[0.47672403, 0.46164088],\n",
       "        [0.66637404, 0.63713842],\n",
       "        [0.23818182, 0.23054712],\n",
       "        [0.60103556, 0.5634522 ]]),\n",
       " array([[0.48321307, 0.48034274],\n",
       "        [0.67606394, 0.65434421],\n",
       "        [0.24158505, 0.24115306],\n",
       "        [0.61137479, 0.57913944]]),\n",
       " array([[0.45745516, 0.38296233],\n",
       "        [0.62993313, 0.55459323],\n",
       "        [0.22854517, 0.19134084],\n",
       "        [0.60374426, 0.53902126]]),\n",
       " array([[0.4837595 , 0.47825215],\n",
       "        [0.65226924, 0.64712104],\n",
       "        [0.24151855, 0.24261031],\n",
       "        [0.63466667, 0.63575806]]),\n",
       " array([[0.45097713, 0.4285282 ],\n",
       "        [0.66630982, 0.60231365],\n",
       "        [0.22399514, 0.21410636],\n",
       "        [0.34253249, 0.58647488]]),\n",
       " array([[0.48834792, 0.48743257],\n",
       "        [0.64775292, 0.65559497],\n",
       "        [0.24382616, 0.24342905],\n",
       "        [0.61148777, 0.64543098]]),\n",
       " array([[0.44587251, 0.49092638],\n",
       "        [0.63801063, 0.65428902],\n",
       "        [0.222542  , 0.24523522],\n",
       "        [0.48540875, 0.63379229]]),\n",
       " array([[0.47687669, 0.48880839],\n",
       "        [0.64742251, 0.65538762],\n",
       "        [0.2431856 , 0.24577069],\n",
       "        [0.60947027, 0.64106273]]),\n",
       " array([[0.47101594, 0.40832807],\n",
       "        [0.64194708, 0.58097592],\n",
       "        [0.23541135, 0.20407327],\n",
       "        [0.63064991, 0.57542327]]),\n",
       " array([[0.47402091, 0.48293686],\n",
       "        [0.65930869, 0.66387753],\n",
       "        [0.24017332, 0.24354081],\n",
       "        [0.6221373 , 0.64185578]]),\n",
       " array([[0.41328326, 0.45850972],\n",
       "        [0.59148312, 0.63773346],\n",
       "        [0.20634316, 0.22888126],\n",
       "        [0.47020333, 0.56474084]]),\n",
       " array([[0.47550384, 0.46672793],\n",
       "        [0.6542067 , 0.63907796],\n",
       "        [0.23816375, 0.23321691],\n",
       "        [0.60740902, 0.60767411]]),\n",
       " array([[0.43926899, 0.48093119],\n",
       "        [0.61271676, 0.65092724],\n",
       "        [0.21949689, 0.24031038],\n",
       "        [0.58563536, 0.60191418]]),\n",
       " array([[0.48399766, 0.48344497],\n",
       "        [0.66498278, 0.65654327],\n",
       "        [0.24113638, 0.24400422],\n",
       "        [0.622508  , 0.61563628]]),\n",
       " array([[0.46808977, 0.46838943],\n",
       "        [0.64312512, 0.63941015],\n",
       "        [0.23845552, 0.2341025 ],\n",
       "        [0.62890808, 0.6300087 ]]),\n",
       " array([[0.47847012, 0.47804712],\n",
       "        [0.64849969, 0.65647993],\n",
       "        [0.23910513, 0.23842902],\n",
       "        [0.64473179, 0.63508524]]),\n",
       " array([[0.45249828, 0.47649133],\n",
       "        [0.62372985, 0.65055973],\n",
       "        [0.2276285 , 0.23809251],\n",
       "        [0.60000273, 0.63936539]]),\n",
       " array([[0.47214496, 0.47252532],\n",
       "        [0.65207321, 0.64512499],\n",
       "        [0.24068898, 0.23924475],\n",
       "        [0.62154376, 0.63970881]]),\n",
       " array([[0.43404493, 0.4655939 ],\n",
       "        [0.61372609, 0.63273282],\n",
       "        [0.23361959, 0.23264996],\n",
       "        [0.56602717, 0.61670224]]),\n",
       " array([[0.48218858, 0.47528634],\n",
       "        [0.65355877, 0.64105759],\n",
       "        [0.24700615, 0.2393495 ],\n",
       "        [0.59026956, 0.62282294]]),\n",
       " array([[0.47068341, 0.45015673],\n",
       "        [0.65184574, 0.62509665],\n",
       "        [0.23517858, 0.22476901],\n",
       "        [0.60309665, 0.59781731]]),\n",
       " array([[0.47818446, 0.4809417 ],\n",
       "        [0.65143093, 0.65170557],\n",
       "        [0.24194038, 0.2410208 ],\n",
       "        [0.6160666 , 0.63092453]]),\n",
       " array([[0.45874754, 0.41512138],\n",
       "        [0.64789937, 0.5897341 ],\n",
       "        [0.22921954, 0.20743759],\n",
       "        [0.52411288, 0.54375835]]),\n",
       " array([[0.48252164, 0.47532172],\n",
       "        [0.67427785, 0.64924973],\n",
       "        [0.24095632, 0.23740438],\n",
       "        [0.62432156, 0.64244995]]),\n",
       " array([[0.48319473, 0.46732799],\n",
       "        [0.65668876, 0.64062726],\n",
       "        [0.24331597, 0.23335775],\n",
       "        [0.60703014, 0.60378233]]),\n",
       " array([[0.47716659, 0.4818559 ],\n",
       "        [0.64402053, 0.65233794],\n",
       "        [0.23911921, 0.24364116],\n",
       "        [0.62165509, 0.63264298]]),\n",
       " array([[0.46828451, 0.43453606],\n",
       "        [0.66393205, 0.61377305],\n",
       "        [0.23913112, 0.21718757],\n",
       "        [0.56701045, 0.59211087]]),\n",
       " array([[0.46877083, 0.48340932],\n",
       "        [0.63544197, 0.65797923],\n",
       "        [0.23869602, 0.24284253],\n",
       "        [0.6106023 , 0.64528761]]),\n",
       " array([[0.46873141, 0.27673778],\n",
       "        [0.6378194 , 0.45189816],\n",
       "        [0.236553  , 0.13829607],\n",
       "        [0.60235307, 0.37604669]]),\n",
       " array([[0.47622719, 0.46709768],\n",
       "        [0.64607607, 0.63441371],\n",
       "        [0.23798083, 0.23340483],\n",
       "        [0.60558854, 0.61408115]]),\n",
       " array([[0.46687391, 0.35787759],\n",
       "        [0.62808663, 0.53436703],\n",
       "        [0.23331572, 0.17886464],\n",
       "        [0.63061328, 0.52515447]]),\n",
       " array([[0.46050307, 0.47826429],\n",
       "        [0.65765603, 0.65318634],\n",
       "        [0.22945842, 0.23888677],\n",
       "        [0.34448863, 0.64356488]]),\n",
       " array([[0.47236055, 0.42520764],\n",
       "        [0.64352089, 0.60044488],\n",
       "        [0.24331659, 0.21248967],\n",
       "        [0.61201475, 0.57748142]]),\n",
       " array([[0.4761107 , 0.47903186],\n",
       "        [0.66044764, 0.64999583],\n",
       "        [0.23785962, 0.23934423],\n",
       "        [0.57673009, 0.62723543]]),\n",
       " array([[0.43364988, 0.39725544],\n",
       "        [0.61156399, 0.56852678],\n",
       "        [0.21670517, 0.19846746],\n",
       "        [0.5818353 , 0.56711071]]),\n",
       " array([[0.47723303, 0.46936452],\n",
       "        [0.65465902, 0.63677512],\n",
       "        [0.24366284, 0.24047722],\n",
       "        [0.61907138, 0.63677512]]),\n",
       " array([[0.47788378, 0.47960716],\n",
       "        [0.6569887 , 0.6524366 ],\n",
       "        [0.23857789, 0.23967139],\n",
       "        [0.60185691, 0.61996469]]),\n",
       " array([[0.48971548, 0.48208732],\n",
       "        [0.65806216, 0.65178271],\n",
       "        [0.24617001, 0.24083237],\n",
       "        [0.57838986, 0.62274885]]),\n",
       " array([[0.46510549, 0.47995151],\n",
       "        [0.63334195, 0.66727012],\n",
       "        [0.23231254, 0.23983581],\n",
       "        [0.60197144, 0.58910414]]),\n",
       " array([[0.48166011, 0.48150441],\n",
       "        [0.65862875, 0.6783443 ],\n",
       "        [0.24056121, 0.2501496 ],\n",
       "        [0.60617692, 0.53433716]]),\n",
       " array([[0.44433617, 0.47803137],\n",
       "        [0.62707544, 0.6487529 ],\n",
       "        [0.22191295, 0.23874339],\n",
       "        [0.53492431, 0.60810939]]),\n",
       " array([[0.47998669, 0.48490996],\n",
       "        [0.65149827, 0.67001575],\n",
       "        [0.243402  , 0.2419411 ],\n",
       "        [0.59404391, 0.58706001]]),\n",
       " array([[0.40355674, 0.46995521],\n",
       "        [0.57854869, 0.63876842],\n",
       "        [0.20162814, 0.23478805],\n",
       "        [0.5542645 , 0.63308104]]),\n",
       " array([[0.48477864, 0.47373576],\n",
       "        [0.65572159, 0.64385646],\n",
       "        [0.24306896, 0.23634798],\n",
       "        [0.62633309, 0.63286204]]),\n",
       " array([[0.46130489, 0.42566608],\n",
       "        [0.65485409, 0.60325256],\n",
       "        [0.2386001 , 0.21204735],\n",
       "        [0.48118539, 0.45284501]]),\n",
       " array([[0.48253599, 0.47099034],\n",
       "        [0.66297298, 0.65082651],\n",
       "        [0.2461795 , 0.23532621],\n",
       "        [0.61612271, 0.60725749]]),\n",
       " array([[0.48054605, 0.47526011],\n",
       "        [0.65139014, 0.64207731],\n",
       "        [0.24009786, 0.23748804],\n",
       "        [0.61949957, 0.63713799]]),\n",
       " array([[0.48395358, 0.47410462],\n",
       "        [0.65051233, 0.64374003],\n",
       "        [0.24187024, 0.23687724],\n",
       "        [0.6414053 , 0.63468487]]),\n",
       " array([[0.46875396, 0.48045742],\n",
       "        [0.65472226, 0.66515049],\n",
       "        [0.23337429, 0.24444676],\n",
       "        [0.60524667, 0.60960243]]),\n",
       " array([[0.4820075 , 0.47810758],\n",
       "        [0.64617024, 0.64956694],\n",
       "        [0.24086361, 0.23893171],\n",
       "        [0.63202191, 0.625946  ]]),\n",
       " array([[0.42801645, 0.44698471],\n",
       "        [0.60896706, 0.62368481],\n",
       "        [0.21379108, 0.22328284],\n",
       "        [0.53567854, 0.5401668 ]]),\n",
       " array([[0.4732324 , 0.47803127],\n",
       "        [0.65260439, 0.64574103],\n",
       "        [0.23620906, 0.24014665],\n",
       "        [0.52432557, 0.62046667]]),\n",
       " array([[0.46560241, 0.4320535 ],\n",
       "        [0.64020653, 0.60026308],\n",
       "        [0.23266189, 0.21589977],\n",
       "        [0.62341538, 0.59046361]]),\n",
       " array([[0.48359369, 0.46173795],\n",
       "        [0.6539896 , 0.62709293],\n",
       "        [0.24160511, 0.2419852 ],\n",
       "        [0.6379175 , 0.62265623]]),\n",
       " array([[0.43594104, 0.43176126],\n",
       "        [0.60611756, 0.6019768 ],\n",
       "        [0.21771089, 0.21574159],\n",
       "        [0.56167655, 0.56867295]]),\n",
       " array([[0.48313993, 0.46638787],\n",
       "        [0.65201615, 0.64031317],\n",
       "        [0.24224577, 0.23973705],\n",
       "        [0.63646653, 0.57886337]]),\n",
       " array([[0.43165915, 0.40228476],\n",
       "        [0.63589509, 0.589821  ],\n",
       "        [0.22021518, 0.20083634],\n",
       "        [0.35644581, 0.27623937]]),\n",
       " array([[0.48601809, 0.48315936],\n",
       "        [0.65404605, 0.66798153],\n",
       "        [0.24785754, 0.24142632],\n",
       "        [0.55943052, 0.57835039]]),\n",
       " array([[0.40355674, 0.46995521],\n",
       "        [0.57854869, 0.63876842],\n",
       "        [0.20160744, 0.23482902],\n",
       "        [0.5542645 , 0.63308104]]),\n",
       " array([[0.47950415, 0.48558291],\n",
       "        [0.65211921, 0.65258925],\n",
       "        [0.24232201, 0.24255296],\n",
       "        [0.62585381, 0.64160354]]),\n",
       " array([[0.4575248 , 0.4514624 ],\n",
       "        [0.62700118, 0.62110629],\n",
       "        [0.22856222, 0.2256472 ],\n",
       "        [0.6262778 , 0.62050384]]),\n",
       " array([[0.48395722, 0.47174838],\n",
       "        [0.65721533, 0.646381  ],\n",
       "        [0.24619748, 0.24404681],\n",
       "        [0.64936161, 0.63335469]]),\n",
       " array([[0.47813878, 0.47401864],\n",
       "        [0.64651948, 0.64113827],\n",
       "        [0.23879175, 0.23958295],\n",
       "        [0.61970426, 0.62916505]]),\n",
       " array([[0.47624062, 0.46806034],\n",
       "        [0.64126196, 0.64090226],\n",
       "        [0.24474551, 0.23316981],\n",
       "        [0.59549021, 0.57998669]]),\n",
       " array([[0.43432256, 0.4594574 ],\n",
       "        [0.61569073, 0.64020491],\n",
       "        [0.21661228, 0.22928146],\n",
       "        [0.43134852, 0.52281415]]),\n",
       " array([[0.48016318, 0.46175332],\n",
       "        [0.66251378, 0.63570193],\n",
       "        [0.23989272, 0.24192874],\n",
       "        [0.60395365, 0.62261918]]),\n",
       " array([[0.42607203, 0.46493971],\n",
       "        [0.59770049, 0.63419362],\n",
       "        [0.21290198, 0.23225952],\n",
       "        [0.57868584, 0.61812097]]),\n",
       " array([[0.47802523, 0.48183769],\n",
       "        [0.63864691, 0.64614842],\n",
       "        [0.23772896, 0.24050972],\n",
       "        [0.61209   , 0.63461205]]),\n",
       " array([[0.46260994, 0.45913181],\n",
       "        [0.63621293, 0.63470399],\n",
       "        [0.2310218 , 0.23371031],\n",
       "        [0.57627496, 0.60189509]]),\n",
       " array([[0.48663786, 0.47016533],\n",
       "        [0.66407896, 0.63996052],\n",
       "        [0.24401715, 0.2349781 ],\n",
       "        [0.60069146, 0.61421244]]),\n",
       " array([[0.44622487, 0.44241915],\n",
       "        [0.62180862, 0.61528199],\n",
       "        [0.22301944, 0.22107694],\n",
       "        [0.59627959, 0.60368714]]),\n",
       " array([[0.48310605, 0.46685217],\n",
       "        [0.65193355, 0.64328769],\n",
       "        [0.24139743, 0.23875921],\n",
       "        [0.63348235, 0.62280442]]),\n",
       " array([[0.43990095, 0.4700605 ],\n",
       "        [0.6096753 , 0.66121281],\n",
       "        [0.21979751, 0.23450644],\n",
       "        [0.57041143, 0.51963222]]),\n",
       " array([[0.4925205 , 0.45888547],\n",
       "        [0.65435839, 0.64783321],\n",
       "        [0.24653233, 0.24042687],\n",
       "        [0.59754845, 0.52890472]]),\n",
       " array([[0.42987919, 0.45836917],\n",
       "        [0.60872337, 0.63871354],\n",
       "        [0.21423241, 0.22813402],\n",
       "        [0.36573143, 0.47589563]]),\n",
       " array([[0.48497158, 0.4719911 ],\n",
       "        [0.66554015, 0.64511224],\n",
       "        [0.2431313 , 0.24421439],\n",
       "        [0.62070823, 0.55191334]]),\n",
       " array([[0.43599653, 0.41748586],\n",
       "        [0.60929964, 0.59000312],\n",
       "        [0.217904  , 0.20865434],\n",
       "        [0.58362034, 0.57797528]]),\n",
       " array([[0.4822856 , 0.48684105],\n",
       "        [0.67326301, 0.65475129],\n",
       "        [0.24608158, 0.24573336],\n",
       "        [0.61992749, 0.64250394]]),\n",
       " array([[0.47540842, 0.37458596],\n",
       "        [0.64908243, 0.54837499],\n",
       "        [0.23738537, 0.18720246],\n",
       "        [0.60006015, 0.54128976]]),\n",
       " array([[0.46542618, 0.48429733],\n",
       "        [0.65398887, 0.65445724],\n",
       "        [0.23224677, 0.24356664],\n",
       "        [0.54203745, 0.64657679]]),\n",
       " array([[0.44731227, 0.46707932],\n",
       "        [0.63806349, 0.65089212],\n",
       "        [0.2229185 , 0.23304918],\n",
       "        [0.51180095, 0.60174236]]),\n",
       " array([[0.48463327, 0.47007244],\n",
       "        [0.6522936 , 0.64117171],\n",
       "        [0.24216766, 0.23489763],\n",
       "        [0.6174493 , 0.63373761]]),\n",
       " array([[0.44088937, 0.47324148],\n",
       "        [0.62888254, 0.64748988],\n",
       "        [0.21928899, 0.23746474],\n",
       "        [0.34221049, 0.56474084]]),\n",
       " array([[0.44540893, 0.48044918],\n",
       "        [0.66380019, 0.65158321],\n",
       "        [0.22355598, 0.24171822],\n",
       "        [0.29543563, 0.63444818]]),\n",
       " array([[0.41651645, 0.4118132 ],\n",
       "        [0.59677538, 0.58603634],\n",
       "        [0.20790677, 0.20577149],\n",
       "        [0.48014842, 0.53048807]]),\n",
       " array([[0.47999919, 0.48513937],\n",
       "        [0.65163383, 0.65848938],\n",
       "        [0.24138753, 0.24239879],\n",
       "        [0.6241737 , 0.6408102 ]]),\n",
       " array([[0.46526202, 0.4546211 ],\n",
       "        [0.65439534, 0.62128047],\n",
       "        [0.23339532, 0.22683414],\n",
       "        [0.48368181, 0.48498299]]),\n",
       " array([[0.47079595, 0.46560728],\n",
       "        [0.64785914, 0.63577616],\n",
       "        [0.23527845, 0.23264556],\n",
       "        [0.6137059 , 0.61668355]]),\n",
       " array([[0.46767999, 0.46347936],\n",
       "        [0.63305062, 0.63846108],\n",
       "        [0.23366701, 0.23157156],\n",
       "        [0.622508  , 0.58774204]]),\n",
       " array([[0.47519   , 0.48160564],\n",
       "        [0.64171525, 0.65429477],\n",
       "        [0.24318854, 0.24451302],\n",
       "        [0.63619413, 0.60321098]]),\n",
       " array([[0.4153787 , 0.44397729],\n",
       "        [0.58769519, 0.61687869],\n",
       "        [0.2075323 , 0.22187255],\n",
       "        [0.55076566, 0.57783703]]),\n",
       " array([[0.472785  , 0.48539991],\n",
       "        [0.64137364, 0.65064156],\n",
       "        [0.23625632, 0.24397954],\n",
       "        [0.61314264, 0.6163471 ]]),\n",
       " array([[0.44928067, 0.40637652],\n",
       "        [0.62851375, 0.58431872],\n",
       "        [0.22453537, 0.20305923],\n",
       "        [0.5789817 , 0.54694063]]),\n",
       " array([[0.48457314, 0.47975331],\n",
       "        [0.6526551 , 0.65054606],\n",
       "        [0.24491995, 0.23973449],\n",
       "        [0.64786352, 0.63189397]]),\n",
       " array([[0.47408734, 0.42822835],\n",
       "        [0.65901866, 0.60019313],\n",
       "        [0.23610379, 0.21401029],\n",
       "        [0.60057672, 0.5963758 ]]),\n",
       " array([[0.48287879, 0.47091052],\n",
       "        [0.65264542, 0.64165637],\n",
       "        [0.24130164, 0.24243323],\n",
       "        [0.63524896, 0.63637574]]),\n",
       " array([[0.4595403 , 0.41571679],\n",
       "        [0.68121354, 0.58871919],\n",
       "        [0.23671449, 0.20766757],\n",
       "        [0.25862186, 0.54056211]]),\n",
       " array([[0.48467287, 0.4779721 ],\n",
       "        [0.67244934, 0.65597051],\n",
       "        [0.2420431 , 0.23872821],\n",
       "        [0.61679567, 0.61914587]]),\n",
       " array([[0.41678855, 0.36188268],\n",
       "        [0.59327487, 0.54113793],\n",
       "        [0.20827085, 0.18082837],\n",
       "        [0.53731002, 0.49886389]]),\n",
       " array([[0.47593979, 0.47953334],\n",
       "        [0.63971696, 0.65185063],\n",
       "        [0.2378652 , 0.23964584],\n",
       "        [0.63424784, 0.63390165]]),\n",
       " array([[0.48050825, 0.41795841],\n",
       "        [0.66493227, 0.59217927],\n",
       "        [0.23935662, 0.20882612],\n",
       "        [0.60558854, 0.55975471]]),\n",
       " array([[0.48249906, 0.47534993],\n",
       "        [0.64874895, 0.64493992],\n",
       "        [0.24427063, 0.23827301],\n",
       "        [0.62135818, 0.62041091]]),\n",
       " array([[0.48185659, 0.45860383],\n",
       "        [0.64986554, 0.62958993],\n",
       "        [0.2408024 , 0.22922107],\n",
       "        [0.64562805, 0.61785984]]),\n",
       " array([[0.48070828, 0.4841176 ],\n",
       "        [0.66518523, 0.64980956],\n",
       "        [0.24218371, 0.24496336],\n",
       "        [0.61528059, 0.64850597]]),\n",
       " array([[0.49108401, 0.47820896],\n",
       "        [0.65562544, 0.64706731],\n",
       "        [0.24841005, 0.24260602],\n",
       "        [0.60693539, 0.60208595]]),\n",
       " array([[0.48588973, 0.48752586],\n",
       "        [0.64620264, 0.65743982],\n",
       "        [0.24276011, 0.24733662],\n",
       "        [0.61659011, 0.63894944]]),\n",
       " array([[0.43694207, 0.37215062],\n",
       "        [0.62098053, 0.55351473],\n",
       "        [0.21802925, 0.18596164],\n",
       "        [0.52882018, 0.48100515]]),\n",
       " array([[0.47353293, 0.47221444],\n",
       "        [0.6369201 , 0.64344318],\n",
       "        [0.24393104, 0.23599623],\n",
       "        [0.63328173, 0.63112585]]),\n",
       " array([[0.46754528, 0.47968765],\n",
       "        [0.64432006, 0.64578353],\n",
       "        [0.23345781, 0.23946482],\n",
       "        [0.53048807, 0.54137288]]),\n",
       " array([[0.4803054 , 0.47681987],\n",
       "        [0.64850371, 0.65483919],\n",
       "        [0.24000646, 0.23831119],\n",
       "        [0.62622251, 0.59187855]]),\n",
       " array([[0.48276671, 0.44283407],\n",
       "        [0.64133259, 0.63788256],\n",
       "        [0.24059056, 0.22044434],\n",
       "        [0.43900059, 0.55648595]]),\n",
       " array([[0.48231667, 0.48172945],\n",
       "        [0.63138171, 0.65105987],\n",
       "        [0.24152253, 0.24070519],\n",
       "        [0.59921753, 0.62174785]]),\n",
       " array([[0.45919657, 0.45262742],\n",
       "        [0.62353593, 0.62120218],\n",
       "        [0.22946654, 0.22615427],\n",
       "        [0.61094155, 0.59677972]]),\n",
       " array([[0.48086835, 0.48558671],\n",
       "        [0.64714369, 0.65133577],\n",
       "        [0.24407394, 0.2424258 ],\n",
       "        [0.62524501, 0.62369291]]),\n",
       " array([[0.43379024, 0.47123408],\n",
       "        [0.60582417, 0.63609172],\n",
       "        [0.21678224, 0.2354437 ],\n",
       "        [0.57949422, 0.63112585]]),\n",
       " array([[0.47712679, 0.47711395],\n",
       "        [0.6618058 , 0.63857914],\n",
       "        [0.24227151, 0.23817146],\n",
       "        [0.61503713, 0.63404743]]),\n",
       " array([[0.47556406, 0.45483005],\n",
       "        [0.64735883, 0.63005829],\n",
       "        [0.23762611, 0.22729856],\n",
       "        [0.62182205, 0.60820399]]),\n",
       " array([[0.47232639, 0.48172123],\n",
       "        [0.6370084 , 0.66284925],\n",
       "        [0.24393088, 0.24281394],\n",
       "        [0.59946659, 0.64611154]]),\n",
       " array([[0.47684228, 0.48208818],\n",
       "        [0.64116322, 0.63720984],\n",
       "        [0.2367099 , 0.24107715],\n",
       "        [0.62109827, 0.59935165]]),\n",
       " array([[0.48954043, 0.47772256],\n",
       "        [0.67196552, 0.6489176 ],\n",
       "        [0.24612123, 0.23869007],\n",
       "        [0.63847893, 0.60684063]]),\n",
       " array([[0.48290058, 0.4663539 ],\n",
       "        [0.65269131, 0.6382046 ],\n",
       "        [0.24130187, 0.23293994],\n",
       "        [0.63260646, 0.61180777]]),\n",
       " array([[0.48590455, 0.48302542],\n",
       "        [0.65071595, 0.65462911],\n",
       "        [0.24282672, 0.24134972],\n",
       "        [0.62237828, 0.64679142]]),\n",
       " array([[0.39254733, 0.41335671],\n",
       "        [0.5658146 , 0.59273416],\n",
       "        [0.19615424, 0.20629363],\n",
       "        [0.52814351, 0.50320845]]),\n",
       " array([[0.48281855, 0.46917363],\n",
       "        [0.65534988, 0.64643234],\n",
       "        [0.24111515, 0.23412825],\n",
       "        [0.6441037 , 0.56606733]]),\n",
       " array([[0.47462068, 0.46905699],\n",
       "        [0.65344081, 0.63941235],\n",
       "        [0.24547877, 0.23509662],\n",
       "        [0.57842933, 0.6130675 ]]),\n",
       " array([[0.46516303, 0.48354109],\n",
       "        [0.65667073, 0.65491487],\n",
       "        [0.23841615, 0.24413991],\n",
       "        [0.49601974, 0.60498066]]),\n",
       " array([[0.46459951, 0.47004347],\n",
       "        [0.63337827, 0.64023684],\n",
       "        [0.23540877, 0.24039725],\n",
       "        [0.52428304, 0.53314043]]),\n",
       " array([[0.47662158, 0.46799087],\n",
       "        [0.64931467, 0.64949303],\n",
       "        [0.23811925, 0.23380486],\n",
       "        [0.61062115, 0.57178722]]),\n",
       " array([[0.46668535, 0.4765353 ],\n",
       "        [0.64209215, 0.65040547],\n",
       "        [0.2329037 , 0.23781415],\n",
       "        [0.59423692, 0.57246417]]),\n",
       " array([[0.4835312 , 0.4784154 ],\n",
       "        [0.6483278 , 0.64632732],\n",
       "        [0.24476312, 0.23903216],\n",
       "        [0.64178372, 0.63757318]]),\n",
       " array([[0.47368536, 0.43566425],\n",
       "        [0.64701317, 0.60762748],\n",
       "        [0.23668708, 0.21764883],\n",
       "        [0.59481564, 0.58700152]]),\n",
       " array([[0.47861842, 0.48158693],\n",
       "        [0.65292867, 0.65573586],\n",
       "        [0.24531658, 0.24046604],\n",
       "        [0.58120653, 0.62315625]]),\n",
       " array([[0.47540842, 0.37458596],\n",
       "        [0.64908243, 0.54837499],\n",
       "        [0.23744631, 0.18718926],\n",
       "        [0.60006015, 0.54128976]]),\n",
       " array([[0.46976267, 0.4816912 ],\n",
       "        [0.653457  , 0.64874847],\n",
       "        [0.23405845, 0.24376404],\n",
       "        [0.5648213 , 0.64577134]]),\n",
       " array([[0.43511964, 0.35160478],\n",
       "        [0.6042031 , 0.52207945],\n",
       "        [0.21740429, 0.1756354 ],\n",
       "        [0.5625851 , 0.45489936]]),\n",
       " array([[0.48642905, 0.48163417],\n",
       "        [0.66372644, 0.66359403],\n",
       "        [0.24216372, 0.24020554],\n",
       "        [0.60055759, 0.57769876]]),\n",
       " array([[0.47556406, 0.45483005],\n",
       "        [0.64735883, 0.63005829],\n",
       "        [0.23759825, 0.22724296],\n",
       "        [0.62182205, 0.60820399]]),\n",
       " array([[0.48087998, 0.47759243],\n",
       "        [0.65428757, 0.65014404],\n",
       "        [0.24427313, 0.24243766],\n",
       "        [0.62269328, 0.62029938]]),\n",
       " array([[0.42439391, 0.45317774],\n",
       "        [0.59439866, 0.63103393],\n",
       "        [0.21192476, 0.2260227 ],\n",
       "        [0.54516523, 0.47264483]]),\n",
       " array([[0.47009967, 0.46133423],\n",
       "        [0.64928381, 0.64319856],\n",
       "        [0.24555431, 0.23264223],\n",
       "        [0.58057719, 0.50283642]]),\n",
       " array([[0.47341788, 0.45323074],\n",
       "        [0.65055295, 0.62349681],\n",
       "        [0.23654846, 0.22645692],\n",
       "        [0.6254111 , 0.61062115]]),\n",
       " array([[0.48682537, 0.48627944],\n",
       "        [0.66181317, 0.66399469],\n",
       "        [0.24412583, 0.243118  ],\n",
       "        [0.62570627, 0.63818922]]),\n",
       " array([[0.37809041, 0.41437158],\n",
       "        [0.55079613, 0.59429763],\n",
       "        [0.18864959, 0.20698824],\n",
       "        [0.42298985, 0.49458256]]),\n",
       " array([[0.47205146, 0.48009429],\n",
       "        [0.6460637 , 0.65369105],\n",
       "        [0.24227393, 0.24162574],\n",
       "        [0.5913943 , 0.63519439]]),\n",
       " array([[0.41203292, 0.45493734],\n",
       "        [0.59066214, 0.63450292],\n",
       "        [0.20547037, 0.236621  ],\n",
       "        [0.42742183, 0.5383748 ]]),\n",
       " array([[0.47661777, 0.47257289],\n",
       "        [0.64796351, 0.65245137],\n",
       "        [0.23796809, 0.24232805],\n",
       "        [0.60292513, 0.62315625]]),\n",
       " array([[0.44836224, 0.46071408],\n",
       "        [0.6356931 , 0.64812445],\n",
       "        [0.22404823, 0.23621628],\n",
       "        [0.4827157 , 0.45268136]]),\n",
       " array([[0.47423614, 0.48325219],\n",
       "        [0.66344358, 0.66450733],\n",
       "        [0.23930508, 0.24229936],\n",
       "        [0.52983403, 0.59019192]]),\n",
       " array([[0.37212813, 0.29923774],\n",
       "        [0.55256684, 0.47513903],\n",
       "        [0.18548895, 0.14889825],\n",
       "        [0.32960867, 0.29091213]]),\n",
       " array([[0.46415181, 0.470806  ],\n",
       "        [0.64909671, 0.65464351],\n",
       "        [0.2428744 , 0.23473435],\n",
       "        [0.38312386, 0.41057958]]),\n",
       " array([[0.47737345, 0.47850737],\n",
       "        [0.68628788, 0.65548268],\n",
       "        [0.23576489, 0.23913247],\n",
       "        [0.52275022, 0.6416576 ]]),\n",
       " array([[0.48571056, 0.47692308],\n",
       "        [0.65911103, 0.65587734],\n",
       "        [0.24273373, 0.23885525],\n",
       "        [0.60737114, 0.61462491]]),\n",
       " array([[0.44256375, 0.3725246 ],\n",
       "        [0.60863413, 0.53874753],\n",
       "        [0.22113692, 0.18611926],\n",
       "        [0.59988788, 0.53185754]]),\n",
       " array([[0.4761171 , 0.48303095],\n",
       "        [0.64467563, 0.65063373],\n",
       "        [0.23775913, 0.24159516],\n",
       "        [0.61716925, 0.63831598]]),\n",
       " array([[0.47087878, 0.3942369 ],\n",
       "        [0.64628286, 0.57561132],\n",
       "        [0.23522689, 0.19697047],\n",
       "        [0.58307158, 0.55768554]]),\n",
       " array([[0.47578861, 0.46783731],\n",
       "        [0.64670323, 0.64224989],\n",
       "        [0.23764942, 0.23790029],\n",
       "        [0.5937736 , 0.62769536]]),\n",
       " array([[0.38895369, 0.43455656],\n",
       "        [0.57025683, 0.6119943 ],\n",
       "        [0.19430012, 0.21715201],\n",
       "        [0.52038089, 0.59110359]]),\n",
       " array([[0.48486322, 0.47956928],\n",
       "        [0.65969625, 0.65674236],\n",
       "        [0.24221163, 0.23948162],\n",
       "        [0.61862429, 0.62782408]]),\n",
       " array([[0.45107753, 0.34885617],\n",
       "        [0.63803397, 0.50869008],\n",
       "        [0.22629881, 0.17420038],\n",
       "        [0.424276  , 0.49152218]]),\n",
       " array([[0.47348875, 0.47792573],\n",
       "        [0.66347946, 0.64356016],\n",
       "        [0.23662046, 0.23872367],\n",
       "        [0.60218136, 0.61537421]]),\n",
       " array([[0.44970198, 0.41611631],\n",
       "        [0.62384341, 0.60084103],\n",
       "        [0.2246237 , 0.20776586],\n",
       "        [0.60456243, 0.5233467 ]]),\n",
       " array([[0.47519   , 0.48160564],\n",
       "        [0.64171525, 0.65429477],\n",
       "        [0.24310734, 0.24470412],\n",
       "        [0.63619413, 0.60321098]]),\n",
       " array([[0.46518941, 0.43825134],\n",
       "        [0.664134  , 0.62885348],\n",
       "        [0.23167067, 0.21892167],\n",
       "        [0.54572309, 0.52353832]]),\n",
       " array([[0.47237546, 0.4814209 ],\n",
       "        [0.64947783, 0.65618243],\n",
       "        [0.24403254, 0.24214659],\n",
       "        [0.61897826, 0.61454993]]),\n",
       " array([[0.47101594, 0.40832807],\n",
       "        [0.64194708, 0.58097592],\n",
       "        [0.23536675, 0.20402398],\n",
       "        [0.63064991, 0.57542327]]),\n",
       " array([[0.47293096, 0.47342492],\n",
       "        [0.64760352, 0.64847072],\n",
       "        [0.24250973, 0.23759466],\n",
       "        [0.62787924, 0.63174773]]),\n",
       " array([[0.44772456, 0.45359666],\n",
       "        [0.62987077, 0.63173195],\n",
       "        [0.22205625, 0.22609781],\n",
       "        [0.39190929, 0.49710134]]),\n",
       " array([[0.47601403, 0.48277983],\n",
       "        [0.65552536, 0.64391764],\n",
       "        [0.24233313, 0.24121788],\n",
       "        [0.595548  , 0.62999037]]),\n",
       " array([[0.47470567, 0.46060828],\n",
       "        [0.64712971, 0.65028453],\n",
       "        [0.24263003, 0.23011786],\n",
       "        [0.63121733, 0.56405654]]),\n",
       " array([[0.4630739 , 0.45107819],\n",
       "        [0.65383659, 0.64811887],\n",
       "        [0.23123783, 0.22534936],\n",
       "        [0.52867221, 0.52979182]]),\n",
       " array([[0.32895511, 0.3169499 ],\n",
       "        [0.49319428, 0.48055318],\n",
       "        [0.16433057, 0.15838904],\n",
       "        [0.46828115, 0.47029474]]),\n",
       " array([[0.47941914, 0.47565618],\n",
       "        [0.65461756, 0.64252463],\n",
       "        [0.23933901, 0.23811552],\n",
       "        [0.61881061, 0.63066822]]),\n",
       " array([[0.34256835, 0.37739634],\n",
       "        [0.51663538, 0.54902712],\n",
       "        [0.17116345, 0.18851667],\n",
       "        [0.47535101, 0.53343454]]),\n",
       " array([[0.48200313, 0.46538937],\n",
       "        [0.64679751, 0.63332248],\n",
       "        [0.24458026, 0.2377046 ],\n",
       "        [0.63780879, 0.62629623]]),\n",
       " array([[0.40124384, 0.31456583],\n",
       "        [0.57177695, 0.48110068],\n",
       "        [0.20044855, 0.15711126],\n",
       "        [0.54599154, 0.44374535]]),\n",
       " array([[0.47901172, 0.47604584],\n",
       "        [0.64592895, 0.6447455 ],\n",
       "        [0.24444841, 0.2451495 ],\n",
       "        [0.61621622, 0.62936689]]),\n",
       " array([[0.41369763, 0.47759133],\n",
       "        [0.59457709, 0.65334745],\n",
       "        [0.20664841, 0.23862964],\n",
       "        [0.54700248, 0.61670224]]),\n",
       " array([[0.48094303, 0.47532985],\n",
       "        [0.66670701, 0.66176427],\n",
       "        [0.24172361, 0.24027871],\n",
       "        [0.59984959, 0.59442988]]),\n",
       " array([[0.41314469, 0.43812716],\n",
       "        [0.58414437, 0.61086239],\n",
       "        [0.20645975, 0.2189698 ],\n",
       "        [0.57355789, 0.59785571]]),\n",
       " array([[0.47618378, 0.4690307 ],\n",
       "        [0.64367535, 0.64202878],\n",
       "        [0.23796475, 0.24037472],\n",
       "        [0.63308104, 0.61942512]]),\n",
       " array([[0.35302139, 0.44719889],\n",
       "        [0.53416677, 0.62785818],\n",
       "        [0.17610171, 0.22329045],\n",
       "        [0.41001196, 0.50628701]]),\n",
       " array([[0.47161235, 0.47047502],\n",
       "        [0.64530638, 0.65099017],\n",
       "        [0.23736267, 0.24017479],\n",
       "        [0.62443244, 0.61953679]]),\n",
       " array([[0.42780492, 0.4712681 ],\n",
       "        [0.60150884, 0.65058083],\n",
       "        [0.21359498, 0.23547027],\n",
       "        [0.58890971, 0.62443244]]),\n",
       " array([[0.48110396, 0.47199187],\n",
       "        [0.67250861, 0.64525536],\n",
       "        [0.24065005, 0.23582329],\n",
       "        [0.64214393, 0.63242384]]),\n",
       " array([[0.46889651, 0.4692595 ],\n",
       "        [0.64702887, 0.64455721],\n",
       "        [0.2341827 , 0.23444016],\n",
       "        [0.59346456, 0.62681203]]),\n",
       " array([[0.48694706, 0.4673865 ],\n",
       "        [0.66140386, 0.64281961],\n",
       "        [0.24457217, 0.24277838],\n",
       "        [0.60731432, 0.62448788]]),\n",
       " array([[0.42405573, 0.47518415],\n",
       "        [0.60294464, 0.6539355 ],\n",
       "        [0.21171   , 0.23733291],\n",
       "        [0.51800394, 0.59487348]]),\n",
       " array([[0.4735015 , 0.46427493],\n",
       "        [0.6509213 , 0.64310901],\n",
       "        [0.23665916, 0.23196828],\n",
       "        [0.62089399, 0.59187855]]),\n",
       " array([[0.45870662, 0.33043033],\n",
       "        [0.63392133, 0.50206444],\n",
       "        [0.22915236, 0.16513322],\n",
       "        [0.58358116, 0.44930719]]),\n",
       " array([[0.47397135, 0.47377442],\n",
       "        [0.64569386, 0.64808904],\n",
       "        [0.2368579 , 0.23667795],\n",
       "        [0.61550526, 0.61888513]]),\n",
       " array([[0.4754136 , 0.4631653 ],\n",
       "        [0.65545207, 0.64228118],\n",
       "        [0.2372771 , 0.23733138],\n",
       "        [0.57560161, 0.55681146]]),\n",
       " array([[0.47592435, 0.47898443],\n",
       "        [0.64449483, 0.65556254],\n",
       "        [0.23702039, 0.24179656],\n",
       "        [0.56474084, 0.59923669]]),\n",
       " array([[0.38865759, 0.44144611],\n",
       "        [0.55758525, 0.61184465],\n",
       "        [0.19420867, 0.22056769],\n",
       "        [0.545847  , 0.60395365]]),\n",
       " array([[0.48332865, 0.47981297],\n",
       "        [0.64961395, 0.65515614],\n",
       "        [0.24484157, 0.23934173],\n",
       "        [0.63943771, 0.63105265]]),\n",
       " array([[0.47243695, 0.41701098],\n",
       "        [0.65235651, 0.58422228],\n",
       "        [0.23889489, 0.20829888],\n",
       "        [0.60809047, 0.58553768]]),\n",
       " array([[0.46417399, 0.46672036],\n",
       "        [0.63324683, 0.63534981],\n",
       "        [0.23188068, 0.23751769],\n",
       "        [0.60034718, 0.63388343]]),\n",
       " array([[0.46434125, 0.34872457],\n",
       "        [0.6401572 , 0.51779153],\n",
       "        [0.23174736, 0.17426391],\n",
       "        [0.51847565, 0.48715411]]),\n",
       " array([[0.4689358 , 0.46219298],\n",
       "        [0.6561442 , 0.65265994],\n",
       "        [0.23780963, 0.22937418],\n",
       "        [0.56881298, 0.58320881]]),\n",
       " array([[0.41588165, 0.42139831],\n",
       "        [0.58771875, 0.60068311],\n",
       "        [0.20781111, 0.21057285],\n",
       "        [0.53728913, 0.55565116]]),\n",
       " array([[0.4779461 , 0.47608973],\n",
       "        [0.64883798, 0.65922192],\n",
       "        [0.24467303, 0.24409591],\n",
       "        [0.55092973, 0.57172746]]),\n",
       " array([[0.4683466 , 0.47233745],\n",
       "        [0.63262862, 0.64282646],\n",
       "        [0.23804512, 0.23589091],\n",
       "        [0.61456868, 0.58075425]]),\n",
       " array([[0.47816296, 0.48364151],\n",
       "        [0.64320253, 0.65751977],\n",
       "        [0.23883535, 0.24174228],\n",
       "        [0.6226377 , 0.6432234 ]]),\n",
       " array([[0.45127646, 0.45920938],\n",
       "        [0.65140212, 0.63906419],\n",
       "        [0.225336  , 0.22949029],\n",
       "        [0.44111558, 0.56280702]]),\n",
       " array([[0.47661309, 0.48322317],\n",
       "        [0.66502401, 0.65386806],\n",
       "        [0.24671611, 0.24682695],\n",
       "        [0.58273819, 0.60678377]]),\n",
       " array([[0.46742397, 0.48088283],\n",
       "        [0.64813763, 0.66267161],\n",
       "        [0.23351161, 0.24025596],\n",
       "        [0.57248407, 0.63413853]]),\n",
       " array([[0.46805051, 0.47526716],\n",
       "        [0.6565582 , 0.65656537],\n",
       "        [0.23426509, 0.23709261],\n",
       "        [0.5531001 , 0.61526187]]),\n",
       " array([[0.47742951, 0.45022086],\n",
       "        [0.65854891, 0.61803976],\n",
       "        [0.23823197, 0.22477234],\n",
       "        [0.60389655, 0.58563536]]),\n",
       " array([[0.47922807, 0.48775526],\n",
       "        [0.6461974 , 0.65584088],\n",
       "        [0.23943059, 0.24375354],\n",
       "        [0.6334094 , 0.65080306]]),\n",
       " array([[0.46583555, 0.4511606 ],\n",
       "        [0.63255789, 0.62008097],\n",
       "        [0.23253728, 0.22549516],\n",
       "        [0.62855918, 0.61946235]]),\n",
       " array([[0.46742846, 0.47618578],\n",
       "        [0.63695941, 0.64464863],\n",
       "        [0.23654448, 0.23794499],\n",
       "        [0.62956866, 0.64073804]]),\n",
       " array([[0.47457159, 0.44321412],\n",
       "        [0.63985307, 0.6262814 ],\n",
       "        [0.24334416, 0.22153221],\n",
       "        [0.63898562, 0.57963215]]),\n",
       " array([[0.47502805, 0.48794575],\n",
       "        [0.64301735, 0.66297542],\n",
       "        [0.23743224, 0.24384801],\n",
       "        [0.61338678, 0.64275584]]),\n",
       " array([[0.44936936, 0.33500496],\n",
       "        [0.62250894, 0.49842225],\n",
       "        [0.22439943, 0.1674193 ],\n",
       "        [0.56226219, 0.49635101]]),\n",
       " array([[0.48218699, 0.47116457],\n",
       "        [0.65467203, 0.64379201],\n",
       "        [0.24198623, 0.24216076],\n",
       "        [0.62513426, 0.63211328]]),\n",
       " array([[0.4753148 , 0.4681566 ],\n",
       "        [0.66759084, 0.66073095],\n",
       "        [0.23934109, 0.23360418],\n",
       "        [0.5920528 , 0.5285665 ]]),\n",
       " array([[0.47710853, 0.46691924],\n",
       "        [0.64792931, 0.6468047 ],\n",
       "        [0.23837327, 0.23772442],\n",
       "        [0.63659361, 0.56606733]]),\n",
       " array([[0.45035177, 0.44940147],\n",
       "        [0.76188324, 0.63645957],\n",
       "        [0.22626944, 0.22453397],\n",
       "        [0.32990834, 0.53477757]]),\n",
       " array([[0.46292199, 0.48078885],\n",
       "        [0.76109676, 0.67245635],\n",
       "        [0.23446271, 0.24028613],\n",
       "        [0.40403977, 0.61265411]]),\n",
       " array([[0.36734275, 0.39077659],\n",
       "        [0.54629567, 0.57265474],\n",
       "        [0.18355493, 0.19525252],\n",
       "        [0.47888412, 0.51946099]]),\n",
       " array([[0.4661386 , 0.47324172],\n",
       "        [0.65817528, 0.6603265 ],\n",
       "        [0.23283691, 0.23657336],\n",
       "        [0.56393571, 0.5924979 ]]),\n",
       " array([[0.46215952, 0.47349912],\n",
       "        [0.64324562, 0.66351279],\n",
       "        [0.23041757, 0.23571529],\n",
       "        [0.47811548, 0.57913944]]),\n",
       " array([[0.47297377, 0.4679504 ],\n",
       "        [0.65933026, 0.65586908],\n",
       "        [0.23582313, 0.23572653],\n",
       "        [0.46809784, 0.58144238]]),\n",
       " array([[0.43193644, 0.38164999],\n",
       "        [0.59673481, 0.55534373],\n",
       "        [0.21575342, 0.1907381 ],\n",
       "        [0.59626035, 0.54599154]]),\n",
       " array([[0.47810566, 0.47995822],\n",
       "        [0.64077825, 0.64509721],\n",
       "        [0.24195149, 0.23979844],\n",
       "        [0.6402507 , 0.64469592]]),\n",
       " array([[0.43649424, 0.4165151 ],\n",
       "        [0.61705846, 0.59180008],\n",
       "        [0.21806247, 0.20765714],\n",
       "        [0.53528057, 0.53670387]]),\n",
       " array([[0.47220941, 0.47578614],\n",
       "        [0.6428062 , 0.65026791],\n",
       "        [0.24030058, 0.24393839],\n",
       "        [0.61116762, 0.62775053]]),\n",
       " array([[0.47859596, 0.47577329],\n",
       "        [0.65488978, 0.67049682],\n",
       "        [0.23880998, 0.24017736],\n",
       "        [0.62754822, 0.56913296]]),\n",
       " array([[0.48309609, 0.48448728],\n",
       "        [0.64946856, 0.65965159],\n",
       "        [0.24145931, 0.24210073],\n",
       "        [0.63633942, 0.6144562 ]]),\n",
       " array([[0.44417606, 0.47071584],\n",
       "        [0.62114909, 0.64527935],\n",
       "        [0.22164226, 0.23518176],\n",
       "        [0.55896426, 0.61186422]]),\n",
       " array([[0.486536  , 0.48508046],\n",
       "        [0.65949617, 0.66149051],\n",
       "        [0.245394  , 0.24745187],\n",
       "        [0.59754845, 0.6305034 ]]),\n",
       " array([[0.46841718, 0.47362482],\n",
       "        [0.65256333, 0.64813743],\n",
       "        [0.23355823, 0.23667295],\n",
       "        [0.59415972, 0.6292935 ]]),\n",
       " array([[0.47724597, 0.47491421],\n",
       "        [0.64453521, 0.64413535],\n",
       "        [0.24011818, 0.23726114],\n",
       "        [0.62940358, 0.63976302]]),\n",
       " array([[0.44502416, 0.44277545],\n",
       "        [0.61197365, 0.61534696],\n",
       "        [0.22219918, 0.22091819],\n",
       "        [0.57801478, 0.58896805]]),\n",
       " array([[0.47082792, 0.47764096],\n",
       "        [0.64886499, 0.65867896],\n",
       "        [0.23791104, 0.24169662],\n",
       "        [0.59579837, 0.62636994]]),\n",
       " array([[0.46668535, 0.4765353 ],\n",
       "        [0.64209215, 0.65040547],\n",
       "        [0.23312822, 0.23777071],\n",
       "        [0.59423692, 0.57246417]]),\n",
       " array([[0.48509558, 0.46603423],\n",
       "        [0.66797558, 0.64720695],\n",
       "        [0.24317363, 0.24013316],\n",
       "        [0.5906576 , 0.57884365]]),\n",
       " array([[0.46771758, 0.40010154],\n",
       "        [0.64866634, 0.58410984],\n",
       "        [0.23373752, 0.19986341],\n",
       "        [0.55815263, 0.48853858]]),\n",
       " array([[0.46538529, 0.47887609],\n",
       "        [0.66176532, 0.66029748],\n",
       "        [0.24427406, 0.24237354],\n",
       "        [0.47464696, 0.63266124]]),\n",
       " array([[0.46852853, 0.46612611],\n",
       "        [0.64715959, 0.6348628 ],\n",
       "        [0.23291377, 0.2329445 ],\n",
       "        [0.58475572, 0.61340555]]),\n",
       " array([[0.47482863, 0.47315664],\n",
       "        [0.66450765, 0.63657569],\n",
       "        [0.24117449, 0.24297411],\n",
       "        [0.59629883, 0.63362822]]),\n",
       " array([[0.46899867, 0.43024742],\n",
       "        [0.63924904, 0.61016404],\n",
       "        [0.23434826, 0.21495672],\n",
       "        [0.62406278, 0.5791    ]]),\n",
       " array([[0.47504559, 0.47749133],\n",
       "        [0.64889671, 0.64917734],\n",
       "        [0.24205635, 0.2385849 ],\n",
       "        [0.63770005, 0.64237796]]),\n",
       " array([[0.45894957, 0.4421698 ],\n",
       "        [0.64316259, 0.61634345],\n",
       "        [0.2291164 , 0.22099072],\n",
       "        [0.57391547, 0.59547094]]),\n",
       " array([[0.48113562, 0.48175877],\n",
       "        [0.66716554, 0.6619421 ],\n",
       "        [0.24900624, 0.24224742],\n",
       "        [0.54926684, 0.55683179]]),\n",
       " array([[0.4576114 , 0.43849834],\n",
       "        [0.6281388 , 0.606346  ],\n",
       "        [0.2287005 , 0.21905935],\n",
       "        [0.62345239, 0.5940246 ]]),\n",
       " array([[0.45745432, 0.47169663],\n",
       "        [0.62685043, 0.64078498],\n",
       "        [0.2286113 , 0.23575103],\n",
       "        [0.62609349, 0.63887707]]),\n",
       " array([[0.44700759, 0.40152324],\n",
       "        [0.62678356, 0.5779328 ],\n",
       "        [0.22340504, 0.20062845],\n",
       "        [0.57647288, 0.56777207]]),\n",
       " array([[0.4751533 , 0.48019763],\n",
       "        [0.65001602, 0.65462644],\n",
       "        [0.23737793, 0.2407982 ],\n",
       "        [0.60712488, 0.64017848]]),\n",
       " array([[0.44836224, 0.46071408],\n",
       "        [0.6356931 , 0.64812445],\n",
       "        [0.22375116, 0.23590635],\n",
       "        [0.4827157 , 0.45268136]]),\n",
       " array([[0.48004272, 0.47638811],\n",
       "        [0.65050087, 0.64640114],\n",
       "        [0.23989882, 0.24170105],\n",
       "        [0.61851247, 0.63185741]]),\n",
       " array([[0.47831782, 0.46732095],\n",
       "        [0.66703634, 0.64090738],\n",
       "        [0.24336782, 0.2335268 ],\n",
       "        [0.56801242, 0.602887  ]]),\n",
       " array([[0.47375409, 0.47024289],\n",
       "        [0.66143661, 0.6477578 ],\n",
       "        [0.24286501, 0.23557831],\n",
       "        [0.53741448, 0.6046575 ]]),\n",
       " array([[0.48561322, 0.41239983],\n",
       "        [0.64922061, 0.58423981],\n",
       "        [0.24539358, 0.20604412],\n",
       "        [0.64855948, 0.57961245]]),\n",
       " array([[0.47891907, 0.48125883],\n",
       "        [0.6449374 , 0.65940627],\n",
       "        [0.24173512, 0.24003059],\n",
       "        [0.62786086, 0.63568535]]),\n",
       " array([[0.41222323, 0.46059983],\n",
       "        [0.60501246, 0.64705665],\n",
       "        [0.20539315, 0.22999793],\n",
       "        [0.41953358, 0.50896224]]),\n",
       " array([[0.48165249, 0.47780178],\n",
       "        [0.67392044, 0.65312594],\n",
       "        [0.24317347, 0.23889298],\n",
       "        [0.63437533, 0.63633942]]),\n",
       " array([[0.44417907, 0.36032589],\n",
       "        [0.60782778, 0.52390834],\n",
       "        [0.22184549, 0.18000653],\n",
       "        [0.61064   , 0.52400652]]),\n",
       " array([[0.48442769, 0.47636364],\n",
       "        [0.64784846, 0.64237934],\n",
       "        [0.24212928, 0.23808431],\n",
       "        [0.64586088, 0.64017848]]),\n",
       " array([[0.46808977, 0.46838943],\n",
       "        [0.64312512, 0.63941015],\n",
       "        [0.23821992, 0.23410343],\n",
       "        [0.62890808, 0.6300087 ]]),\n",
       " array([[0.48241097, 0.47998162],\n",
       "        [0.65600705, 0.64804575],\n",
       "        [0.24148115, 0.23981173],\n",
       "        [0.64747061, 0.63875042]]),\n",
       " array([[0.45640183, 0.38252258],\n",
       "        [0.65581134, 0.57210286],\n",
       "        [0.22756756, 0.19101773],\n",
       "        [0.41102352, 0.24145629]]),\n",
       " array([[0.47195828, 0.47778006],\n",
       "        [0.65225225, 0.65677715],\n",
       "        [0.23587789, 0.24220429],\n",
       "        [0.58871523, 0.6244694 ]]),\n",
       " array([[0.46297535, 0.43859815],\n",
       "        [0.64934503, 0.61923707],\n",
       "        [0.23098602, 0.21908998],\n",
       "        [0.51969642, 0.53131006]]),\n",
       " array([[0.48857177, 0.47875169],\n",
       "        [0.65649118, 0.66334347],\n",
       "        [0.24444343, 0.23927062],\n",
       "        [0.64745275, 0.61413742]]),\n",
       " array([[0.38017849, 0.39694053],\n",
       "        [0.55565853, 0.57020904],\n",
       "        [0.18991681, 0.19829665],\n",
       "        [0.48044162, 0.51091366]]),\n",
       " array([[0.48473816, 0.48577743],\n",
       "        [0.64796129, 0.65650755],\n",
       "        [0.24221598, 0.24267712],\n",
       "        [0.63035686, 0.63353706]]),\n",
       " array([[0.41892663, 0.46594926],\n",
       "        [0.60115286, 0.64127997],\n",
       "        [0.20930697, 0.24113242],\n",
       "        [0.57272284, 0.63335469]]),\n",
       " array([[0.47897904, 0.46401478],\n",
       "        [0.66434158, 0.63814388],\n",
       "        [0.23869545, 0.23191899],\n",
       "        [0.60754158, 0.62670154]]),\n",
       " array([[0.4653541 , 0.43256365],\n",
       "        [0.66893354, 0.61254262],\n",
       "        [0.24424799, 0.21612428],\n",
       "        [0.55090922, 0.59952406]]),\n",
       " array([[0.47206358, 0.47995307],\n",
       "        [0.66247282, 0.66971519],\n",
       "        [0.24047351, 0.23924827],\n",
       "        [0.50624344, 0.62714341]]),\n",
       " array([[0.45351263, 0.41192769],\n",
       "        [0.64850325, 0.58958501],\n",
       "        [0.23162355, 0.20504246],\n",
       "        [0.38422091, 0.39216179]]),\n",
       " array([[0.48205858, 0.47589094],\n",
       "        [0.65959697, 0.66710032],\n",
       "        [0.24089222, 0.23771113],\n",
       "        [0.63280728, 0.62133962]]),\n",
       " array([[0.48419391, 0.47803832],\n",
       "        [0.65146534, 0.651037  ],\n",
       "        [0.24494487, 0.23891309],\n",
       "        [0.62572472, 0.6107154 ]]),\n",
       " array([[0.47676865, 0.46950561],\n",
       "        [0.66491563, 0.64662127],\n",
       "        [0.24322061, 0.23465666],\n",
       "        [0.61353697, 0.61250373]]),\n",
       " array([[0.43014039, 0.41364659],\n",
       "        [0.61070873, 0.58298597],\n",
       "        [0.21480662, 0.20658176],\n",
       "        [0.56993227, 0.55896426]]),\n",
       " array([[0.48518548, 0.47782136],\n",
       "        [0.66152272, 0.64919654],\n",
       "        [0.24332863, 0.2396049 ],\n",
       "        [0.64841677, 0.6271066 ]]),\n",
       " array([[0.4492917 , 0.42105263],\n",
       "        [0.6183945 , 0.59095193],\n",
       "        [0.2244833 , 0.21027971],\n",
       "        [0.58412953, 0.56308936]]),\n",
       " array([[0.48564534, 0.47322168],\n",
       "        [0.65657873, 0.64897276],\n",
       "        [0.24426041, 0.23651563],\n",
       "        [0.62590913, 0.59535534]]),\n",
       " array([[0.37922965, 0.44624529],\n",
       "        [0.54428461, 0.61141275],\n",
       "        [0.18942297, 0.22302067],\n",
       "        [0.52689425, 0.61099807]]),\n",
       " array([[0.48545677, 0.48031565],\n",
       "        [0.65717061, 0.66106728],\n",
       "        [0.2444221 , 0.24189271],\n",
       "        [0.61990889, 0.60174236]]),\n",
       " array([[0.45858741, 0.4524284 ],\n",
       "        [0.65229853, 0.63683488],\n",
       "        [0.22903767, 0.22609045],\n",
       "        [0.50504402, 0.57945481]]),\n",
       " array([[0.48679095, 0.47355979],\n",
       "        [0.6706275 , 0.65402681],\n",
       "        [0.24322399, 0.24282127],\n",
       "        [0.62533729, 0.61688908]]),\n",
       " array([[0.47586472, 0.45536754],\n",
       "        [0.6587358 , 0.62103085],\n",
       "        [0.23763628, 0.22738999],\n",
       "        [0.60604411, 0.59927502]]),\n",
       " array([[0.47099083, 0.47973682],\n",
       "        [0.65173193, 0.65080495],\n",
       "        [0.23758889, 0.24316417],\n",
       "        [0.61064   , 0.6279344 ]]),\n",
       " array([[0.37738881, 0.37549776],\n",
       "        [0.55033727, 0.54402043],\n",
       "        [0.18857204, 0.18764119],\n",
       "        [0.50680976, 0.52247313]]),\n",
       " array([[0.48579386, 0.47309574],\n",
       "        [0.65639029, 0.64626216],\n",
       "        [0.24299438, 0.23625583],\n",
       "        [0.57692789, 0.59464207]]),\n",
       " array([[0.4490504 , 0.45872929],\n",
       "        [0.62478121, 0.63447751],\n",
       "        [0.22446461, 0.22914003],\n",
       "        [0.60359193, 0.62668312]]),\n",
       " array([[0.48271371, 0.47397653],\n",
       "        [0.65086207, 0.64061008],\n",
       "        [0.24317111, 0.24273137],\n",
       "        [0.64616524, 0.64102666]]),\n",
       " array([[0.48046859, 0.45363173],\n",
       "        [0.65265888, 0.62560157],\n",
       "        [0.24174588, 0.22668225],\n",
       "        [0.62743784, 0.59550947]]),\n",
       " array([[0.46770855, 0.47988898],\n",
       "        [0.64186694, 0.66112957],\n",
       "        [0.24401539, 0.24075072],\n",
       "        [0.61237211, 0.55723846]]),\n",
       " array([[0.37433442, 0.41833628],\n",
       "        [0.54747963, 0.59102005],\n",
       "        [0.18694374, 0.20903656],\n",
       "        [0.52317632, 0.56857291]]),\n",
       " array([[0.48309335, 0.48297973],\n",
       "        [0.65511189, 0.65388761],\n",
       "        [0.24133907, 0.24466017],\n",
       "        [0.63626678, 0.60307759]]),\n",
       " array([[0.45761241, 0.46390612],\n",
       "        [0.64942104, 0.65294795],\n",
       "        [0.22836216, 0.23364478],\n",
       "        [0.47143646, 0.53175229]]),\n",
       " array([[0.44401896, 0.45909186],\n",
       "        [0.63613564, 0.64208962],\n",
       "        [0.22134848, 0.23362416],\n",
       "        [0.38422091, 0.45552857]]),\n",
       " array([[0.4688577 , 0.45891164],\n",
       "        [0.63688522, 0.63607985],\n",
       "        [0.23418402, 0.22901503],\n",
       "        [0.60703014, 0.50987354]]),\n",
       " array([[0.47638951, 0.46708513],\n",
       "        [0.64917204, 0.65177963],\n",
       "        [0.24286666, 0.23833173],\n",
       "        [0.62548491, 0.58287549]]),\n",
       " array([[0.41002232, 0.4654527 ],\n",
       "        [0.58082733, 0.63561347],\n",
       "        [0.2048907 , 0.23261842],\n",
       "        [0.57322001, 0.6176546 ]]),\n",
       " array([[0.48306805, 0.47918064],\n",
       "        [0.66061414, 0.64362152],\n",
       "        [0.24086969, 0.23930325],\n",
       "        [0.63455743, 0.61724394]]),\n",
       " array([[0.38996364, 0.45114053],\n",
       "        [0.5701829 , 0.62921517],\n",
       "        [0.19429723, 0.22537007],\n",
       "        [0.34636005, 0.39344828]]),\n",
       " array([[0.46593877, 0.47194469],\n",
       "        [0.67072135, 0.6591315 ],\n",
       "        [0.23252848, 0.23580374],\n",
       "        [0.55166756, 0.6313454 ]]),\n",
       " array([[0.3994458 , 0.41983852],\n",
       "        [0.57401803, 0.59314439],\n",
       "        [0.19955766, 0.20978181],\n",
       "        [0.5206374 , 0.56951274]]),\n",
       " array([[0.4673454 , 0.48316337],\n",
       "        [0.63674946, 0.65108321],\n",
       "        [0.23355079, 0.24392795],\n",
       "        [0.60784447, 0.63956424]]),\n",
       " array([[0.47501031, 0.47728022],\n",
       "        [0.65193276, 0.6486229 ],\n",
       "        [0.23840552, 0.2384646 ],\n",
       "        [0.6206525 , 0.62273033]]),\n",
       " array([[0.47710396, 0.47710892],\n",
       "        [0.6434167 , 0.64670887],\n",
       "        [0.24240559, 0.24477456],\n",
       "        [0.63650284, 0.63280728]]),\n",
       " array([[0.40920044, 0.30607311],\n",
       "        [0.57752565, 0.46097149],\n",
       "        [0.2043832 , 0.15293645],\n",
       "        [0.57613638, 0.46644602]]),\n",
       " array([[0.48182282, 0.48768608],\n",
       "        [0.64734707, 0.65627147],\n",
       "        [0.24100318, 0.24360784],\n",
       "        [0.64827404, 0.6525252 ]]),\n",
       " array([[0.38578377, 0.44034158],\n",
       "        [0.55634127, 0.61154121],\n",
       "        [0.19278774, 0.21995099],\n",
       "        [0.54862942, 0.60634765]]),\n",
       " array([[0.46933063, 0.48413713],\n",
       "        [0.63570123, 0.6571661 ],\n",
       "        [0.24100529, 0.24171621],\n",
       "        [0.63180257, 0.64250394]]),\n",
       " array([[0.48192386, 0.42276059],\n",
       "        [0.64844527, 0.59121968],\n",
       "        [0.24099468, 0.21118593],\n",
       "        [0.63315402, 0.57710586]]),\n",
       " array([[0.47693366, 0.47432793],\n",
       "        [0.65483206, 0.65135546],\n",
       "        [0.23785976, 0.23658629],\n",
       "        [0.6178785 , 0.62206314]]),\n",
       " array([[0.47386979, 0.42016017],\n",
       "        [0.65088792, 0.60587097],\n",
       "        [0.23919604, 0.20984695],\n",
       "        [0.60130308, 0.5367666 ]]),\n",
       " array([[0.4828706 , 0.48199918],\n",
       "        [0.65651214, 0.65683039],\n",
       "        [0.24218201, 0.24367843],\n",
       "        [0.61793446, 0.62093114]]),\n",
       " array([[0.48192386, 0.42276059],\n",
       "        [0.64844527, 0.59121968],\n",
       "        [0.24098389, 0.21122444],\n",
       "        [0.63315402, 0.57710586]]),\n",
       " array([[0.47859992, 0.478206  ],\n",
       "        [0.64695891, 0.644189  ],\n",
       "        [0.23918471, 0.23890946],\n",
       "        [0.63824355, 0.6359943 ]]),\n",
       " array([[0.47050502, 0.39173893],\n",
       "        [0.64437855, 0.56760019],\n",
       "        [0.2350228 , 0.19574154],\n",
       "        [0.60651834, 0.52750856]]),\n",
       " array([[0.48103587, 0.48241165],\n",
       "        [0.65167772, 0.65349771],\n",
       "        [0.24285184, 0.24702558],\n",
       "        [0.63592162, 0.63079638]]),\n",
       " array([[0.4847322 , 0.46752648],\n",
       "        [0.67070816, 0.63823554],\n",
       "        [0.24248889, 0.23353977],\n",
       "        [0.63140028, 0.62566938]]),\n",
       " array([[0.47972816, 0.4800008 ],\n",
       "        [0.66731637, 0.65260897],\n",
       "        [0.23958373, 0.23973092],\n",
       "        [0.5265339 , 0.63831598]]),\n",
       " array([[0.47273318, 0.47634524],\n",
       "        [0.65635369, 0.64798506],\n",
       "        [0.23646178, 0.2379914 ],\n",
       "        [0.4424908 , 0.62287851]]),\n",
       " array([[0.47607348, 0.47070522],\n",
       "        [0.66859078, 0.63680146],\n",
       "        [0.23847225, 0.23515055],\n",
       "        [0.5611713 , 0.63225944]]),\n",
       " array([[0.46623094, 0.46060302],\n",
       "        [0.66894004, 0.66603569],\n",
       "        [0.23978684, 0.2300599 ],\n",
       "        [0.42865254, 0.44603618]]),\n",
       " array([[0.47000211, 0.4910778 ],\n",
       "        [0.65885417, 0.66734925],\n",
       "        [0.23482588, 0.24570105],\n",
       "        [0.60612   , 0.65158478]]),\n",
       " array([[0.48169545, 0.47644401],\n",
       "        [0.65078049, 0.65754863],\n",
       "        [0.24242123, 0.23869827],\n",
       "        [0.61552398, 0.55622136]]),\n",
       " array([[0.47871828, 0.47767112],\n",
       "        [0.65722501, 0.65013633],\n",
       "        [0.24292421, 0.23855236],\n",
       "        [0.55947106, 0.61789715]]),\n",
       " array([[0.48185659, 0.45860383],\n",
       "        [0.64986554, 0.62958993],\n",
       "        [0.2408076 , 0.22913683],\n",
       "        [0.64562805, 0.61785984]]),\n",
       " array([[0.48490574, 0.4842133 ],\n",
       "        [0.65766689, 0.66825317],\n",
       "        [0.24574601, 0.243211  ],\n",
       "        [0.64320543, 0.63581258]]),\n",
       " array([[0.46454575, 0.44495014],\n",
       "        [0.65418165, 0.6286194 ],\n",
       "        [0.23156345, 0.22235856],\n",
       "        [0.50071011, 0.46128417]]),\n",
       " array([[0.472419  , 0.47339559],\n",
       "        [0.64516753, 0.66711151],\n",
       "        [0.23657557, 0.2365321 ],\n",
       "        [0.53983373, 0.59137492]]),\n",
       " array([[0.46287097, 0.47135406],\n",
       "        [0.64053368, 0.65284426],\n",
       "        [0.23129629, 0.23545035],\n",
       "        [0.5936191 , 0.6054746 ]]),\n",
       " array([[0.46338374, 0.48603096],\n",
       "        [0.63579828, 0.66633021],\n",
       "        [0.23777035, 0.24338115],\n",
       "        [0.62756661, 0.64261191]]),\n",
       " array([[0.36277248, 0.3868137 ],\n",
       "        [0.53598408, 0.56784155],\n",
       "        [0.1811913 , 0.19324634],\n",
       "        [0.44246711, 0.52460197]]),\n",
       " array([[0.48364134, 0.49059219],\n",
       "        [0.66889653, 0.66716166],\n",
       "        [0.24359234, 0.24683563],\n",
       "        [0.58536181, 0.61316142]]),\n",
       " array([[0.47248949, 0.47926989],\n",
       "        [0.64783803, 0.64326721],\n",
       "        [0.24032136, 0.2426414 ],\n",
       "        [0.63941963, 0.60200961]]),\n",
       " array([[0.48293757, 0.48936087],\n",
       "        [0.6522247 , 0.65324057],\n",
       "        [0.24324439, 0.24525654],\n",
       "        [0.64850597, 0.65574459]]),\n",
       " array([[0.36296939, 0.45719539],\n",
       "        [0.54682672, 0.63678951],\n",
       "        [0.18113576, 0.22843355],\n",
       "        [0.42468809, 0.56963263]]),\n",
       " array([[0.47350934, 0.48089021],\n",
       "        [0.67169122, 0.65248911],\n",
       "        [0.23651412, 0.24640786],\n",
       "        [0.47207508, 0.6015514 ]]),\n",
       " array([[0.48181997, 0.45835822],\n",
       "        [0.67421579, 0.64099187],\n",
       "        [0.24071794, 0.22898495],\n",
       "        [0.55283427, 0.56090843]]),\n",
       " array([[0.48950316, 0.4869922 ],\n",
       "        [0.66754156, 0.66136219],\n",
       "        [0.24466558, 0.24340042],\n",
       "        [0.61572985, 0.63028357]]),\n",
       " array([[0.47805036, 0.44561381],\n",
       "        [0.65021746, 0.61608676],\n",
       "        [0.23883444, 0.22240655],\n",
       "        [0.57647288, 0.57085037]]),\n",
       " array([[0.47998841, 0.48094247],\n",
       "        [0.65747863, 0.64456845],\n",
       "        [0.23966983, 0.24397996],\n",
       "        [0.56554506, 0.63875042]]),\n",
       " array([[0.44977245, 0.35453857],\n",
       "        [0.61974802, 0.52532751],\n",
       "        [0.22475036, 0.17718522],\n",
       "        [0.59614488, 0.49504718]]),\n",
       " array([[0.47391863, 0.47921323],\n",
       "        [0.63940017, 0.64675716],\n",
       "        [0.24264449, 0.23945049],\n",
       "        [0.63141857, 0.63072315]]),\n",
       " array([[0.48373531, 0.40062458],\n",
       "        [0.63811388, 0.56945348],\n",
       "        [0.24412688, 0.20021396],\n",
       "        [0.62855918, 0.56464025]]),\n",
       " array([[0.48089638, 0.47710964],\n",
       "        [0.64089122, 0.64847709],\n",
       "        [0.24587824, 0.23817438],\n",
       "        [0.61962983, 0.63472128]]),\n",
       " array([[0.45698643, 0.47610592],\n",
       "        [0.6452942 , 0.65671902],\n",
       "        [0.22761933, 0.23854511],\n",
       "        [0.4279771 , 0.59510482]]),\n",
       " array([[0.48400396, 0.47525961],\n",
       "        [0.66649635, 0.64917634],\n",
       "        [0.244241  , 0.23757475],\n",
       "        [0.62730904, 0.61785984]]),\n",
       " array([[0.4774497 , 0.45646592],\n",
       "        [0.67590586, 0.63088867],\n",
       "        [0.24021424, 0.22812926],\n",
       "        [0.52208928, 0.61533677]]),\n",
       " array([[0.47048095, 0.48330855],\n",
       "        [0.6589895 , 0.65088149],\n",
       "        [0.23385162, 0.2422691 ],\n",
       "        [0.46476762, 0.65083861]]),\n",
       " array([[0.48322107, 0.45848103],\n",
       "        [0.65893428, 0.64186299],\n",
       "        [0.24316758, 0.22915328],\n",
       "        [0.60996104, 0.6106777 ]]),\n",
       " array([[0.47354245, 0.48270296],\n",
       "        [0.64707548, 0.65741193],\n",
       "        [0.23654955, 0.24115138],\n",
       "        [0.61726261, 0.64232396]]),\n",
       " array([[0.46590969, 0.45693183],\n",
       "        [0.6474539 , 0.64114327],\n",
       "        [0.23250787, 0.22817219],\n",
       "        [0.47405597, 0.55010903]]),\n",
       " array([[0.47758835, 0.48208032],\n",
       "        [0.65846824, 0.66112584],\n",
       "        [0.23805173, 0.24523112],\n",
       "        [0.49652762, 0.58067557]]),\n",
       " array([[0.48056745, 0.44243196],\n",
       "        [0.65456978, 0.61544957],\n",
       "        [0.24010529, 0.22110553],\n",
       "        [0.64654101, 0.61237211]]),\n",
       " array([[0.46935927, 0.47692308],\n",
       "        [0.65986295, 0.66782609],\n",
       "        [0.23380297, 0.24318518],\n",
       "        [0.61120529, 0.63481229]]),\n",
       " array([[0.45127646, 0.45920938],\n",
       "        [0.65140212, 0.63906419],\n",
       "        [0.22527475, 0.22942073],\n",
       "        [0.44111558, 0.56280702]]),\n",
       " array([[0.4804732 , 0.47162935],\n",
       "        [0.66234519, 0.64320628],\n",
       "        [0.23994867, 0.23999386],\n",
       "        [0.54986263, 0.62776892]]),\n",
       " array([[0.43926899, 0.48093119],\n",
       "        [0.61271676, 0.65092724],\n",
       "        [0.21948624, 0.2403191 ],\n",
       "        [0.58563536, 0.60191418]]),\n",
       " array([[0.48657234, 0.47324746],\n",
       "        [0.66042818, 0.64563913],\n",
       "        [0.24313139, 0.2365345 ],\n",
       "        [0.63075977, 0.61856838]]),\n",
       " array([[0.46287097, 0.47135406],\n",
       "        [0.64053368, 0.65284426],\n",
       "        [0.23123987, 0.2352795 ],\n",
       "        [0.5936191 , 0.6054746 ]]),\n",
       " array([[0.4654783 , 0.47374108],\n",
       "        [0.63685271, 0.64714401],\n",
       "        [0.23264671, 0.24156543],\n",
       "        [0.62150665, 0.6234894 ]]),\n",
       " array([[0.47633027, 0.41502676],\n",
       "        [0.66090312, 0.59030837],\n",
       "        [0.23762677, 0.207375  ],\n",
       "        [0.62226707, 0.55567153]]),\n",
       " array([[0.48150518, 0.47866633],\n",
       "        [0.65179868, 0.6500185 ],\n",
       "        [0.24319368, 0.23896036],\n",
       "        [0.62600131, 0.61698248]]),\n",
       " array([[0.47501031, 0.47728022],\n",
       "        [0.65193276, 0.6486229 ],\n",
       "        [0.23892533, 0.23851324],\n",
       "        [0.6206525 , 0.62273033]]),\n",
       " array([[0.4826665 , 0.48377355],\n",
       "        [0.66293565, 0.66007022],\n",
       "        [0.24174295, 0.24546935],\n",
       "        [0.60338243, 0.61524314]]),\n",
       " array([[0.4367682 , 0.48098673],\n",
       "        [0.60437031, 0.64927571],\n",
       "        [0.21810732, 0.24219069],\n",
       "        [0.5661878 , 0.56731119]]),\n",
       " array([[0.47825915, 0.4811466 ],\n",
       "        [0.64092213, 0.64066032],\n",
       "        [0.23895608, 0.24318874],\n",
       "        [0.64068391, 0.64500079]]),\n",
       " array([[0.45657794, 0.45662664],\n",
       "        [0.65670511, 0.65318244],\n",
       "        [0.22761784, 0.22649503],\n",
       "        [0.54284657, 0.48224343]]),\n",
       " array([[0.48239605, 0.47585993],\n",
       "        [0.65585947, 0.65221096],\n",
       "        [0.24572172, 0.23796158],\n",
       "        [0.6058733 , 0.61569242]]),\n",
       " array([[0.45756096, 0.32598711],\n",
       "        [0.62682024, 0.49327297],\n",
       "        [0.22857606, 0.16280342],\n",
       "        [0.61728128, 0.46412287]]),\n",
       " array([[0.48029836, 0.47213629],\n",
       "        [0.65498369, 0.64509223],\n",
       "        [0.24425868, 0.23592383],\n",
       "        [0.63277078, 0.6292201 ]]),\n",
       " array([[0.43382029, 0.48163455],\n",
       "        [0.62331396, 0.65195798],\n",
       "        [0.21676587, 0.24467098],\n",
       "        [0.51376653, 0.63632126]]),\n",
       " array([[0.48014483, 0.47936386],\n",
       "        [0.66006192, 0.65218539],\n",
       "        [0.24080733, 0.23996398],\n",
       "        [0.56691018, 0.60553157]]),\n",
       " array([[0.48392541, 0.45222617],\n",
       "        [0.65278907, 0.62387546],\n",
       "        [0.24367691, 0.2259215 ],\n",
       "        [0.63981723, 0.60342053]]),\n",
       " array([[0.48801536, 0.48232644],\n",
       "        [0.65868315, 0.65197653],\n",
       "        [0.24622684, 0.24404494],\n",
       "        [0.62234121, 0.63013699]]),\n",
       " array([[0.41423498, 0.4649733 ],\n",
       "        [0.58858781, 0.64615517],\n",
       "        [0.20696304, 0.23232367],\n",
       "        [0.57236466, 0.60984782]]),\n",
       " array([[0.47584947, 0.47367026],\n",
       "        [0.650272  , 0.64235535],\n",
       "        [0.23782439, 0.23698162],\n",
       "        [0.6234894 , 0.61793446]]),\n",
       " array([[0.42494943, 0.46746542],\n",
       "        [0.61196994, 0.63995899],\n",
       "        [0.21229244, 0.23353069],\n",
       "        [0.53057242, 0.63324524]]),\n",
       " array([[0.48301973, 0.47937861],\n",
       "        [0.66350507, 0.64760818],\n",
       "        [0.24141017, 0.23959882],\n",
       "        [0.62282294, 0.64566388]]),\n",
       " array([[0.29029534, 0.44298189],\n",
       "        [0.45479833, 0.62543817],\n",
       "        [0.14503438, 0.22136959],\n",
       "        [0.41503243, 0.5757403 ]]),\n",
       " array([[0.47866672, 0.4726578 ],\n",
       "        [0.64666205, 0.64511924],\n",
       "        [0.2409453 , 0.23622839],\n",
       "        [0.64289974, 0.63379229]]),\n",
       " array([[0.4635563 , 0.3778887 ],\n",
       "        [0.65428555, 0.54608962],\n",
       "        [0.23166695, 0.1887719 ],\n",
       "        [0.60313476, 0.54607412]]),\n",
       " array([[0.47584356, 0.48261795],\n",
       "        [0.66617197, 0.65012743],\n",
       "        [0.2377427 , 0.24202326],\n",
       "        [0.58362034, 0.64709535]]),\n",
       " array([[0.3013818 , 0.42445751],\n",
       "        [0.46229996, 0.59283388],\n",
       "        [0.15059449, 0.21210998],\n",
       "        [0.45838853, 0.58034105]]),\n",
       " array([[0.47489217, 0.46941224],\n",
       "        [0.64274429, 0.63978822],\n",
       "        [0.24240521, 0.23439621],\n",
       "        [0.63833409, 0.62145098]]),\n",
       " array([[0.35169255, 0.44799879],\n",
       "        [0.53045552, 0.62725536],\n",
       "        [0.17562265, 0.22387443],\n",
       "        [0.456134  , 0.57550254]]),\n",
       " array([[0.48617016, 0.47857473],\n",
       "        [0.65930702, 0.65359814],\n",
       "        [0.24257709, 0.24023198],\n",
       "        [0.58696252, 0.61632841]]),\n",
       " array([[0.47795877, 0.35013046],\n",
       "        [0.65842515, 0.51761444],\n",
       "        [0.23886146, 0.1749561 ],\n",
       "        [0.61563628, 0.5023985 ]]),\n",
       " array([[0.49233421, 0.47239795],\n",
       "        [0.66369064, 0.63971952],\n",
       "        [0.24600501, 0.23601684],\n",
       "        [0.64252194, 0.62821011]]),\n",
       " array([[0.38645154, 0.46719553],\n",
       "        [0.57800055, 0.64639492],\n",
       "        [0.19310021, 0.2333279 ],\n",
       "        [0.44346147, 0.53563665]]),\n",
       " array([[0.48222955, 0.48466024],\n",
       "        [0.65786766, 0.66686734],\n",
       "        [0.24467718, 0.24661514],\n",
       "        [0.52886245, 0.5936191 ]]),\n",
       " array([[0.46243169, 0.37245144],\n",
       "        [0.63405705, 0.55769294],\n",
       "        [0.23101819, 0.18609411],\n",
       "        [0.60757945, 0.49829151]]),\n",
       " array([[0.48548678, 0.48154123],\n",
       "        [0.65636243, 0.65338494],\n",
       "        [0.24256525, 0.2433905 ],\n",
       "        [0.63306279, 0.63064991]]),\n",
       " array([[0.47021951, 0.41481406],\n",
       "        [0.65413977, 0.58551569],\n",
       "        [0.23486136, 0.20726971],\n",
       "        [0.58326762, 0.5678522 ]]),\n",
       " array([[0.48592574, 0.48158836],\n",
       "        [0.66329927, 0.65573046],\n",
       "        [0.24406318, 0.2438832 ],\n",
       "        [0.60553157, 0.62397033]]),\n",
       " array([[0.36871846, 0.43632097],\n",
       "        [0.55568417, 0.61585502],\n",
       "        [0.18419095, 0.21789873],\n",
       "        [0.4158906 , 0.54825905]]),\n",
       " array([[0.46877689, 0.48047795],\n",
       "        [0.6604786 , 0.66528099],\n",
       "        [0.23546216, 0.24038398],\n",
       "        [0.45908448, 0.58596738]]),\n",
       " array([[0.37631674, 0.47312763],\n",
       "        [0.54905914, 0.64670609],\n",
       "        [0.18794926, 0.23644992],\n",
       "        [0.53695475, 0.62732744]]),\n",
       " array([[0.4788233 , 0.48643969],\n",
       "        [0.65351755, 0.65454903],\n",
       "        [0.24030337, 0.24304157],\n",
       "        [0.64046734, 0.62581693]]),\n",
       " array([[0.48144677, 0.43033763],\n",
       "        [0.67247666, 0.60533526],\n",
       "        [0.24050427, 0.21416979],\n",
       "        [0.529454  , 0.47369206]]),\n",
       " array([[0.47566429, 0.48019098],\n",
       "        [0.66229646, 0.6610819 ],\n",
       "        [0.24302626, 0.24472312],\n",
       "        [0.60349671, 0.62563249]]),\n",
       " array([[0.45029903, 0.46639652],\n",
       "        [0.6289323 , 0.64951689],\n",
       "        [0.22481835, 0.2329233 ],\n",
       "        [0.53448399, 0.63092453]]),\n",
       " array([[0.46010049, 0.47934169],\n",
       "        [0.65015835, 0.649571  ],\n",
       "        [0.23635171, 0.23938465],\n",
       "        [0.53465177, 0.63140028]]),\n",
       " array([[0.47832737, 0.41954971],\n",
       "        [0.65969569, 0.59312697],\n",
       "        [0.24128829, 0.20967956],\n",
       "        [0.55538626, 0.56881298]]),\n",
       " array([[0.47735431, 0.47029283],\n",
       "        [0.65163339, 0.65741536],\n",
       "        [0.2467539 , 0.23416756],\n",
       "        [0.59230441, 0.60480959]]),\n",
       " array([[0.4625929 , 0.47666114],\n",
       "        [0.67010309, 0.64743555],\n",
       "        [0.2403405 , 0.23796864],\n",
       "        [0.40107428, 0.64120699]]),\n",
       " array([[0.45904453, 0.47636041],\n",
       "        [0.64616798, 0.64662117],\n",
       "        [0.2375403 , 0.2379249 ],\n",
       "        [0.54104036, 0.64120699]]),\n",
       " array([[0.46162465, 0.441097  ],\n",
       "        [0.64629401, 0.6137486 ],\n",
       "        [0.23005814, 0.22039775],\n",
       "        [0.5899978 , 0.59868079]]),\n",
       " array([[0.47036912, 0.48424514],\n",
       "        [0.64409923, 0.65479361],\n",
       "        [0.24306972, 0.24209508],\n",
       "        [0.60536065, 0.63108925]]),\n",
       " array([[0.47696725, 0.44205463],\n",
       "        [0.66212648, 0.61973981],\n",
       "        [0.23658895, 0.22086062],\n",
       "        [0.46738707, 0.55129874]]),\n",
       " array([[0.48818626, 0.47315046],\n",
       "        [0.66945235, 0.6473147 ],\n",
       "        [0.24379457, 0.23648739],\n",
       "        [0.53731002, 0.61561756]]),\n",
       " array([[0.47392018, 0.43579056],\n",
       "        [0.6458106 , 0.60385039],\n",
       "        [0.23686494, 0.21778453],\n",
       "        [0.63244211, 0.60025152]]),\n",
       " array([[0.47163803, 0.46876984],\n",
       "        [0.64337153, 0.63829902],\n",
       "        [0.23560701, 0.23421322],\n",
       "        [0.60212412, 0.63149173]]),\n",
       " array([[0.40413617, 0.439187  ],\n",
       "        [0.57206167, 0.61148887],\n",
       "        [0.20181902, 0.21947742],\n",
       "        [0.52725442, 0.59481564]]),\n",
       " array([[0.48409122, 0.48610766],\n",
       "        [0.77727024, 0.66338427],\n",
       "        [0.14187844, 0.24467053],\n",
       "        [0.57761974, 0.62815498]]),\n",
       " array([[0.47080043, 0.47878012],\n",
       "        [0.66003351, 0.65087369],\n",
       "        [0.23455518, 0.23929552],\n",
       "        [0.60218136, 0.60964019]]),\n",
       " array([[0.46988077, 0.47345649],\n",
       "        [0.63901015, 0.64200731],\n",
       "        [0.24373735, 0.24052981],\n",
       "        [0.61116762, 0.62923845]]),\n",
       " array([[0.46818953, 0.42916329],\n",
       "        [0.6612036 , 0.60649361],\n",
       "        [0.23325773, 0.21395318],\n",
       "        [0.46179267, 0.44879039]]),\n",
       " array([[0.48128102, 0.4785973 ],\n",
       "        [0.65182245, 0.65454545],\n",
       "        [0.24032871, 0.23912606],\n",
       "        [0.61052689, 0.62469109]]),\n",
       " array([[0.4809425 , 0.39388969],\n",
       "        [0.65692168, 0.56787277],\n",
       "        [0.24423671, 0.19679406],\n",
       "        [0.62304517, 0.54566113]]),\n",
       " array([[0.4912128 , 0.4817332 ],\n",
       "        [0.66523297, 0.65728209],\n",
       "        [0.24541115, 0.24073584],\n",
       "        [0.62241535, 0.62973371]]),\n",
       " array([[0.36064767, 0.37844889],\n",
       "        [0.5303994 , 0.54719515],\n",
       "        [0.18019665, 0.18911089],\n",
       "        [0.51154137, 0.54437937]]),\n",
       " array([[0.47975021, 0.47550455],\n",
       "        [0.64851796, 0.64116109],\n",
       "        [0.2406468 , 0.23756546],\n",
       "        [0.63355529, 0.63887707]]),\n",
       " array([[0.43308524, 0.38754651],\n",
       "        [0.62194138, 0.56921049],\n",
       "        [0.21629752, 0.19368166],\n",
       "        [0.53093079, 0.51393908]]),\n",
       " array([[0.48818862, 0.47575905],\n",
       "        [0.66821498, 0.66969119],\n",
       "        [0.24433101, 0.23713927],\n",
       "        [0.58972593, 0.58960939]]),\n",
       " array([[0.43033004, 0.42445093],\n",
       "        [0.60217772, 0.60027882],\n",
       "        [0.21479121, 0.21213285],\n",
       "        [0.5172958 , 0.59203344]]),\n",
       " array([[0.47972156, 0.48156709],\n",
       "        [0.65251162, 0.65010402],\n",
       "        [0.24161082, 0.24065011],\n",
       "        [0.62028079, 0.64505458]]),\n",
       " array([[0.41190884, 0.45641188],\n",
       "        [0.57747703, 0.62805607],\n",
       "        [0.20494017, 0.22802698],\n",
       "        [0.42831489, 0.62217438]]),\n",
       " array([[0.47725544, 0.48212946],\n",
       "        [0.67082231, 0.65370817],\n",
       "        [0.24467197, 0.24524495],\n",
       "        [0.6353399 , 0.64578925]]),\n",
       " array([[0.47313079, 0.38525589],\n",
       "        [0.64856511, 0.55817101],\n",
       "        [0.23634726, 0.19249189],\n",
       "        [0.56026095, 0.5406869 ]]),\n",
       " array([[0.48887205, 0.46977691],\n",
       "        [0.66946339, 0.64550748],\n",
       "        [0.24506888, 0.2347502 ],\n",
       "        [0.5838554 , 0.61276688]]),\n",
       " array([[0.42338754, 0.45561775],\n",
       "        [0.60135633, 0.62836464],\n",
       "        [0.21129602, 0.22750264],\n",
       "        [0.46518181, 0.52517571]]),\n",
       " array([[0.483822  , 0.48168837],\n",
       "        [0.64874282, 0.64029492],\n",
       "        [0.24559556, 0.24784238],\n",
       "        [0.62443244, 0.64711322]]),\n",
       " array([[0.43886967, 0.35395903],\n",
       "        [0.62215192, 0.52498821],\n",
       "        [0.21925873, 0.17681675],\n",
       "        [0.50952651, 0.49172215]]),\n",
       " array([[0.4811002 , 0.48092213],\n",
       "        [0.65375655, 0.64736711],\n",
       "        [0.24262269, 0.2413061 ],\n",
       "        [0.56102976, 0.6242846 ]]),\n",
       " array([[0.48000085, 0.37097346],\n",
       "        [0.65173087, 0.53894562],\n",
       "        [0.23982798, 0.18538921],\n",
       "        [0.61443745, 0.53799917]]),\n",
       " array([[0.48544531, 0.46814736],\n",
       "        [0.64824486, 0.6321833 ],\n",
       "        [0.24296277, 0.23411668],\n",
       "        [0.63550356, 0.63537627]]),\n",
       " array([[0.44384035, 0.47963442],\n",
       "        [0.62025503, 0.65745667],\n",
       "        [0.22154234, 0.23943929],\n",
       "        [0.58293432, 0.61858702]]),\n",
       " array([[0.46085432, 0.48118989],\n",
       "        [0.63144345, 0.64870336],\n",
       "        [0.24215318, 0.24050581],\n",
       "        [0.60250566, 0.63309929]]),\n",
       " array([[0.44373201, 0.35361628],\n",
       "        [0.61018478, 0.52113438],\n",
       "        [0.22162757, 0.17667189],\n",
       "        [0.58089193, 0.50613448]]),\n",
       " array([[0.47637232, 0.47602178],\n",
       "        [0.6470191 , 0.64313142],\n",
       "        [0.24119798, 0.24381598],\n",
       "        [0.63742815, 0.63435712]]),\n",
       " array([[0.45666016, 0.46507115],\n",
       "        [0.67295241, 0.65490476],\n",
       "        [0.24645378, 0.23760362],\n",
       "        [0.27942535, 0.48827081]]),\n",
       " array([[0.48357506, 0.4842464 ],\n",
       "        [0.67253118, 0.68567317],\n",
       "        [0.24987214, 0.24182853],\n",
       "        [0.58436442, 0.6123345 ]]),\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fusion_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3631afa141bb46bf8eb86e2ea4f4c916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fusion_scores_train = get_fusion_scores_multi_process(iris_norm_L, iris_norm_R, img_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the features to a file\n",
    "# np.savez('temp_data/fusion_scores_seg.npz',\n",
    "#          fusion_scores_train=fusion_scores_train, \n",
    "#          fusion_scores_test=fusion_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features from the file\n",
    "with np.load('temp_data/fusion_scores_enhanced.npz') as data:\n",
    "    fusion_scores_train = data['fusion_scores_train']\n",
    "    fusion_scores_test = data['fusion_scores_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification by machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"sklearnex\")\n",
    "logger.setLevel(logging.WARNING)  # Set the logger's logging level to WARNING or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = feature_preprocessing(features_train_a, features_test_a, features_train_b, features_test_b, fusion_scores_train, fusion_scores_test, use_fusion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for best hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   8.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   7.7s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   7.2s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   7.1s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   7.4s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  26.8s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  26.8s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  27.6s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  25.6s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  28.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   5.6s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   5.9s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   6.2s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   6.2s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   7.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   7.6s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   7.7s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   7.3s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   7.3s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   7.3s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  26.6s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  27.7s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  29.4s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  29.6s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  30.9s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   8.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   7.8s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   8.2s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   7.9s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   7.7s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  20.6s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  21.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  21.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  20.9s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  20.2s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  27.7s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  28.8s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  26.6s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  25.2s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  29.4s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   6.2s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.5s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.3s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.7s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  11.6s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.6s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  24.3s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  24.6s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  28.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  26.6s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  23.6s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   7.8s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   7.4s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   7.6s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   8.1s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   8.1s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   8.1s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   7.9s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   8.2s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   7.9s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  27.2s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  26.5s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  28.4s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  25.9s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  28.5s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   5.7s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   5.7s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   5.9s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   5.7s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   7.4s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   7.6s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   7.6s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   7.5s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   7.4s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  26.6s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  26.8s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  28.4s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  27.7s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  29.6s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   7.7s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   8.5s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   8.4s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   8.5s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   5.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  28.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  29.5s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  29.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  27.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  28.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  27.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  27.2s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  25.6s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  25.5s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  30.5s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.6s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  18.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  18.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  19.4s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  18.3s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  18.2s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  26.2s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  24.4s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  25.6s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  26.1s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  24.7s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   6.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   6.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   8.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   7.4s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   7.5s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   7.5s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   7.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   7.2s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  27.9s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  26.3s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  29.4s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  25.7s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  29.3s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   5.8s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.3s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.4s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   8.1s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   7.7s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   7.6s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   7.5s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   7.8s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  26.9s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  27.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  28.7s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  27.9s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  31.1s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   8.3s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   8.5s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   8.6s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   7.4s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  39.2s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  41.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  40.2s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  41.3s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  39.8s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  27.8s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  28.5s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  27.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  26.7s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  31.4s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.5s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.7s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.5s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=  27.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.1s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.1s\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "param = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid_search = get_best_param(X_train_scaled, y_train_final, svm.SVC(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "Best Score:  0.8922500000000001\n",
      "Best Estimator:  SVC(C=10, gamma=0.01, kernel='poly')\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters and score\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "print(\"Best Estimator: \", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.0001, verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an SVM classifier with a Gaussian kernel\n",
    "clf = svm.SVC(kernel='rbf', C=10, gamma=0.0001, verbose=2)\n",
    "\n",
    "# train the classifier\n",
    "clf.fit(X_train_scaled, y_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(clf, open('Model/svm_VGG16_fusion_enha.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open('Model/svm_VGG16_fusion_enha.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an SVM classifier with a Gaussian kernel\n",
    "clf = svm.SVC(kernel='rbf', C=10, gamma=0.0001, verbose=2)\n",
    "\n",
    "X = np.concatenate((X_train_scaled, X_test_scaled), axis=0)\n",
    "y = np.concatenate((y_train_final, y_test_final), axis=0)\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro']\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.93325 0.92    0.9325  0.92225 0.90525]\n",
      "Precision: [0.93338272 0.92024206 0.93259733 0.92259325 0.90694298]\n",
      "Recall: [0.93325 0.92    0.9325  0.92225 0.90525]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', scores['test_accuracy'])\n",
    "print('Precision:', scores['test_precision_macro'])\n",
    "print('Recall:', scores['test_recall_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      2000\n",
      "           1       0.96      0.88      0.92      2000\n",
      "\n",
      "    accuracy                           0.92      4000\n",
      "   macro avg       0.92      0.92      0.92      4000\n",
      "weighted avg       0.92      0.92      0.92      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEWCAYAAAAQBZBVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAifElEQVR4nO3dd7xU5Z3H8c/3ghJUrFgIxRbAgoLKIgZrbNjWssYSo+ga0VXTm22j0agbEzVrbDFqrItijJHYidEYC5EiEuxYCFyxAAYLRcDf/nHOxQEuc+dcZu7MnfN953VezDznOc95BvWXp5zzPIoIzMzypqHaFTAzqwYHPzPLJQc/M8slBz8zyyUHPzPLJQc/M8slB786I6mzpD9JmiPprpUo5xhJj5SzbtUg6UFJw6pdD6s9Dn5VIulrksZJ+ljSjPQ/0p3LUPThwIbAehHx1dYWEhG3R8Q+ZajPUiTtLikk3bNMev80/fESyzlP0m0t5YuI/SLi5lZW1+qYg18VSPoe8CvgIpJA1Qu4Gji4DMVvDLwaEYvKUFalvA/sJGm9grRhwKvluoES/vfbViwifLThAawFfAx8tUieTiTB8e30+BXQKT23OzAd+D7wHjADOCE991PgU2Bheo8TgfOA2wrK3gQIoGP6/XjgDeAj4E3gmIL0Jwuu+zIwFpiT/vnlgnOPAxcAT6XlPAJ0XcFva6r/tcBpaVoHoBH4CfB4Qd7/BaYBHwLjgV3S9KHL/M7nC+pxYVqPecCX0rRvpOevAe4uKP/nwKOAqv3vhY+2P/z/jG1vJ+ALwD1F8pwNDAYGAP2BQcA5Bec3Igmi3UkC3FWS1omIc0lak3dGxBoRcUOxikhaHbgC2C8iupAEuInN5FsXuD/Nux5wGXD/Mi23rwEnABsAqwI/KHZv4BbguPTzvsBkkkBfaCzJ38G6wP8Bd0n6QkQ8tMzv7F9wzbHAcKALMHWZ8r4PbCPpeEm7kPzdDYsIv+OZQw5+bW89YGYU75YeA5wfEe9FxPskLbpjC84vTM8vjIgHSFo/fVtZn8+AfpI6R8SMiHihmTwHAK9FxK0RsSgiRgAvAwcV5PldRLwaEfOAkSRBa4Ui4mlgXUl9SYLgLc3kuS0iZqX3vJSkRdzS77wpIl5Ir1m4THlzSf4eLwNuA74ZEdNbKM/qlINf25sFdJXUsUieL7J0q2VqmrakjGWC51xgjawViYhPgCOBU4AZku6XtEUJ9WmqU/eC7++0oj63AqcDe9BMS1jSDyS9lM5c/4uktdu1hTKnFTsZEX8n6eaLJEhbTjn4tb1ngAXAIUXyvE0ycdGkF8t3CUv1CbBawfeNCk9GxMMRsTfQjaQ199sS6tNUp8ZW1qnJrcCpwANpq2yJtFv6I+AIYJ2IWJtkvFFNVV9BmUW7sJJOI2lBvp2Wbznl4NfGImIOycD+VZIOkbSapFUk7SfpkjTbCOAcSetL6prmb/GxjhWYCOwqqZektYAzm05I2lDSwenY3wKS7vNnzZTxANAnfTyno6Qjga2A+1pZJwAi4k1gN5IxzmV1ARaRzAx3lPQTYM2C8+8Cm2SZ0ZXUB/gZ8HWS7u+PJA1oXe2tvXPwq4J0/Op7JJMY75N01U4H/phm+RkwDpgE/AOYkKa15l6jgTvTssazdMBqSOvxNjCbJBD9VzNlzAIOJJkwmEXSYjowIma2pk7LlP1kRDTXqn0YeIjk8ZepwHyW7tI2PcA9S9KElu6TDjPcBvw8Ip6PiNeAs4BbJXVamd9g7ZM80WVmeeSWn5nlkoOfmeWSg5+Z5ZKDn5nlUrEHbducOnYOrdql2tWwDLbbsle1q2AZTJ36FjNnzlTLOVesw5obRyyaV1LemPf+wxExdGXuVym1FfxW7UKnvkdUuxqWwVN/v7LaVbAMhuw4cKXLiEXz6bTFUSXlnf/cr1t6I6dqair4mVk7IEAr1XisCQ5+ZpZdHSyV6OBnZtm55Wdm+SNo6FDtSqw0Bz8zy0a422tmeSR3e80sp9zyM7NccsvPzPJHbvmZWQ4Jz/aaWR655WdmedXgMT8zyxs/52dmueXZXjPLn/p4va39t13NrO2pobSjpWKkGyW9J2lyQdqdkiamx1uSJqbpm0iaV3Du2oJrdpD0D0lTJF0htdw0dcvPzLJRWV9vuwm4ErilKSEijvz8VroUmFOQ//WIGNBMOdcAJwF/Bx4AhgIPFruxW35mll2ZWn4R8QQwu9lbJK23I4ARRasidQPWjIgxkWxEfgtwSEv3dvAzs+yaWn8tHdBV0riCY3iGu+wCvBsRrxWkbSrpOUl/lbRLmtYdmF6QZ3qaVpS7vWaWUaaHnGdGRGs3DjmapVt9M4BeETFL0g7AHyVt3cqyHfzMLKM2eL1NUkfgMGCHprSIWAAsSD+Pl/Q60AdoBHoUXN4jTSvK3V4zy0hlG/MrYi/g5YhY0p2VtL6kDunnzYDewBsRMQP4UNLgdJzwOODelm7g4Gdm2ZU+5tdCMRoBPAP0lTRd0onpqaNYfqJjV2BS+ujL74FTIqJpsuRU4HpgCvA6Lcz0gru9ZtYaZXq9LSKOXkH68c2k3Q3cvYL844B+We7t4Gdm2fn1NjPLHXlJKzPLKTU4+JlZzggo4dXZmufgZ2bZKD3aOQc/M8tIbvmZWT45+JlZLjV4wsPMcsdjfmaWR/KYn5nllYOfmeWSg5+Z5ZKDn5nlj0ANDn5mljOe8DCz3HLwM7N8av+xz8HPzDKSW35mllMOfmaWO0J+t9fMcqr9N/y8daWZZZSO+ZVytFiUdKOk9yRNLkg7T1KjpInpsX/BuTMlTZH0iqR9C9KHpmlTJJ1Rys9w8DOzzMoV/ICbgKHNpF8eEQPS44H0nluR7Oe7dXrN1ZI6pBuZXwXsB2wFHJ3mLcrdXjPLrFwTHhHxhKRNSsx+MHBHRCwA3pQ0BRiUnpsSEW+kdbsjzftiscLc8jOzzNSgkg6gq6RxBcfwEm9xuqRJabd4nTStOzCtIM/0NG1F6UU5+LXCtecew9RHL2bcXWctSdumT3cev/n7jB15Fr//1cl0Wf0LAKy71uo8dN23eP+pS7n8x19dqpwjhu7A2JFn8eydZ3Lvlaey3tqrt+nvsMQVv7qc7ftvzQ4D+nHc149m/vz5HH/sMWy7dV92GNCPk7/xnyxcuLDa1awZpXZ509bhzIgYWHBcV8ItrgE2BwYAM4BLK/E7Khr8WjMI2R7c+qcxHHzaVUulXfOTr3HOFffyb0dcxKjHnue7w/YEYP6ChZx/9X2cefk9S+Xv0KGBX/zwcIYO/18GHXkxk19r5JQjd2uz32CJxsZGrr7qCp4aM47xEyezePFi7rrzDo762jE8P/llxj33D+bNn8fvbri+2lWtKWUc81tORLwbEYsj4jPgt3zetW0EehZk7ZGmrSi9qIoFv9YOQrYHT014ndlz5i6V9qVeG/Dk+CkA/GXMyxyy5wAA5s7/lKcnvsH8BUu3HKTkWL3zqgB0WaMzM96fU/nK23IWLVrEvHnzkj/nzqXbF7/I0P32X/If8MCBg2hsnF7tataUSgY/Sd0Kvh4KNM0EjwKOktRJ0qZAb+BZYCzQW9KmklYlmRQZ1dJ9KtnyG0Q6CBkRnwJNg5B16aU3ZnDQ7tsCcNje29Njw3WK5l+06DO+fdGdjB15Fm88ciFbbrYRN/3x6baoqhXo3r073/nuD+izWS827dmNNddci7323mfJ+YULFzLi9lvZe9/mJiRzTCUeLRUjjQCeAfpKmi7pROASSf+QNAnYA/guQES8AIwkmch4CDgtbSEuAk4HHgZeAkameYuqZPAraRBS0vCmwdBYNK+C1amsk8+7neFH7MJTt/+INVbrxKcLFxfN37FjAycdvguDj/45m+1zNpNfbeSH/7lP0Wus/D744APu+9O9vPTam7zxz7f5ZO4njLj9tiXnv336qQzZZVd23nmXKtay9pSr5RcRR0dEt4hYJSJ6RMQNEXFsRGwTEdtGxL9HxIyC/BdGxOYR0TciHixIfyAi+qTnLizlN1R9wiMirmsaDFXHztWuTqu9+ta7HHTqVQw55hJGPjSeN6e/XzR//z49AHhz+kwAfj96AoP7b1bxetrS/vLon9lkk01Zf/31WWWVVTjkkMMY80zSAr/wgp/y/sz3ueSXl1W5lrVFgoYGlXTUskoGv1YNQrZX66+zBpD8P+IZJ+3Lb3//ZNH8b78/hy0224iu6XV7Dt6CV958p+L1tKX17NmLZ58dw9y5c4kIHvvLo/TdYkt+d8P1jH7kYW65bURdvMdaXplme2tWJR9yXjIISRL0jgK+VsH7tZmbLz6eXXboTde112DKQxdwwbUPsEbnTpx85K4A3PuXidxy75gl+V++/6d0Wf0LrLpKRw7aY1sOPPUqXn7jHS667kFGX/8dFi5azD9nzGb4ubet6JZWIYN23JFDDzucnQZtT8eOHenffztOPGk46621Or023pjdd94JgIMPPYyzzvlJlWtbO2o8rpVEEVG5wpN38n4FdABubKkv3rDaBtGp7xEVq4+V3wdjr6x2FSyDITsOZPz4cSsVur6wUZ/YeNivS8r76iVDx0fEwJW5X6VU9PW29J28Byp5DzNrY6qPlp/f7TWzTAQ1P5lRCgc/M8vMwc/M8sfdXjPLI+E9PMwsl2r/Gb5SOPiZWWZ1EPsc/MwsI3nCw8xyyGN+ZpZbdRD7HPzMLDu3/Mwsl+og9jn4mVlGcsvPzHJI1P5CpaVw8DOzzOqg4efgZ2bZ1UO31+tzm1k2+nzr1ZaOFouSbpT0nqTJBWm/kPSypEmS7pG0dpq+iaR5kiamx7UF1+yQ7vg2RdIVKiE6O/iZWSZNDzmXaQ+Pm4Bl9wUdDfSLiG2BV4EzC869HhED0uOUgvRrgJNI9vLt3UyZy3HwM7PMyrh15RPA7GXSHkn34gUYQ7L5WbG6dAPWjIgxkezLcQtwSEv3dvAzs8wybF3ZtWlf7vQYnvFW/wk8WPB9U0nPSfqrpKbNlLuT7AvepNk9wpflCQ8zyybbYqYzW7uBkaSzgUXA7WnSDKBXRMyStAPwR0lbt6ZscPAzs4zUBuv5SToeOBDYM+3KEhELgAXp5/GSXgf6kGyNW9g1LmmPcHd7zSyzcs32Nl+2hgI/Av49IuYWpK8vqUP6eTOSiY03ImIG8KGkweks73HAvS3dxy0/M8usoUwtP0kjgN1JxganA+eSzO52AkanLcwx6czursD5khYCnwGnRETTZMmpJDPHnUnGCAvHCZvl4GdmmaiMi5lGxNHNJN+wgrx3A3ev4Nw4oF+We68w+EnavtiFETEhy43MrH7Uwau9RVt+lxY5F8BXylwXM2sn6uH1thUGv4jYoy0rYmbtRx3EvpZneyWtJukcSdel33tLOrDyVTOzWiTSx11K+F8tK+VRl98BnwJfTr83Aj+rWI3MrOY1qLSjlpUS/DaPiEuAhQDpczc1/rPMrGJU2qtttb7gaSmPunwqqTPJJAeSNid9ytrM8keU7zm/aiol+J0LPAT0lHQ7MAQ4vpKVMrPaVgexr+XgFxGjJU0ABpME/W9HxMyK18zMalZdP+qyjN2AnUm6vqsA91SsRmZW01bmvd1a0mLwk3Q18CVgRJp0sqS9IuK0itbMzGpWhzqIfqW0/L4CbNm0rIykm4EXKlorM6tp9dDtLeVRlylAr4LvPdM0M8uhZLa3/T/nV2xhgz+RjPF1AV6S9Gz6fUfg2bapnpnVnNI3J6ppxbq9v2yzWphZu1IHsa/owgZ/bcuKmFn7UQ8tv1IWNhgsaaykjyV9KmmxpA/bonJmVnsEdGhQSUctK2XC40rgaOA1kiWivwFcVclKmVltU4lHLStpA6OImAJ0iIjFEfE7StgN3czqk5S821vKUctKec5vrqRVgYmSLiHZO9O7vpnlWI3HtZKUEsSOTfOdDnxC8pzfYZWslJnVNqWPu7R01LIWg19ETI2I+RHxYUT8NCK+B1zUBnUzsxpVrn17Jd0o6T1JkwvS1pU0WtJr6Z/rpOmSdIWkKZImFW6yJmlYmv81ScNK+Q2t7b7u1MrrzKydk0qb6S1xtvcmlp9DOAN4NCJ6A4+m3wH2I9movDcwHLgmrc+6JEvv7QgMAs5tCpjFeOzOzDIrV7c3Ip4AZi+TfDBwc/r5ZuCQgvRbIjEGWFtSN2BfYHREzI6ID4DRlDAp25p9e0WyrFXZbdO3Jw8+dlklirYKWeeAYjucWq1ZMOXdspSTodXUVdK4gu/XRcR1LVyzYUTMSD+/A2yYfu4OTCvINz1NW1F6Ua3dt/fllgo2s/okMr3hMTMiBrb2XhERkqK11xfjfXvNLLMKv7zxrqRuETEj7da+l6Y3kjxt0qRHmtYI7L5M+uMt3cRjfmaWiVTx19tGAU0ztsOAewvSj0tnfQcDc9Lu8cPAPpLWSSc69knTiip1GXszsyXK1fKTNIKk1dZV0nSSWdv/AUZKOhGYChyRZn8A2J9kPdG5wAkAETFb0gXA2DTf+RGx7CTKchz8zCyzcj2/HBFHr+DUns3kDaDZ7TMi4kbgxiz3LmVVF0n6uqSfpN97SRqU5SZmVj+a9u1t7+/2ljLmdzXJQ81NEfojvKqLWa41lHjUslK6vTtGxPaSngOIiA/ShQ7MLKdqvFFXklKC30JJHUj270DS+sBnFa2VmdWsptfb2rtSgt8VJJuUbyDpQuBw4JyK1srMalodxL6Wg19E3C5pPMnsi4BDIuKlitfMzGpS04RHe9di8JPUi+SZmj8VpkXEPytZMTOrXXUQ+0rq9t5PMt4n4AvApsArwNYVrJeZ1ap2sCF5KUrp9m5T+D1d7eXUitXIzGqean57opZlfsMjIiZI2rESlTGz2iegY60/xFeCUsb8vlfwtQHYHni7YjUys5pX6/tzlKKUll+Xgs+LSMYA765Mdcys1iWzvdWuxcorGvzSh5u7RMQP2qg+ZlbrStycqNYVW8a+Y0QskjSkLStkZrWv3p/ze5ZkfG+ipFHAXST79gIQEX+ocN3MrAYJ6JCHCQ+SZ/tmAV/h8+f9AnDwM8sl0VDnj7pskM70TubzoNekIhuKmFntSzYwqnYtVl6x4NcBWAOaDfEOfmZ5lYM3PGZExPltVhMzazfqfcKj/f86Myu7PHR7l9tAxMwMqIvFTFc4YV3K1m9mlj+iPHt4SOoraWLB8aGk70g6T1JjQfr+BdecKWmKpFck7bsyv8NbV5pZNirPu70R8QowAJa8TdZIsmr8CcDlEfHLpW4rbQUcRbKc3heBP0vqExGLW3P/OnhU0czamko8MtgTeD0iphbJczBwR0QsiIg3STYvb/U2ug5+ZpZJxn17u0oaV3AMX0GxRwEjCr6fLmmSpBslrZOmdQemFeSZnqa1ioOfmWWWoeU3MyIGFhzXLVdWshXuv5O8QgtwDbA5SZd4BnBpJX6Dx/zMLCPRUN7Z3v2ACRHxLkDTnwCSfgvcl35tBHoWXNcjTWsVt/zMLJNyzfYWOJqCLq+kbgXnDiV5xRZgFHCUpE6SNgV6kyzA0ipu+ZlZZuVayVnS6sDewMkFyZdIGkDyGu1bTeci4gVJI4EXSRZWPq21M73g4GdmrVCuTm9EfAKst0zasUXyXwhcWI57O/iZWTZles6v2hz8zCwTAR0c/Mwsj9p/6HPwM7NWqIOGn4OfmWWTPOrS/qOfg5+ZZeaWn5nlkJBbfmaWN57tNbN8kru9ZpZTDn5mlkse8zOz3EkWM612LVaeg5+ZZVbv+/aamTWrHrq9Xsx0JTVOn8bhB+3D7oP7s8dOA7j+2l8vdf7aKy+n+zqdmD1r5lLpEyeMo1fX1bjv3j+0ZXVz69rv7cvUO/+Lcb8ZtiTt1rMOZMzVxzLm6mN5+eZvMObqZCWlXhuuyexR31py7opv7bXkmlU6NnDlt/dm0g0nMPH6Ezhk595t/luqranbW8pRyyrW8pN0I3Ag8F5E9KvUfaqtY8eOnPuzn7NN/+34+KOPGLrHYHbdfS/6bLEljdOn8cRjf6Z7j15LXbN48WIuPO9sdttjrxWUauV26yOTuXbUc1z/w/2WpB170X1LPv/P8N2Y88mCJd/fmDGHwafeulw5Pz56MO//ay7bnvg7JFi3S+fKVrwm1cdDzpVs+d0EDK1g+TVhw426sU3/7QBYo0sXevfZgndmJNsKnHf2Dzn7vIuXW/vsxuuu4oCDDmG99Tdo8/rm1VOTG5n90fwVnv+PXfsy8rGXWyxn2L79+MUdfwcgAmZ9OK9sdWw30uf8SjlqWcWCX0Q8AcyuVPm1aNo/32LypOfZbodBPPzAKLp1+yJbb7PtUnlmvN3IQ/eN4rgTT15BKdbWhvTrzrsffMLrb/9rSdomG63FM1cdyyO/OIIh/ZLdEddavRMA5w4bwtNXfp3bzz6QDdZerRpVrroK7Nvb5qo+5idpeNOenrNmzmz5ghr1yccfc9JxR/HTi39Jx44d+fVll/CDM89dLt+5Z/2As867kIaGqv/VW+qIPbbgrsc/b/W9M/sT+nz9OnY67VZ+/JvHuemMA+iy2qp07NBAj/W7MObFt/ny6bfx95dmcPFJu1Wx5tXR9HpbKUctq/psb7qP53UA/bfbIapcnVZZuHAhJw07kkO/ehT7H3QIL70wmX9OfYu9d/k3AGa8PZ19dxvM/Y8+yaTnxnPqicnA+uzZM/nL6Ifo2LEDQw84uJo/Ibc6NIiDh/RmyOm3LUn7dOFiZi9M9sV5bsp7vPH2v+jdfR0mvPYun8xfyB+feg2AP/ztVYYNrdvh7OJqO66VpOrBr72LCL7/zZP5Up8tOPm07wCw5db9mPTa9CV5dty2Dw8+9jTrrteVMc+/uiT9O6d+g7323d+Br4q+sv3GvDptNo0zP16S1nWtzsz+aD6ffRZsstFafKn72rz5zhwAHhjzOrtu25O/Pj+N3Qf04uWps6pV9aoq14SHpLeAj4DFwKKIGChpXeBOYBOS3duOiIgPlAye/y+wPzAXOD4iJrT23g5+K2nsmKe5+87b2XKrfktaemf89/nsuc9+LVxpbenmMw5gl2170HWtzky5bTgX3Po0Nz88ma/u1peRjy890bHzNj347+O+zMJFn/HZZ8E3r/gzH6STJefc8AQ3/Gh/fnFKJ2bOmcvJlz5cjZ9TdWXu0e4REYVjXmcAj0bE/0g6I/3+Y5LNzXunx47ANemfraKIyvQ0JY0Adge6Au8C50bEDcWu6b/dDvHgY89UpD5WGZsf+euWM1nNWDDmV3w2Z9pKha4tt9kubrn38ZLyDtp87fERMXBF59OW38DC4CfpFWD3iJiRbmD+eET0lfSb9POIZfO15ndUrOUXEUdXqmwzq7LSw2dXSeMKvl+XjvM3CeARSQH8Jj23YUFAewfYMP3cHZhWcO30NK22gp+Z1Scp07u9M4u1/ICdI6JR0gbAaElLjUFERKSBsez8vIWZZVau5/wiojH98z3gHmAQ8G7a3SX98700eyPQs+DyHmlaqzj4mVl2ZYh+klaX1KXpM7APMBkYBTS9hD0MuDf9PAo4TonBwJzWjveBu71mllnZ3u3dELgnff2zI/B/EfGQpLHASEknAlOBI9L8D5A85jKF5FGXE1bm5g5+ZpZZOR51iYg3gP7NpM8C9mwmPYDTVv7OCQc/M8tE1P6iBaVw8DOzzOphSSsHPzPLzC0/M8ulOoh9Dn5mllF7WKyvBA5+ZpaZx/zMLHe8b6+Z5ZeDn5nlkbu9ZpZLftTFzHKpDmKfg5+ZtUIdRD8HPzPLJONipjXLwc/MMmv/oc/Bz8xaow6in4OfmWVUtsVMq8rBz8wyq4MhPwc/M8vGi5maWW6522tmueSWn5nlUh3EPu/ba2YZKWn5lXIULUbqKekxSS9KekHSt9P08yQ1SpqYHvsXXHOmpCmSXpG078r8DLf8zKwVytL2WwR8PyImpJuXj5c0Oj13eUT8cqk7SlsBRwFbA18E/iypT0Qsbs3N3fIzs0yaFjMt5SgmImZExIT080fAS0D3IpccDNwREQsi4k2SzcsHtfZ3OPiZWWYZur1dJY0rOIY3X542AbYD/p4mnS5pkqQbJa2TpnUHphVcNp3iwbIoBz8zy0wl/g+YGREDC47rlitLWgO4G/hORHwIXANsDgwAZgCXVuI3OPiZWXYq8WipGGkVksB3e0T8ASAi3o2IxRHxGfBbPu/aNgI9Cy7vkaa1ioOfmWVWjtgnScANwEsRcVlBereCbIcCk9PPo4CjJHWStCnQG3i2tb/Bs71mlkkpj7GUaAhwLPAPSRPTtLOAoyUNAAJ4CzgZICJekDQSeJFkpvi01s70goOfmbWCyhD9IuJJmm8gPlDkmguBC1f65jj4mVkr1MMbHg5+ZpaZ3+01sxzyYqZmlkNez8/McsvBz8xyyd1eM8uf8j3nV1UOfmaWSYlvrtU8Bz8zy64Oop+Dn5ll5jE/M8ullhYqbQ8c/MwsOwc/M8sjd3vNLHfq5Q0PRUS167CEpPeBqdWuRwV0BWZWuxKWSb3+M9s4ItZfmQIkPUTy91OKmRExdGXuVyk1FfzqlaRxETGw2vWw0vmfWf3zMvZmlksOfmaWSw5+bWO57fqs5vmfWZ3zmJ+Z5ZJbfmaWSw5+ZpZLDn4VJGmopFckTZF0RrXrYy2TdKOk9yRNbjm3tWcOfhUiqQNwFbAfsBXJRsxbVbdWVoKbgJp8KNfKy8GvcgYBUyLijYj4FLgDOLjKdbIWRMQTwOxq18Mqz8GvcroD0wq+T0/TzKwGOPiZWS45+FVOI9Cz4HuPNM3MaoCDX+WMBXpL2lTSqsBRwKgq18nMUg5+FRIRi4DTgYeBl4CREfFCdWtlLZE0AngG6CtpuqQTq10nqwy/3mZmueSWn5nlkoOfmeWSg5+Z5ZKDn5nlkoOfmeWSg187IWmxpImSJku6S9JqK1HWTZIOTz9fX2zBBUm7S/pyK+7xlqTldvhaUfoKyjhe0pXluK/Zshz82o95ETEgIvoBnwKnFJ6U1Ko9mCPiGxHxYpEsuwOZg59ZrXPwa5/+BnwpbZX9TdIo4EVJHST9QtJYSZMknQygxJXp2oJ/BjZoKkjS45IGpp+HSpog6XlJj0rahCTIfjdtde4iaX1Jd6f3GCtpSHrtepIekfSCpOtJ9rYuiaRBkp6R9JykpyX1LTjdM63ja5LOLbjm65KeTev1m3QJMbOStaq1YNWTtvD2Ax5Kk7YH+kXEm5KGA3Mi4t8kdQKekvQIsB3Ql2RdwQ2BF4Eblyl3feC3wK5pWetGxGxJ1wIfR8Qv03z/B1weEU9K6kXyBsuWwLnAkxFxvqQDgCxvRrwM7BIRiyTtBVwE/Ed6bhDQD5gLjJV0P/AJcCQwJCIWSroaOAa4JcM9Lecc/NqPzpImpp//BtxA0h19NiLeTNP3AbZtGs8D1gJ6A7sCIyJiMfC2pL80U/5g4ImmsiJiRWva7QVsJS1p2K0paY30Hoel194v6YMMv20t4GZJvYEAVik4NzoiZgFI+gOwM7AI2IEkGAJ0Bt7LcD8zB792ZF5EDChMSP/D/6QwCfhmRDy8TL79y1iPBmBwRMxvpi6tdQHwWEQcmna1Hy84t+z7l0HyO2+OiDNX5qaWbx7zqy8PA/8laRUASX0krQ48ARyZjgl2A/Zo5toxwK6SNk2vXTdN/wjoUpDvEeCbTV8kDUg/PgF8LU3bD1gnQ73X4vPlvo5f5tzektaV1Bk4BHgKeBQ4XNIGTXWVtHGG+5k5+NWZ60nG8yakG/D8hqR1fw/wWnruFpJVS5YSEe8Dw4E/SHoeuDM99Sfg0KYJD+BbwMB0QuVFPp91/ilJ8HyBpPv7zyL1nJSumDJd0mXAJcDFkp5j+d7Is8DdwCTg7ogYl85OnwM8ImkSMBroVuLfkRngVV3MLKfc8jOzXHLwM7NccvAzs1xy8DOzXHLwM7NccvAzs1xy8DOzXPp/F1y+Vbb8ucsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.48      0.60      2000\n",
      "           1       0.63      0.88      0.73      2000\n",
      "\n",
      "    accuracy                           0.68      4000\n",
      "   macro avg       0.71      0.68      0.66      4000\n",
      "weighted avg       0.71      0.68      0.66      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = get_best_param(X_train_scaled, y_train_final, RandomForestClassifier(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9399375000000001\n",
      "Best Estimator:  RandomForestClassifier(min_samples_split=5, n_estimators=200)\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters and score\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "print(\"Best Estimator: \", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=5, n_estimators=200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Random Forest classifier with 100 trees\n",
    "rfc = RandomForestClassifier(min_samples_split=5, n_estimators=200)\n",
    "\n",
    "# Train the classifier on your data\n",
    "rfc.fit(X_train_scaled, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(rfc, open('Model/rfc_VGG16_fusion_enha.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = pickle.load(open('Model/rfc_VGG16_fusion.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test data\n",
    "y_predict = rfc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      2000\n",
      "           1       0.97      0.88      0.93      2000\n",
      "\n",
      "    accuracy                           0.93      4000\n",
      "   macro avg       0.93      0.93      0.93      4000\n",
      "weighted avg       0.93      0.93      0.93      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   4.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   4.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   4.3s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   4.4s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  57.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  56.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  56.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  57.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  56.6s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  21.7s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  17.8s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  21.5s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  17.8s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  20.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  40.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  40.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  40.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  40.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  41.8s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  18.9s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  19.5s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  11.4s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  18.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  50.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  50.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  50.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  50.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  50.2s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=  32.1s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=  33.4s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=  27.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=  28.2s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=  28.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  40.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  37.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  40.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  40.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  37.8s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.9min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.0min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 3.7min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.1min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  52.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  52.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  52.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  52.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  51.6s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  27.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  29.5s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  27.4s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  29.4s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  32.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  38.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  38.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  39.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  38.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  38.4s\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "grid_search = get_best_param(X_train_scaled, y_train_final, LogisticRegression(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9376874999999998\n",
      "Best Estimator:  LogisticRegression(C=0.1, penalty='l1', solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters and score\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "print(\"Best Estimator: \", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Logistic Regression classifier\n",
    "lr = LogisticRegression(C=0.1, penalty='l1', solver='liblinear')\n",
    "\n",
    "# Train the classifier on your data\n",
    "lr.fit(X_train_scaled, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(lr, open('Model/lr_VGG16_fusion_enha.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pickle.load(open('Model/lr_VGG16_fusion.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test data\n",
    "y_predict = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      2000\n",
      "           1       0.94      0.93      0.93      2000\n",
      "\n",
      "    accuracy                           0.93      4000\n",
      "   macro avg       0.93      0.93      0.93      4000\n",
      "weighted avg       0.93      0.93      0.93      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification by CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 64, 128, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 64, 128, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " vgg16 (Functional)             (None, 2, 4, 512)    14714688    ['input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 4096)         0           ['vgg16[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 4096)         0           ['vgg16[1][0]']                  \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 1)            0           ['flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2           ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,714,690\n",
      "Trainable params: 14,714,690\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(64,128,3))\n",
    "\n",
    "input_dim = X_train_pair.shape[2:]\n",
    "\n",
    "img_a = Input(shape=input_dim)\n",
    "img_b = Input(shape=input_dim)\n",
    "\n",
    "feat_vecs_a = model_vgg(img_a)\n",
    "feat_vecs_b = model_vgg(img_b)\n",
    "\n",
    "flatten_a = Flatten()(feat_vecs_a)\n",
    "flatten_b = Flatten()(feat_vecs_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance)([flatten_a, flatten_b])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model_vgg = Model(inputs=[img_a, img_b], outputs=outputs)\n",
    "\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model_vgg.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 73s 146ms/step - loss: 0.6932 - accuracy: 0.4972\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 0.6932 - accuracy: 0.4972\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 74s 149ms/step - loss: 0.6932 - accuracy: 0.4909\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 0.6932 - accuracy: 0.4951\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 0.6932 - accuracy: 0.4936\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4959\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4921\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4970\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4984\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4936\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4989\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4985\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4984\n",
      "Epoch 15/100\n",
      "326/500 [==================>...........] - ETA: 26s - loss: 0.6932 - accuracy: 0.4975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28180/1909033650.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mX_train_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_b\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_final\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# reducing batch size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \"\"\"\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \"\"\"\n\u001b[0;32m   1156\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model_vgg.fit(\n",
    "\t[X_train_a, X_train_b], y_train_final,\n",
    "\tbatch_size=32, # reducing batch size\n",
    "\tepochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model(inputShape, embeddingDim=48):\n",
    "\t# specify the inputs for the feature extractor network\n",
    "\tinputs = Input(inputShape)\n",
    "\t# define the first set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
    "\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\tx = Dropout(0.3)(x)\n",
    "\t# second set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "\tx = MaxPooling2D(pool_size=2)(x)\n",
    "\tx = Dropout(0.3)(x)\n",
    " \t# prepare the final outputs\n",
    "\tpooledOutput = GlobalAveragePooling2D()(x)\n",
    "\toutputs = Dense(embeddingDim)(pooledOutput)\n",
    "\t# build the model\n",
    "\tmodel = Model(inputs, outputs)\n",
    "\t# return the model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgA = Input(shape=X_train_pair.shape[2:])\n",
    "imgB = Input(shape=X_train_pair.shape[2:])\n",
    "featureExtractor = build_siamese_model(X_train_pair.shape[2:])\n",
    "featsA = featureExtractor(imgA)\n",
    "featsB = featureExtractor(imgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    X_train_a = tf.convert_to_tensor(X_train_pair[:, 0], np.float32)\n",
    "    X_train_b = tf.convert_to_tensor(X_train_pair[:, 1], np.float32)\n",
    "    y_train_final = tf.convert_to_tensor(y_train_pair.reshape(-1,1), np.float32)\n",
    "    \n",
    "    X_test_a = tf.convert_to_tensor(X_test_pair[:, 0], np.float32)\n",
    "    X_test_b = tf.convert_to_tensor(X_test_pair[:, 1], np.float32)\n",
    "    y_test_final = tf.convert_to_tensor(y_test_pair.reshape(-1,1), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 14s 26ms/step - loss: 0.7163 - accuracy: 0.4863 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6934 - accuracy: 0.4931 - val_loss: 0.6950 - val_accuracy: 0.4970\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6934 - accuracy: 0.4963 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4945 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4934 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6933 - val_accuracy: 0.4988\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6934 - val_accuracy: 0.4978\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4972 - val_loss: 0.6933 - val_accuracy: 0.4983\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4939 - val_loss: 0.6937 - val_accuracy: 0.4460\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6934 - accuracy: 0.5021 - val_loss: 0.6933 - val_accuracy: 0.4985\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6937 - val_accuracy: 0.4995\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4945 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4956 - val_loss: 0.6939 - val_accuracy: 0.3473\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4939 - val_loss: 0.6932 - val_accuracy: 0.4602\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.4950\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4905 - val_loss: 0.6946 - val_accuracy: 0.2918\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6941 - val_accuracy: 0.3918\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6933 - val_accuracy: 0.4692\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6943 - val_accuracy: 0.2965\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6937 - val_accuracy: 0.3670\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6936 - val_accuracy: 0.4565\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6933 - val_accuracy: 0.4248\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6934 - val_accuracy: 0.4692\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6935 - val_accuracy: 0.3620\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6933 - val_accuracy: 0.3915\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.4437\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.4297\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6932 - val_accuracy: 0.4902\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4954 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6935 - val_accuracy: 0.3957\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6937 - val_accuracy: 0.3285\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6935 - val_accuracy: 0.4588\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6935 - val_accuracy: 0.4958\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6933 - val_accuracy: 0.4365\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6937 - val_accuracy: 0.3803\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6940 - val_accuracy: 0.3100\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6937 - val_accuracy: 0.3877\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6935 - val_accuracy: 0.4720\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4954 - val_loss: 0.6944 - val_accuracy: 0.3860\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6947 - val_accuracy: 0.3828\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6936 - val_accuracy: 0.4515\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6949 - val_accuracy: 0.4182\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6936 - val_accuracy: 0.4510\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6934 - val_accuracy: 0.4850\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6931 - accuracy: 0.5003 - val_loss: 0.6938 - val_accuracy: 0.4245\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6969 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6946 - val_accuracy: 0.3970\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6981 - val_accuracy: 0.2915\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6931 - accuracy: 0.4996 - val_loss: 0.6985 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6977 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6956 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6962 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4936 - val_loss: 0.6963 - val_accuracy: 0.3638\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6971 - val_accuracy: 0.3640\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6964 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6978 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6968 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "439/500 [=========================>....] - ETA: 1s - loss: 0.6932 - accuracy: 0.4968"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28180/948365459.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_b\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \tepochs=100)\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \"\"\"\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \"\"\"\n\u001b[0;32m   1156\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(\n",
    "\t[X_train_a, X_train_b], y_train_final,\n",
    "\tvalidation_data=([X_test_a, X_test_b], y_test_final),\n",
    "\tbatch_size=32, \n",
    "\tepochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test_a, X_test_b, y_test_final):\n",
    "    # evaluate the model on the test data\n",
    "    print(\"[INFO] evaluating model...\")\n",
    "    loss, accuracy = model.evaluate([X_test_a, X_test_b], y_test_final, verbose=0)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "    # make predictions on the test data\n",
    "    print(\"[INFO] making predictions...\")\n",
    "    y_pred = model.predict([X_test_a, X_test_b])\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # print the classification report\n",
    "    print(\"[INFO] classification report...\")\n",
    "    print(classification_report(y_test_final, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating model...\n",
      "Test Loss: 3.5463\n",
      "Test Accuracy: 50.00%\n",
      "[INFO] making predictions...\n",
      "125/125 [==============================] - 1s 9ms/step\n",
      "[INFO] classification report...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      2000\n",
      "         1.0       0.50      1.00      0.67      2000\n",
      "\n",
      "    accuracy                           0.50      4000\n",
      "   macro avg       0.25      0.50      0.33      4000\n",
      "weighted avg       0.25      0.50      0.33      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_model(model, X_test_a, X_test_b, y_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

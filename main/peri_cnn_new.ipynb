{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.applications import ResNet101, ResNet50, VGG16, VGG19, InceptionV3, InceptionResNetV2\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess_input\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess_input\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input as inception_resnet_preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm.auto import trange, tqdm\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(img_folder):\n",
    "   \n",
    "    iris_data=[]\n",
    "    iris_label=[[],[]]\n",
    "   \n",
    "    for dir1 in tqdm(os.listdir(img_folder)):\n",
    "        for eye in os.listdir(os.path.join(img_folder, dir1)):\n",
    "            for file in list(os.listdir(os.path.join(img_folder, dir1, eye))[i] for i in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]):\n",
    "                image_path= os.path.join(img_folder, dir1, eye, file)\n",
    "                if image_path.endswith(\".jpg\") == False:\n",
    "                    continue\n",
    "                img = image.load_img(image_path, target_size=(64, 64))\n",
    "                img = image.img_to_array(img)\n",
    "                iris_data.append(img)\n",
    "                iris_label[0].append(dir1+'0' if eye == 'L' else dir1+'1')\n",
    "                iris_label[1].append(file)\n",
    "                \n",
    "    return np.array(iris_data), np.array(iris_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d218f5069e714077a9bf7f701361179d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris_data, iris_label = create_dataset('Iris-Dataset/CASIA-Iris-Thousand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR(X, y, classes, img_num):\n",
    "    X_combined = []\n",
    "    y_combined = []\n",
    "    img_label = []\n",
    "    for i in range(0, classes*img_num*2, img_num*2):\n",
    "        for j in range(img_num):\n",
    "            X_combined.append(np.concatenate((X[i+j], X[i+j+img_num]), axis=1))\n",
    "            y_combined.append(\"\".join([*y[0][i]][:3]))\n",
    "            img_label.append(y[1][i+j][6:8])\n",
    "    return np.array(X_combined), np.array(y_combined), np.array(img_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data, iris_label, img_label = combine_LR(iris_data, iris_label, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, label_train, label_test = train_test_split(iris_data, iris_label, img_label, test_size=0.2, stratify=iris_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(images, labels, img_label):\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "    imageLabels = []\n",
    "    \n",
    "    numClasses = len(np.unique(labels))\n",
    "    idx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
    "\t# loop over all images\n",
    "    for idxA in range(len(images)):\n",
    "\t\t# grab the current image and label belonging to the current\n",
    "\t\t# iteration\n",
    "        currentImage = images[idxA]\n",
    "        label = labels[idxA]\n",
    "        try:\n",
    "            while True:\n",
    "                # randomly pick an image that belongs to the *same* class\n",
    "                idxB = np.random.choice(idx[label])\n",
    "                if idxB != idxA:\n",
    "                    break\n",
    "            posImage = images[idxB]\n",
    "        except:\n",
    "            print(label, len(idx))\n",
    "\t\t# prepare a positive pair and update the images and labels\n",
    "\t\t# lists, respectively\n",
    "        pairImages.append([currentImage, posImage])\n",
    "        pairLabels.append([1])\n",
    "        imageLabels.append([str(labels[idxA]).zfill(3) + img_label[idxA], str(labels[idxB]).zfill(3) + img_label[idxB]])\n",
    "\t\t# grab the indices for each of the class labels *not* equal to\n",
    "\t\t# the current label and randomly pick an image corresponding\n",
    "\t\t# to a label *not* equal to the current label\n",
    "        negIdx = np.where(labels != label)[0]\n",
    "        idxC = np.random.choice(negIdx)\n",
    "        negImage = images[idxC]\n",
    "\t\t# prepare a negative pair of images and update our lists\n",
    "        pairImages.append([currentImage, negImage])\n",
    "        pairLabels.append([0])\n",
    "        imageLabels.append([str(labels[idxA]).zfill(3) + img_label[idxA], str(labels[idxC]).zfill(3) + img_label[idxC]])\n",
    "\t# return a 2-tuple of our image pairs and labels\n",
    "    return (np.array(pairImages), np.array(pairLabels), np.array(imageLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pair, y_train_pair, label_train_pair = make_pairs(X_train, y_train.astype(int), label_train)\n",
    "X_test_pair, y_test_pair, label_test_pair = make_pairs(X_test, y_test.astype(int), label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_gpu():\n",
    "    # set the visible devices to the GPU\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "\t# unpack the vectors into separate lists\n",
    "\t(featsA, featsB) = vectors\n",
    "\t# compute the sum of squared distances between the vectors\n",
    "\tsumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
    "\t\tkeepdims=True)\n",
    "\t# return the euclidean distance between the vectors\n",
    "\treturn K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(H, plotPath):\n",
    "\t# construct a plot that plots and saves the training history\n",
    "\tplt.style.use(\"ggplot\")\n",
    "\tplt.figure()\n",
    "\tplt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "\tplt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\tplt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "\tplt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "\tplt.title(\"Training Loss and Accuracy\")\n",
    "\tplt.xlabel(\"Epoch #\")\n",
    "\tplt.ylabel(\"Loss/Accuracy\")\n",
    "\tplt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(64,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the default graph\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# create a new session\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/cpu:0'):\n",
    "#     X_train_a = tf.convert_to_tensor(vgg16_preprocess_input(X_train_pair[:, 0]), np.float32)\n",
    "#     X_train_b = tf.convert_to_tensor(vgg16_preprocess_input(X_train_pair[:, 1]), np.float32)\n",
    "#     y_train_final = tf.convert_to_tensor(y_train_pair.reshape(-1,1), np.float32)\n",
    "\n",
    "#     X_test_a = tf.convert_to_tensor(vgg16_preprocess_input(X_test_pair[:, 0]), np.float32)\n",
    "#     X_test_b = tf.convert_to_tensor(vgg16_preprocess_input(X_test_pair[:, 1]), np.float32)\n",
    "#     y_test_final = tf.convert_to_tensor(y_test_pair.reshape(-1,1), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a = vgg16_preprocess_input(X_train_pair[:, 0])\n",
    "X_train_b = vgg16_preprocess_input(X_train_pair[:, 1])\n",
    "y_train_final = y_train_pair.reshape(-1)\n",
    "\n",
    "X_test_a = vgg16_preprocess_input(X_test_pair[:, 0])\n",
    "X_test_b = vgg16_preprocess_input(X_test_pair[:, 1])\n",
    "y_test_final = y_test_pair.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 201s 400ms/step\n",
      "500/500 [==============================] - 195s 390ms/step\n",
      "125/125 [==============================] - 49s 394ms/step\n",
      "125/125 [==============================] - 50s 400ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    features_train_a = model_vgg.predict(X_train_a)\n",
    "    features_train_b = model_vgg.predict(X_train_b)\n",
    "    features_test_a = model_vgg.predict(X_test_a)\n",
    "    features_test_b = model_vgg.predict(X_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the features to a file\n",
    "# np.savez('temp_data/features.npz', \n",
    "#          features_train_a=features_train_a, \n",
    "#          features_train_b=features_train_b,\n",
    "#          label_train=y_train_final, \n",
    "#          img_label_train=label_train_pair,\n",
    "         \n",
    "#          features_test_a=features_test_a, \n",
    "#          features_test_b=features_test_b,\n",
    "#          label_test=y_test_final,\n",
    "#          img_label_test=label_test_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features from the file\n",
    "with np.load('temp_data/features.npz') as data:\n",
    "    features_train_a = data['features_train_a']\n",
    "    features_train_b = data['features_train_b']\n",
    "    y_train_final = data['label_train']\n",
    "    img_label_train = data['img_label_train']\n",
    "    \n",
    "    features_test_a = data['features_test_a']\n",
    "    features_test_b = data['features_test_b']\n",
    "    y_test_final = data['label_test']\n",
    "    img_label_test = data['img_label_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create all scores for score fusion with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.Iris_recognition import *\n",
    "from module.Periocular_recognition import *\n",
    "from module.score_fusion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_norm_L = np.load('temp_data/iris_norm_L_all.npy')\n",
    "iris_norm_R = np.load('temp_data/iris_norm_R_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(img_label_train[1][1][:-2]), int(img_label_train[1][1][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fusion_scores(labels):\n",
    "    total_test_img = 10\n",
    "    fusion_scores = []\n",
    "    for pair in tqdm(range(len(labels))):\n",
    "        img_1_fol = int(labels[pair][0][:-2])\n",
    "        img_1_item = int(labels[pair][0][-2:])\n",
    "        img_2_fol =int(labels[pair][1][:-2])\n",
    "        img_2_item = int(labels[pair][1][-2:])\n",
    "\n",
    "        img_1_L = iris_norm_L[(img_1_fol) * total_test_img + img_1_item]\n",
    "        img_1_R = iris_norm_R[(img_1_fol) * total_test_img + img_1_item]\n",
    "        img_2_L = iris_norm_L[(img_2_fol) * total_test_img + img_2_item]\n",
    "        img_2_R = iris_norm_R[(img_2_fol) * total_test_img + img_2_item]\n",
    "        fusion_scores.append(iris_score_fusion_preload(img_1_L, img_1_R, img_2_L, img_2_R))\n",
    "        \n",
    "    return np.array(fusion_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fusion_scores_multi_thread(labels):\n",
    "    total_test_img = 10\n",
    "    fusion_scores = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for pair in range(len(labels)):\n",
    "            img_1_fol = int(labels[pair][0][:-2])\n",
    "            img_1_item = int(labels[pair][0][-2:])\n",
    "            img_2_fol =int(labels[pair][1][:-2])\n",
    "            img_2_item = int(labels[pair][1][-2:])\n",
    "\n",
    "            img_1_L = iris_norm_L[(img_1_fol) * total_test_img + img_1_item]\n",
    "            img_1_R = iris_norm_R[(img_1_fol) * total_test_img + img_1_item]\n",
    "            img_2_L = iris_norm_L[(img_2_fol) * total_test_img + img_2_item]\n",
    "            img_2_R = iris_norm_R[(img_2_fol) * total_test_img + img_2_item]\n",
    "            futures.append(executor.submit(iris_score_fusion_preload, img_1_L, img_1_R, img_2_L, img_2_R))\n",
    "        \n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "            fusion_scores.append(future.result())\n",
    "        \n",
    "    return np.array(fusion_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e425c5a6c206471eb8cb5f4bc4fd85c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fusion_scores_test = get_fusion_scores(img_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.49353516, 0.48733408],\n",
       "        [0.66523628, 0.6651807 ],\n",
       "        [0.24661259, 0.24332181],\n",
       "        [0.66089526, 0.57884365]]),\n",
       " array([[0.48869141, 0.4952907 ],\n",
       "        [0.66722667, 0.68170878],\n",
       "        [0.24417692, 0.24666999],\n",
       "        [0.65653822, 0.65486168]]),\n",
       " array([[0.46430297, 0.47544447],\n",
       "        [0.67292918, 0.64320768],\n",
       "        [0.23039012, 0.23756612],\n",
       "        [0.54586765, 0.63535809]]),\n",
       " array([[0.4976521 , 0.49434171],\n",
       "        [0.66422323, 0.65637025],\n",
       "        [0.24868463, 0.24684587],\n",
       "        [0.64505458, 0.65747175]]),\n",
       " array([[0.36545938, 0.41706361],\n",
       "        [0.54998974, 0.59160332],\n",
       "        [0.18233304, 0.20812728],\n",
       "        [0.34614639, 0.49436121]]),\n",
       " array([[0.48459677, 0.4942999 ],\n",
       "        [0.66367978, 0.66502779],\n",
       "        [0.24201412, 0.24699176],\n",
       "        [0.63151002, 0.65418989]]),\n",
       " array([[0.49203125, 0.473125  ],\n",
       "        [0.67139278, 0.65571285],\n",
       "        [0.2455207 , 0.23586635],\n",
       "        [0.6595455 , 0.64234196]]),\n",
       " array([[0.47811138, 0.49267638],\n",
       "        [0.64566462, 0.65261617],\n",
       "        [0.23884598, 0.24611665],\n",
       "        [0.63681142, 0.65542688]]),\n",
       " array([[0.49103516, 0.36632757],\n",
       "        [0.65779696, 0.53745277],\n",
       "        [0.24525608, 0.18301282],\n",
       "        [0.65865   , 0.50320845]]),\n",
       " array([[0.48489998, 0.49000339],\n",
       "        [0.65480493, 0.66203108],\n",
       "        [0.24214626, 0.24479184],\n",
       "        [0.65303921, 0.62247094]]),\n",
       " array([[0.44542079, 0.36989827],\n",
       "        [0.61771268, 0.54038687],\n",
       "        [0.22253496, 0.18478447],\n",
       "        [0.59329066, 0.51943958]]),\n",
       " array([[0.48237529, 0.49075597],\n",
       "        [0.64254368, 0.65204881],\n",
       "        [0.24075806, 0.24514494],\n",
       "        [0.6358671 , 0.64682718]]),\n",
       " array([[0.48949939, 0.42664938],\n",
       "        [0.66288202, 0.60279279],\n",
       "        [0.24456995, 0.21322695],\n",
       "        [0.63927499, 0.5632708 ]]),\n",
       " array([[0.50416763, 0.4888838 ],\n",
       "        [0.67225464, 0.65587734],\n",
       "        [0.25158725, 0.24424423],\n",
       "        [0.59677972, 0.62890808]]),\n",
       " array([[0.47522068, 0.47918025],\n",
       "        [0.63613724, 0.6518498 ],\n",
       "        [0.23742852, 0.23939446],\n",
       "        [0.63849703, 0.629587  ]]),\n",
       " array([[0.49316177, 0.48524493],\n",
       "        [0.65452983, 0.649626  ],\n",
       "        [0.24644985, 0.24243911],\n",
       "        [0.64507251, 0.65023397]]),\n",
       " array([[0.47905413, 0.46219072],\n",
       "        [0.65274243, 0.63766986],\n",
       "        [0.23930693, 0.2306603 ],\n",
       "        [0.49129993, 0.58676751]]),\n",
       " array([[0.48666464, 0.49078197],\n",
       "        [0.66335639, 0.67282841],\n",
       "        [0.24305545, 0.24377214],\n",
       "        [0.60952691, 0.63075977]]),\n",
       " array([[0.46190931, 0.47177402],\n",
       "        [0.62737811, 0.64663112],\n",
       "        [0.23070887, 0.2356906 ],\n",
       "        [0.58700152, 0.58844288]]),\n",
       " array([[0.4964364 , 0.49484599],\n",
       "        [0.6660537 , 0.6679174 ],\n",
       "        [0.24793218, 0.24729492],\n",
       "        [0.62997204, 0.64526969]]),\n",
       " array([[0.4420306 , 0.38485553],\n",
       "        [0.6123849 , 0.55367984],\n",
       "        [0.22078737, 0.19216909],\n",
       "        [0.55811203, 0.51755338]]),\n",
       " array([[0.49112005, 0.47988002],\n",
       "        [0.66752242, 0.64456272],\n",
       "        [0.24506274, 0.23947249],\n",
       "        [0.56222182, 0.59954321]]),\n",
       " array([[0.48999489, 0.47503906],\n",
       "        [0.67957036, 0.6681501 ],\n",
       "        [0.24456612, 0.23652399],\n",
       "        [0.65489702, 0.6441037 ]]),\n",
       " array([[0.48789959, 0.48673828],\n",
       "        [0.66263584, 0.65818873],\n",
       "        [0.24363693, 0.24319569],\n",
       "        [0.65401299, 0.65477332]]),\n",
       " array([[0.44937345, 0.45198711],\n",
       "        [0.63290876, 0.61692766],\n",
       "        [0.2235491 , 0.22555295],\n",
       "        [0.45794744, 0.58783942]]),\n",
       " array([[0.48969872, 0.49414255],\n",
       "        [0.66700006, 0.66398785],\n",
       "        [0.24468137, 0.24688661],\n",
       "        [0.62625937, 0.63907606]]),\n",
       " array([[0.48540086, 0.45590421],\n",
       "        [0.64967891, 0.6289737 ],\n",
       "        [0.24245507, 0.22782034],\n",
       "        [0.63235078, 0.6142312 ]]),\n",
       " array([[0.49943295, 0.48426105],\n",
       "        [0.68484556, 0.65726269],\n",
       "        [0.2484096 , 0.24125063],\n",
       "        [0.66565896, 0.62931184]]),\n",
       " array([[0.33595153, 0.37431321],\n",
       "        [0.49632286, 0.53727262],\n",
       "        [0.16782009, 0.18701546],\n",
       "        [0.48670696, 0.53435814]]),\n",
       " array([[0.47401517, 0.47906204],\n",
       "        [0.63806897, 0.63975286],\n",
       "        [0.23686165, 0.23936272],\n",
       "        [0.62675679, 0.64244995]]),\n",
       " array([[0.4890237 , 0.42450623],\n",
       "        [0.66806723, 0.60912675],\n",
       "        [0.24401443, 0.21178665],\n",
       "        [0.5057857 , 0.46715766]]),\n",
       " array([[0.48498551, 0.47142578],\n",
       "        [0.6710455 , 0.65275712],\n",
       "        [0.24202607, 0.23550716],\n",
       "        [0.65218822, 0.64077412]]),\n",
       " array([[0.48999489, 0.47503906],\n",
       "        [0.67957036, 0.6681501 ],\n",
       "        [0.24463373, 0.23722952],\n",
       "        [0.65489702, 0.6441037 ]]),\n",
       " array([[0.47919516, 0.48696702],\n",
       "        [0.65801121, 0.66935751],\n",
       "        [0.2391048 , 0.24325365],\n",
       "        [0.64782781, 0.64212592]]),\n",
       " array([[0.49131873, 0.48162169],\n",
       "        [0.68552241, 0.6615473 ],\n",
       "        [0.24535593, 0.24054394],\n",
       "        [0.49054379, 0.59883419]]),\n",
       " array([[0.48977564, 0.49046002],\n",
       "        [0.68203336, 0.6689736 ],\n",
       "        [0.24470144, 0.24508669],\n",
       "        [0.53567854, 0.62719863]]),\n",
       " array([[0.46361105, 0.48482422],\n",
       "        [0.63398061, 0.65544466],\n",
       "        [0.23148459, 0.24208662],\n",
       "        [0.59429481, 0.65303921]]),\n",
       " array([[0.48724763, 0.49129155],\n",
       "        [0.65383899, 0.65146322],\n",
       "        [0.24347236, 0.24545077],\n",
       "        [0.64850597, 0.65103412]]),\n",
       " array([[0.42249948, 0.46551794],\n",
       "        [0.58806476, 0.63096941],\n",
       "        [0.21105058, 0.23249631],\n",
       "        [0.57156807, 0.61877335]]),\n",
       " array([[0.48587378, 0.47578943],\n",
       "        [0.65079909, 0.64643763],\n",
       "        [0.24263675, 0.23759812],\n",
       "        [0.61617882, 0.62817335]]),\n",
       " array([[0.43324525, 0.46710553],\n",
       "        [0.61246998, 0.64449819],\n",
       "        [0.21643056, 0.23303827],\n",
       "        [0.5749673 , 0.61843792]]),\n",
       " array([[0.47593657, 0.49159941],\n",
       "        [0.64531821, 0.65813992],\n",
       "        [0.23777318, 0.24563491],\n",
       "        [0.63849703, 0.6360488 ]]),\n",
       " array([[0.48710029, 0.37877186],\n",
       "        [0.648507  , 0.54881857],\n",
       "        [0.24332797, 0.18928201],\n",
       "        [0.64062977, 0.53353955]]),\n",
       " array([[0.48250468, 0.4850499 ],\n",
       "        [0.64505426, 0.65300405],\n",
       "        [0.24107737, 0.24237384],\n",
       "        [0.63317227, 0.63846082]]),\n",
       " array([[0.48870042, 0.47492708],\n",
       "        [0.66280905, 0.63848303],\n",
       "        [0.24411939, 0.23725616],\n",
       "        [0.53922967, 0.63415675]]),\n",
       " array([[0.49539134, 0.47915047],\n",
       "        [0.67597384, 0.65201431],\n",
       "        [0.24731466, 0.23908315],\n",
       "        [0.53731002, 0.5809116 ]]),\n",
       " array([[0.45493835, 0.48648914],\n",
       "        [0.62942228, 0.65398627],\n",
       "        [0.22727609, 0.24306293],\n",
       "        [0.59096788, 0.65215274]]),\n",
       " array([[0.49881502, 0.48411797],\n",
       "        [0.67517284, 0.65254461],\n",
       "        [0.24919968, 0.24187504],\n",
       "        [0.63818922, 0.65122957]]),\n",
       " array([[0.40251698, 0.38246388],\n",
       "        [0.56679137, 0.55121161],\n",
       "        [0.20106889, 0.19111503],\n",
       "        [0.5648213 , 0.54259771]]),\n",
       " array([[0.4899162 , 0.48795181],\n",
       "        [0.6588838 , 0.65674975],\n",
       "        [0.24460555, 0.24371434],\n",
       "        [0.64618314, 0.63492148]]),\n",
       " array([[0.48974128, 0.49148437],\n",
       "        [0.6759534 , 0.65832985],\n",
       "        [0.24427887, 0.24548616],\n",
       "        [0.6572781 , 0.659054  ]]),\n",
       " array([[0.48853336, 0.49014855],\n",
       "        [0.67798954, 0.66611768],\n",
       "        [0.24374449, 0.24436896],\n",
       "        [0.65632668, 0.65747175]]),\n",
       " array([[0.47875863, 0.46791274],\n",
       "        [0.67142575, 0.65235584],\n",
       "        [0.23850423, 0.23376943],\n",
       "        [0.41953358, 0.54495851]]),\n",
       " array([[0.46887571, 0.47369414],\n",
       "        [0.65603152, 0.66450439],\n",
       "        [0.23425002, 0.23643075],\n",
       "        [0.60385848, 0.56337159]]),\n",
       " array([[0.49015625, 0.48119141],\n",
       "        [0.65627615, 0.65619923],\n",
       "        [0.24499782, 0.24037379],\n",
       "        [0.65785887, 0.64973562]]),\n",
       " array([[0.49104719, 0.49307194],\n",
       "        [0.6567382 , 0.65941883],\n",
       "        [0.24539423, 0.24632992],\n",
       "        [0.64253994, 0.61972287]]),\n",
       " array([[0.48216797, 0.47417969],\n",
       "        [0.68252696, 0.65860076],\n",
       "        [0.23966231, 0.23649736],\n",
       "        [0.65062527, 0.64331328]]),\n",
       " array([[0.48931641, 0.47791992],\n",
       "        [0.66144788, 0.64646952],\n",
       "        [0.24435666, 0.2383275 ],\n",
       "        [0.65710202, 0.64071999]]),\n",
       " array([[0.44843874, 0.45963585],\n",
       "        [0.63268156, 0.62999259],\n",
       "        [0.22340495, 0.22967194],\n",
       "        [0.47289538, 0.60326813]]),\n",
       " array([[0.48102405, 0.48698775],\n",
       "        [0.66041946, 0.65342101],\n",
       "        [0.24037861, 0.2432013 ],\n",
       "        [0.54628052, 0.62089399]]),\n",
       " array([[0.47246736, 0.46699148],\n",
       "        [0.64478171, 0.64085791],\n",
       "        [0.23606465, 0.23328094],\n",
       "        [0.58146204, 0.60378233]]),\n",
       " array([[0.48667031, 0.49772011],\n",
       "        [0.65772079, 0.6770801 ],\n",
       "        [0.24318662, 0.24864885],\n",
       "        [0.62304517, 0.63855133]]),\n",
       " array([[0.47886455, 0.46026544],\n",
       "        [0.67894484, 0.62423956],\n",
       "        [0.23892073, 0.22973482],\n",
       "        [0.46522782, 0.61005538]]),\n",
       " array([[0.46518076, 0.48990834],\n",
       "        [0.66361627, 0.6752103 ],\n",
       "        [0.23208229, 0.24415756],\n",
       "        [0.50103932, 0.60555056]]),\n",
       " array([[0.44931329, 0.47430355],\n",
       "        [0.62043943, 0.63714816],\n",
       "        [0.22446783, 0.23698118],\n",
       "        [0.59071579, 0.63284379]]),\n",
       " array([[0.48562134, 0.48523881],\n",
       "        [0.65033348, 0.64534086],\n",
       "        [0.24265125, 0.24244332],\n",
       "        [0.64158552, 0.63824355]]),\n",
       " array([[0.43890384, 0.45067586],\n",
       "        [0.61658689, 0.61698237],\n",
       "        [0.21935117, 0.2251815 ],\n",
       "        [0.57913944, 0.61256012]]),\n",
       " array([[0.48909355, 0.48924197],\n",
       "        [0.65675852, 0.65140724],\n",
       "        [0.24433007, 0.24450211],\n",
       "        [0.64219794, 0.64912998]]),\n",
       " array([[0.43687788, 0.48496481],\n",
       "        [0.62532578, 0.65638291],\n",
       "        [0.21815623, 0.24202243],\n",
       "        [0.52012429, 0.58610405]]),\n",
       " array([[0.50141584, 0.49614845],\n",
       "        [0.66853589, 0.65782754],\n",
       "        [0.2500381 , 0.24787528],\n",
       "        [0.63978109, 0.65144272]]),\n",
       " array([[0.47375691, 0.39750904],\n",
       "        [0.6580533 , 0.56824513],\n",
       "        [0.23671548, 0.19864281],\n",
       "        [0.60017498, 0.55750268]]),\n",
       " array([[0.4978156 , 0.47885651],\n",
       "        [0.68450034, 0.64472106],\n",
       "        [0.24850578, 0.2392419 ],\n",
       "        [0.59850818, 0.64169364]]),\n",
       " array([[0.48166465, 0.41574037],\n",
       "        [0.64817445, 0.58115005],\n",
       "        [0.24066538, 0.20763008],\n",
       "        [0.64980683, 0.57174738]]),\n",
       " array([[0.47409914, 0.49694745],\n",
       "        [0.63910865, 0.66142652],\n",
       "        [0.23688307, 0.24830622],\n",
       "        [0.64253994, 0.65454354]]),\n",
       " array([[0.47395955, 0.45885835],\n",
       "        [0.6503445 , 0.63129727],\n",
       "        [0.23684211, 0.22922421],\n",
       "        [0.56771198, 0.59541315]]),\n",
       " array([[0.47682461, 0.48472179],\n",
       "        [0.66412653, 0.66237719],\n",
       "        [0.2379663 , 0.24199622],\n",
       "        [0.53034043, 0.65280884]]),\n",
       " array([[0.44501614, 0.45692376],\n",
       "        [0.61436252, 0.62111169],\n",
       "        [0.22232576, 0.22823316],\n",
       "        [0.6021432 , 0.61214643]]),\n",
       " array([[0.48751435, 0.48548925],\n",
       "        [0.65228364, 0.64492146],\n",
       "        [0.24359097, 0.24257588],\n",
       "        [0.63428427, 0.63566718]]),\n",
       " array([[0.47396547, 0.38298127],\n",
       "        [0.63408055, 0.54963535],\n",
       "        [0.23668849, 0.19131359],\n",
       "        [0.64214393, 0.54582635]]),\n",
       " array([[0.48928965, 0.47759613],\n",
       "        [0.65115548, 0.64358622],\n",
       "        [0.24453299, 0.23859136],\n",
       "        [0.65355283, 0.63643022]]),\n",
       " array([[0.49171778, 0.4420431 ],\n",
       "        [0.65712123, 0.612273  ],\n",
       "        [0.24565982, 0.22066294],\n",
       "        [0.65921203, 0.58822881]]),\n",
       " array([[0.48716797, 0.47876379],\n",
       "        [0.65456883, 0.63943907],\n",
       "        [0.24343213, 0.23918838],\n",
       "        [0.655162  , 0.64214393]]),\n",
       " array([[0.471, 0.471],\n",
       "        [0.651, 0.651],\n",
       "        [0.235, 0.235],\n",
       "        [0.642, 0.642]]),\n",
       " array([[0.49623047, 0.48105318],\n",
       "        [0.66916877, 0.65586864],\n",
       "        [0.24780798, 0.24003766],\n",
       "        [0.66330753, 0.60279169]]),\n",
       " array([[0.471, 0.471],\n",
       "        [0.651, 0.651],\n",
       "        [0.235, 0.235],\n",
       "        [0.642, 0.642]]),\n",
       " array([[0.471, 0.471],\n",
       "        [0.651, 0.651],\n",
       "        [0.235, 0.235],\n",
       "        [0.642, 0.642]]),\n",
       " array([[0.47378662, 0.39307994],\n",
       "        [0.6476779 , 0.56731728],\n",
       "        [0.23665508, 0.19642065],\n",
       "        [0.58504905, 0.51255756]]),\n",
       " array([[0.480881  , 0.49248046],\n",
       "        [0.64805812, 0.66009735],\n",
       "        [0.24022382, 0.246027  ],\n",
       "        [0.63820733, 0.65533859]]),\n",
       " array([[0.47620877, 0.46100668],\n",
       "        [0.65335636, 0.64802009],\n",
       "        [0.23764934, 0.22997469],\n",
       "        [0.60714383, 0.51604956]]),\n",
       " array([[0.47927396, 0.48444245],\n",
       "        [0.64965383, 0.66918715],\n",
       "        [0.23860943, 0.24199948],\n",
       "        [0.61449369, 0.6135182 ]]),\n",
       " array([[0.49460938, 0.40626281],\n",
       "        [0.66922122, 0.57735322],\n",
       "        [0.24711674, 0.20290893],\n",
       "        [0.66185772, 0.55823384]]),\n",
       " array([[0.47912109, 0.47755595],\n",
       "        [0.65583895, 0.65081016],\n",
       "        [0.23930305, 0.23843958],\n",
       "        [0.64784566, 0.61120529]]),\n",
       " array([[0.47509481, 0.4965469 ],\n",
       "        [0.63434433, 0.65976622],\n",
       "        [0.2374144 , 0.24810259],\n",
       "        [0.6437625 , 0.6411529 ]]),\n",
       " array([[0.48127386, 0.50071762],\n",
       "        [0.64167269, 0.66243836],\n",
       "        [0.24051492, 0.25015581],\n",
       "        [0.63744628, 0.65826334]]),\n",
       " array([[0.42302686, 0.45503822],\n",
       "        [0.59401085, 0.62966173],\n",
       "        [0.21129387, 0.22733327],\n",
       "        [0.5516061 , 0.58311079]]),\n",
       " array([[0.49951172, 0.49032806],\n",
       "        [0.66575556, 0.69990818],\n",
       "        [0.24959486, 0.24201747],\n",
       "        [0.6662325 , 0.58842342]]),\n",
       " array([[0.45122003, 0.47500534],\n",
       "        [0.62619208, 0.6474456 ],\n",
       "        [0.22546441, 0.23729399],\n",
       "        [0.58836504, 0.60593024]]),\n",
       " array([[0.49105122, 0.48505117],\n",
       "        [0.66053054, 0.66905864],\n",
       "        [0.24528403, 0.24202285],\n",
       "        [0.6278057 , 0.61701984]]),\n",
       " array([[0.41583661, 0.43689139],\n",
       "        [0.58950635, 0.60953895],\n",
       "        [0.20777427, 0.21823381],\n",
       "        [0.57593836, 0.58342441]]),\n",
       " array([[0.49039606, 0.47045133],\n",
       "        [0.66532101, 0.63996382],\n",
       "        [0.24487862, 0.23497551],\n",
       "        [0.63643022, 0.61321777]]),\n",
       " array([[0.4913375 , 0.48355469],\n",
       "        [0.68019274, 0.65984382],\n",
       "        [0.24498356, 0.24152657],\n",
       "        [0.65840397, 0.65188657]]),\n",
       " array([[0.48119067, 0.49203125],\n",
       "        [0.65901613, 0.66779769],\n",
       "        [0.24043796, 0.24583726],\n",
       "        [0.64971781, 0.6595455 ]]),\n",
       " array([[0.44731528, 0.34050417],\n",
       "        [0.64126362, 0.52414296],\n",
       "        [0.22313057, 0.16941433],\n",
       "        [0.45461954, 0.34782749]]),\n",
       " array([[0.47425267, 0.4755947 ],\n",
       "        [0.66495417, 0.64990225],\n",
       "        [0.23684142, 0.23741396],\n",
       "        [0.51935395, 0.49752032]]),\n",
       " array([[0.44207812, 0.38436239],\n",
       "        [0.61057679, 0.54284574],\n",
       "        [0.22089147, 0.19192703],\n",
       "        [0.59677972, 0.542328  ]]),\n",
       " array([[0.49291043, 0.46873761],\n",
       "        [0.66469346, 0.63176317],\n",
       "        [0.24615814, 0.23425507],\n",
       "        [0.63679327, 0.63183913]]),\n",
       " array([[0.46595996, 0.47007771],\n",
       "        [0.62663493, 0.64470445],\n",
       "        [0.23276236, 0.23488075],\n",
       "        [0.61810232, 0.60606308]]),\n",
       " array([[0.49183922, 0.4868027 ],\n",
       "        [0.65365525, 0.65477885],\n",
       "        [0.24578651, 0.24312787],\n",
       "        [0.64235996, 0.64516214]]),\n",
       " array([[0.45092138, 0.46343574],\n",
       "        [0.61561469, 0.62971377],\n",
       "        [0.22515766, 0.23154344],\n",
       "        [0.60153231, 0.63032022]]),\n",
       " array([[0.48188257, 0.48842769],\n",
       "        [0.65092608, 0.65315279],\n",
       "        [0.24078115, 0.24404547],\n",
       "        [0.62745624, 0.64390619]]),\n",
       " array([[0.47949787, 0.46563432],\n",
       "        [0.65915103, 0.63328735],\n",
       "        [0.239497  , 0.23264229],\n",
       "        [0.58038041, 0.61043261]]),\n",
       " array([[0.49991442, 0.48995477],\n",
       "        [0.66445797, 0.65450883],\n",
       "        [0.24964995, 0.24480201],\n",
       "        [0.62670154, 0.63913032]]),\n",
       " array([[0.36263272, 0.3958896 ],\n",
       "        [0.54349635, 0.57321801],\n",
       "        [0.18114364, 0.19768773],\n",
       "        [0.48352462, 0.50506584]]),\n",
       " array([[0.49472658, 0.48812285],\n",
       "        [0.6691842 , 0.66692022],\n",
       "        [0.24707703, 0.24385059],\n",
       "        [0.60733326, 0.58254201]]),\n",
       " array([[0.44933829, 0.44810425],\n",
       "        [0.6195339 , 0.61760688],\n",
       "        [0.22433041, 0.22377263],\n",
       "        [0.54860885, 0.59531681]]),\n",
       " array([[0.48529727, 0.49301252],\n",
       "        [0.66087794, 0.6542669 ],\n",
       "        [0.24246607, 0.24632564],\n",
       "        [0.61327411, 0.64446268]]),\n",
       " array([[0.45396519, 0.46039986],\n",
       "        [0.64128179, 0.63928274],\n",
       "        [0.22681561, 0.23004598],\n",
       "        [0.55717748, 0.59073518]]),\n",
       " array([[0.48820913, 0.47243688],\n",
       "        [0.6592068 , 0.64177052],\n",
       "        [0.24386715, 0.23599213],\n",
       "        [0.62494964, 0.61743064]]),\n",
       " array([[0.48966797, 0.49874044],\n",
       "        [0.65818697, 0.66831281],\n",
       "        [0.2447283 , 0.24921587],\n",
       "        [0.65741894, 0.58918189]]),\n",
       " array([[0.47607825, 0.48649459],\n",
       "        [0.64256176, 0.65470237],\n",
       "        [0.23787146, 0.24308247],\n",
       "        [0.6426299 , 0.64462416]]),\n",
       " array([[0.38255558, 0.44763521],\n",
       "        [0.55393702, 0.62412808],\n",
       "        [0.1910931 , 0.22362622],\n",
       "        [0.52238784, 0.56805247]]),\n",
       " array([[0.47937054, 0.48371794],\n",
       "        [0.65048953, 0.65666479],\n",
       "        [0.23951761, 0.24166412],\n",
       "        [0.62219292, 0.62644364]]),\n",
       " array([[0.46635343, 0.46631678],\n",
       "        [0.63067769, 0.63593156],\n",
       "        [0.23285117, 0.23289399],\n",
       "        [0.62778731, 0.61520569]]),\n",
       " array([[0.48616585, 0.48379342],\n",
       "        [0.65083806, 0.65305571],\n",
       "        [0.24291282, 0.24172802],\n",
       "        [0.64593251, 0.64100863]]),\n",
       " array([[0.4632247 , 0.49050341],\n",
       "        [0.65564447, 0.65222055],\n",
       "        [0.23115272, 0.24493427],\n",
       "        [0.49223294, 0.58719647]]),\n",
       " array([[0.49367311, 0.49825296],\n",
       "        [0.66408582, 0.65490908],\n",
       "        [0.24664898, 0.24884962],\n",
       "        [0.60829856, 0.64777424]]),\n",
       " array([[0.44593765, 0.42471236],\n",
       "        [0.61904762, 0.61800388],\n",
       "        [0.22268549, 0.21130931],\n",
       "        [0.59727949, 0.45973346]]),\n",
       " array([[0.49184407, 0.50313323],\n",
       "        [0.65113725, 0.67434334],\n",
       "        [0.24565337, 0.25139585],\n",
       "        [0.65450819, 0.65987881]]),\n",
       " array([[0.46078124, 0.44601724],\n",
       "        [0.64637208, 0.62177839],\n",
       "        [0.22975957, 0.22285592],\n",
       "        [0.5737367 , 0.57769876]]),\n",
       " array([[0.48523236, 0.47690251],\n",
       "        [0.65911205, 0.64956195],\n",
       "        [0.24239621, 0.23815288],\n",
       "        [0.58678701, 0.6168704 ]]),\n",
       " array([[0.49240556, 0.4953125 ],\n",
       "        [0.66736524, 0.67382294],\n",
       "        [0.24593799, 0.24659412],\n",
       "        [0.65893107, 0.66248694]]),\n",
       " array([[0.49457364, 0.49932314],\n",
       "        [0.67515269, 0.67726535],\n",
       "        [0.24705909, 0.24938683],\n",
       "        [0.60319192, 0.60359193]]),\n",
       " array([[0.49365234, 0.49427734],\n",
       "        [0.66674581, 0.66637702],\n",
       "        [0.24567945, 0.247009  ],\n",
       "        [0.66100033, 0.66156038]]),\n",
       " array([[0.49189453, 0.48782155],\n",
       "        [0.66405632, 0.65486947],\n",
       "        [0.24574875, 0.2437625 ],\n",
       "        [0.65942266, 0.63015531]]),\n",
       " array([[0.39015168, 0.43821653],\n",
       "        [0.56119337, 0.60972253],\n",
       "        [0.19494239, 0.21891111],\n",
       "        [0.51703813, 0.595548  ]]),\n",
       " array([[0.49635917, 0.47107639],\n",
       "        [0.66639671, 0.64078632],\n",
       "        [0.24794017, 0.23538536],\n",
       "        [0.62068966, 0.6250235 ]]),\n",
       " array([[0.48229969, 0.48470289],\n",
       "        [0.66340588, 0.65597732],\n",
       "        [0.24100693, 0.2421881 ],\n",
       "        [0.58986188, 0.63112585]]),\n",
       " array([[0.47987898, 0.48133323],\n",
       "        [0.64695647, 0.64969727],\n",
       "        [0.23973469, 0.24044489],\n",
       "        [0.61398736, 0.63701101]]),\n",
       " array([[0.41286068, 0.45990461],\n",
       "        [0.58249491, 0.63591907],\n",
       "        [0.20624459, 0.22977853],\n",
       "        [0.56244385, 0.61541166]]),\n",
       " array([[0.47613326, 0.49040596],\n",
       "        [0.64794609, 0.65855671],\n",
       "        [0.23785061, 0.2449816 ],\n",
       "        [0.61961123, 0.65156703]]),\n",
       " array([[0.3947401 , 0.32281435],\n",
       "        [0.56366528, 0.48323106],\n",
       "        [0.19715886, 0.16124333],\n",
       "        [0.54415173, 0.47407871]]),\n",
       " array([[0.48839637, 0.485     ],\n",
       "        [0.6544535 , 0.65790589],\n",
       "        [0.24398344, 0.24212049],\n",
       "        [0.64421142, 0.65319865]]),\n",
       " array([[0.45806478, 0.47904073],\n",
       "        [0.6235087 , 0.64102564],\n",
       "        [0.228845  , 0.23919495],\n",
       "        [0.60710594, 0.64280981]]),\n",
       " array([[0.4906865 , 0.48374592],\n",
       "        [0.65420272, 0.64794412],\n",
       "        [0.24510881, 0.24161272],\n",
       "        [0.62526347, 0.64877347]]),\n",
       " array([[0.45346057, 0.33419322],\n",
       "        [0.62431309, 0.50145152],\n",
       "        [0.22656987, 0.16698231],\n",
       "        [0.60833639, 0.46582567]]),\n",
       " array([[0.47269211, 0.49081699],\n",
       "        [0.64229218, 0.65770242],\n",
       "        [0.23623125, 0.2452273 ],\n",
       "        [0.6418918 , 0.61563628]]),\n",
       " array([[0.47619849, 0.4548721 ],\n",
       "        [0.64384808, 0.62205323],\n",
       "        [0.23782762, 0.22707962],\n",
       "        [0.613368  , 0.58696252]]),\n",
       " array([[0.48984114, 0.48625926],\n",
       "        [0.6508179 , 0.65012792],\n",
       "        [0.24471299, 0.24294921],\n",
       "        [0.62782408, 0.63624862]]),\n",
       " array([[0.48201933, 0.45944684],\n",
       "        [0.65835113, 0.64370931],\n",
       "        [0.24077683, 0.22927728],\n",
       "        [0.56877297, 0.5751061 ]]),\n",
       " array([[0.46644969, 0.48351715],\n",
       "        [0.64921662, 0.65299   ],\n",
       "        [0.23306104, 0.24166007],\n",
       "        [0.54257696, 0.63395632]]),\n",
       " array([[0.47787757, 0.49029776],\n",
       "        [0.6565463 , 0.65583308],\n",
       "        [0.23872997, 0.24493455],\n",
       "        [0.56620787, 0.62822849]]),\n",
       " array([[0.48775833, 0.48245234],\n",
       "        [0.67059162, 0.65327075],\n",
       "        [0.2436657 , 0.24099484],\n",
       "        [0.58026232, 0.64723833]]),\n",
       " array([[0.42918569, 0.45293611],\n",
       "        [0.60542731, 0.63060904],\n",
       "        [0.21445049, 0.2262204 ],\n",
       "        [0.58224764, 0.60311571]]),\n",
       " array([[0.49068726, 0.48322934],\n",
       "        [0.65668385, 0.65272415],\n",
       "        [0.24512313, 0.2414892 ],\n",
       "        [0.65572694, 0.64404984]]),\n",
       " array([[0.47864836, 0.34057642],\n",
       "        [0.64667447, 0.50209714],\n",
       "        [0.23904193, 0.17016757],\n",
       "        [0.61366836, 0.48789132]]),\n",
       " array([[0.47559749, 0.49772502],\n",
       "        [0.63749865, 0.65889747],\n",
       "        [0.23765836, 0.24871919],\n",
       "        [0.63176601, 0.65898376]]),\n",
       " array([[0.48445022, 0.42605559],\n",
       "        [0.65166481, 0.59929565],\n",
       "        [0.24203425, 0.21289243],\n",
       "        [0.61514951, 0.5634119 ]]),\n",
       " array([[0.49593443, 0.49139932],\n",
       "        [0.66400737, 0.65832801],\n",
       "        [0.24780561, 0.24553156],\n",
       "        [0.62096828, 0.63304455]]),\n",
       " array([[0.46443677, 0.44619755],\n",
       "        [0.65514522, 0.62449916],\n",
       "        [0.23171532, 0.22292741],\n",
       "        [0.5435098 , 0.57019185]]),\n",
       " array([[0.47808815, 0.49698283],\n",
       "        [0.64914646, 0.66707436],\n",
       "        [0.2388871 , 0.24828262],\n",
       "        [0.61295479, 0.64805989]]),\n",
       " array([[0.46490234, 0.49208984],\n",
       "        [0.64973386, 0.66048865],\n",
       "        [0.23166573, 0.24579105],\n",
       "        [0.63472128, 0.65959814]]),\n",
       " array([[0.49509766, 0.49236328],\n",
       "        [0.66672804, 0.66407629],\n",
       "        [0.247136  , 0.24594489],\n",
       "        [0.66229474, 0.65984374]]),\n",
       " array([[0.4732065 , 0.45533885],\n",
       "        [0.64197357, 0.62416805],\n",
       "        [0.23643516, 0.22746238],\n",
       "        [0.61589825, 0.60539863]]),\n",
       " array([[0.47680503, 0.48814021],\n",
       "        [0.65003147, 0.65401464],\n",
       "        [0.23792108, 0.24365205],\n",
       "        [0.59508554, 0.63896753]]),\n",
       " array([[0.45001875, 0.45085266],\n",
       "        [0.61491161, 0.62365838],\n",
       "        [0.22475312, 0.22528158],\n",
       "        [0.59340659, 0.59595239]]),\n",
       " array([[0.48661263, 0.49015779],\n",
       "        [0.65000547, 0.65305797],\n",
       "        [0.24292302, 0.24477513],\n",
       "        [0.63415675, 0.64911216]]),\n",
       " array([[0.42623764, 0.47644657],\n",
       "        [0.59706929, 0.64677791],\n",
       "        [0.21294349, 0.23813709],\n",
       "        [0.5909485 , 0.63039349]]),\n",
       " array([[0.48395304, 0.46540704],\n",
       "        [0.66241637, 0.66092163],\n",
       "        [0.24127492, 0.23128155],\n",
       "        [0.64113486, 0.52455946]]),\n",
       " array([[0.33571639, 0.41353217],\n",
       "        [0.49488562, 0.58116386],\n",
       "        [0.16766948, 0.20662645],\n",
       "        [0.47541911, 0.57168761]]),\n",
       " array([[0.49241526, 0.48671792],\n",
       "        [0.65404877, 0.64918611],\n",
       "        [0.24608019, 0.24307456],\n",
       "        [0.63985336, 0.63701101]]),\n",
       " array([[0.46856475, 0.37864548],\n",
       "        [0.63329155, 0.54653431],\n",
       "        [0.23411627, 0.18922209],\n",
       "        [0.62434005, 0.53659931]]),\n",
       " array([[0.48908905, 0.49743882],\n",
       "        [0.65616197, 0.66817661],\n",
       "        [0.24431049, 0.24836537],\n",
       "        [0.65480866, 0.64673777]]),\n",
       " array([[0.50080202, 0.49793155],\n",
       "        [0.67434972, 0.66627527],\n",
       "        [0.25021414, 0.2486704 ],\n",
       "        [0.59647199, 0.63524896]]),\n",
       " array([[0.48279631, 0.48187586],\n",
       "        [0.65089002, 0.65413204],\n",
       "        [0.24108935, 0.24073099],\n",
       "        [0.60273449, 0.6355581 ]]),\n",
       " array([[0.43647168, 0.48928404],\n",
       "        [0.61608764, 0.66167258],\n",
       "        [0.21791058, 0.24445386],\n",
       "        [0.55538626, 0.6184752 ]]),\n",
       " array([[0.47535156, 0.49227016],\n",
       "        [0.66590057, 0.66415171],\n",
       "        [0.23673355, 0.24597661],\n",
       "        [0.6443909 , 0.61619752]]),\n",
       " array([[0.45755801, 0.46970208],\n",
       "        [0.63301752, 0.62990886],\n",
       "        [0.22851797, 0.23450128],\n",
       "        [0.56805247, 0.60667002]]),\n",
       " array([[0.49142658, 0.49291074],\n",
       "        [0.65910151, 0.6530703 ],\n",
       "        [0.24554203, 0.24620827],\n",
       "        [0.63860563, 0.65547984]]),\n",
       " array([[0.47388477, 0.46866874],\n",
       "        [0.65698594, 0.64507563],\n",
       "        [0.2368148 , 0.23417257],\n",
       "        [0.60130308, 0.60723855]]),\n",
       " array([[0.48561032, 0.47451553],\n",
       "        [0.66038744, 0.64733996],\n",
       "        [0.24248546, 0.23685516],\n",
       "        [0.62896315, 0.63289855]]),\n",
       " array([[0.41237292, 0.48390625],\n",
       "        [0.58996101, 0.66336448],\n",
       "        [0.20593762, 0.24171321],\n",
       "        [0.54263919, 0.65220596]]),\n",
       " array([[0.48237651, 0.47535156],\n",
       "        [0.66020327, 0.65287837],\n",
       "        [0.24064975, 0.2371742 ],\n",
       "        [0.5417883 , 0.6443909 ]]),\n",
       " array([[0.32731689, 0.41861939],\n",
       "        [0.48772269, 0.58485931],\n",
       "        [0.16344998, 0.20905605],\n",
       "        [0.46779986, 0.57128905]]),\n",
       " array([[0.48601626, 0.49215458],\n",
       "        [0.64888334, 0.66104299],\n",
       "        [0.24282923, 0.2458306 ],\n",
       "        [0.6360488 , 0.64671988]]),\n",
       " array([[0.46812612, 0.45111772],\n",
       "        [0.64079207, 0.62037685],\n",
       "        [0.23389545, 0.22539749],\n",
       "        [0.62130249, 0.60410589]]),\n",
       " array([[0.48630859, 0.49929687],\n",
       "        [0.6655707 , 0.67461867],\n",
       "        [0.2427954 , 0.24928234],\n",
       "        [0.65438442, 0.66604137]]),\n",
       " array([[0.47358763, 0.47238065],\n",
       "        [0.65191111, 0.65131561],\n",
       "        [0.2364053 , 0.23592168],\n",
       "        [0.59491204, 0.64162156]]),\n",
       " array([[0.47959963, 0.49804665],\n",
       "        [0.65279261, 0.66660566],\n",
       "        [0.23966986, 0.24877552],\n",
       "        [0.61276688, 0.66487607]]),\n",
       " array([[0.44238508, 0.40773228],\n",
       "        [0.62378235, 0.58321936],\n",
       "        [0.22099101, 0.20369012],\n",
       "        [0.55748236, 0.5539991 ]]),\n",
       " array([[0.49017578, 0.4818514 ],\n",
       "        [0.67626849, 0.65215958],\n",
       "        [0.24455687, 0.24076117],\n",
       "        [0.65787646, 0.63350059]]),\n",
       " array([[0.46224511, 0.45815131],\n",
       "        [0.62097399, 0.6186394 ],\n",
       "        [0.23073554, 0.22884674],\n",
       "        [0.60928142, 0.60950803]]),\n",
       " array([[0.48174534, 0.47299247],\n",
       "        [0.65037636, 0.63726178],\n",
       "        [0.24048909, 0.23604643],\n",
       "        [0.62603819, 0.63116244]]),\n",
       " array([[0.44873712, 0.45398227],\n",
       "        [0.61395555, 0.62025419],\n",
       "        [0.22407584, 0.22674797],\n",
       "        [0.60505667, 0.61877335]]),\n",
       " array([[0.4809925 , 0.48946187],\n",
       "        [0.64428425, 0.6583933 ],\n",
       "        [0.24033999, 0.24451502],\n",
       "        [0.63581258, 0.64605783]]),\n",
       " array([[0.40892681, 0.42788866],\n",
       "        [0.58272853, 0.59729611],\n",
       "        [0.20426256, 0.21374393],\n",
       "        [0.54191288, 0.56829272]]),\n",
       " array([[0.47587296, 0.4786087 ],\n",
       "        [0.64584884, 0.65074618],\n",
       "        [0.23768451, 0.23900718],\n",
       "        [0.595259  , 0.60480959]]),\n",
       " array([[0.43213981, 0.47208882],\n",
       "        [0.60552076, 0.63693756],\n",
       "        [0.21588656, 0.23573741],\n",
       "        [0.54623925, 0.61970426]]),\n",
       " array([[0.47880947, 0.48060964],\n",
       "        [0.64527428, 0.64827454],\n",
       "        [0.23917812, 0.23788896],\n",
       "        [0.61703852, 0.63366469]]),\n",
       " array([[0.48060547, 0.46248047],\n",
       "        [0.6715701 , 0.65460426],\n",
       "        [0.24019291, 0.2309863 ],\n",
       "        [0.64920126, 0.63246037]]),\n",
       " array([[0.49060547, 0.49643279],\n",
       "        [0.6835474 , 0.67688711],\n",
       "        [0.24509947, 0.24803286],\n",
       "        [0.65826334, 0.65949286]]),\n",
       " array([[0.48633961, 0.46760928],\n",
       "        [0.66809142, 0.64470918],\n",
       "        [0.24246038, 0.23345219],\n",
       "        [0.61951818, 0.56662934]]),\n",
       " array([[0.4990981 , 0.48584643],\n",
       "        [0.67654904, 0.65301494],\n",
       "        [0.24917714, 0.24277604],\n",
       "        [0.64458828, 0.64684506]]),\n",
       " array([[0.46562728, 0.35775462],\n",
       "        [0.63108092, 0.52772591],\n",
       "        [0.23244533, 0.17874953],\n",
       "        [0.59614488, 0.49763054]]),\n",
       " array([[0.49233315, 0.48873047],\n",
       "        [0.66106939, 0.65983704],\n",
       "        [0.24598092, 0.24418012],\n",
       "        [0.6291467 , 0.65657348]]),\n",
       " array([[0.44227548, 0.48136498],\n",
       "        [0.6022536 , 0.64574542],\n",
       "        [0.22081915, 0.240579  ],\n",
       "        [0.60454341, 0.64151344]]),\n",
       " array([[0.48460037, 0.47275513],\n",
       "        [0.64433672, 0.63572136],\n",
       "        [0.24205219, 0.23622802],\n",
       "        [0.64415756, 0.63384697]]),\n",
       " array([[0.46757983, 0.45027639],\n",
       "        [0.66931108, 0.62578024],\n",
       "        [0.23318627, 0.22489646],\n",
       "        [0.4825808 , 0.49727778]]),\n",
       " array([[0.47896351, 0.47212842],\n",
       "        [0.66357986, 0.65002113],\n",
       "        [0.23932616, 0.23587897],\n",
       "        [0.579967  , 0.5920528 ]]),\n",
       " array([[0.49039735, 0.46111687],\n",
       "        [0.66932181, 0.62002894],\n",
       "        [0.24479227, 0.23034518],\n",
       "        [0.63277078, 0.62248947]]),\n",
       " array([[0.4896752 , 0.47919265],\n",
       "        [0.66746619, 0.64320192],\n",
       "        [0.24409316, 0.23922681],\n",
       "        [0.62174785, 0.62093114]]),\n",
       " array([[0.34757369, 0.48245401],\n",
       "        [0.50485437, 0.6502561 ],\n",
       "        [0.17360682, 0.24086142],\n",
       "        [0.49862178, 0.63588528]]),\n",
       " array([[0.4880076 , 0.4849615 ],\n",
       "        [0.64574915, 0.65066853],\n",
       "        [0.24380036, 0.24224507],\n",
       "        [0.64061172, 0.6416576 ]]),\n",
       " array([[0.49676383, 0.46722149],\n",
       "        [0.67081867, 0.64472641],\n",
       "        [0.24809255, 0.23348656],\n",
       "        [0.57625516, 0.60015584]]),\n",
       " array([[0.49119379, 0.48162024],\n",
       "        [0.67525072, 0.67194424],\n",
       "        [0.24478684, 0.23937861],\n",
       "        [0.53824961, 0.51465042]]),\n",
       " array([[0.49595983, 0.47532383],\n",
       "        [0.6748874 , 0.65736124],\n",
       "        [0.24766801, 0.23751858],\n",
       "        [0.59587538, 0.6014177 ]]),\n",
       " array([[0.49372414, 0.48669046],\n",
       "        [0.67258549, 0.66912048],\n",
       "        [0.24666197, 0.24302555],\n",
       "        [0.59102605, 0.54313681]]),\n",
       " array([[0.4139399 , 0.39665615],\n",
       "        [0.6025581 , 0.57087079],\n",
       "        [0.20680349, 0.19803312],\n",
       "        [0.49243272, 0.53841652]]),\n",
       " array([[0.48334564, 0.48799159],\n",
       "        [0.66226348, 0.66044288],\n",
       "        [0.2415337 , 0.24343999],\n",
       "        [0.60604411, 0.62372991]]),\n",
       " array([[0.45059966, 0.46242613],\n",
       "        [0.61704326, 0.62268463],\n",
       "        [0.225178  , 0.23088274],\n",
       "        [0.60284888, 0.62295258]]),\n",
       " array([[0.49080474, 0.47924382],\n",
       "        [0.65876084, 0.65061606],\n",
       "        [0.24507934, 0.23769841],\n",
       "        [0.63573988, 0.63011866]]),\n",
       " array([[0.42904317, 0.4111156 ],\n",
       "        [0.60252542, 0.58654595],\n",
       "        [0.21440037, 0.20538412],\n",
       "        [0.59278804, 0.56867295]]),\n",
       " array([[0.48317994, 0.48096718],\n",
       "        [0.64670916, 0.64938958],\n",
       "        [0.24115148, 0.23990116],\n",
       "        [0.63909415, 0.63521258]]),\n",
       " array([[0.43189971, 0.36586496],\n",
       "        [0.59605052, 0.53293624],\n",
       "        [0.21577194, 0.18279771],\n",
       "        [0.58542044, 0.52370861]]),\n",
       " array([[0.48949694, 0.48891285],\n",
       "        [0.65653912, 0.65981221],\n",
       "        [0.24456854, 0.24386691],\n",
       "        [0.62898151, 0.63889517]]),\n",
       " array([[0.46614551, 0.40248702],\n",
       "        [0.63471503, 0.57211724],\n",
       "        [0.23282914, 0.20109232],\n",
       "        [0.61133713, 0.54599154]]),\n",
       " array([[0.49473037, 0.47827308],\n",
       "        [0.66086004, 0.64272619],\n",
       "        [0.24710983, 0.23900097],\n",
       "        [0.64061172, 0.63539446]]),\n",
       " array([[0.44374871, 0.45348177],\n",
       "        [0.6119933 , 0.62202381],\n",
       "        [0.22168928, 0.22660792],\n",
       "        [0.59232377, 0.60799587]]),\n",
       " array([[0.48861145, 0.48975971],\n",
       "        [0.6629108 , 0.67843589],\n",
       "        [0.24412436, 0.24364353],\n",
       "        [0.59799009, 0.59743319]]),\n",
       " array([[0.41119428, 0.40594688],\n",
       "        [0.58228687, 0.58341196],\n",
       "        [0.20544667, 0.20281741],\n",
       "        [0.54825905, 0.54479309]]),\n",
       " array([[0.49019368, 0.48616   ],\n",
       "        [0.65437262, 0.6542851 ],\n",
       "        [0.24486285, 0.24293094],\n",
       "        [0.63999787, 0.64385231]]),\n",
       " array([[0.41053722, 0.36543043],\n",
       "        [0.57565743, 0.53206757],\n",
       "        [0.20514422, 0.18251372],\n",
       "        [0.56592676, 0.51583448]]),\n",
       " array([[0.49216806, 0.49236905],\n",
       "        [0.65362146, 0.65703579],\n",
       "        [0.24579983, 0.24587839],\n",
       "        [0.64066586, 0.64183776]]),\n",
       " array([[0.44938297, 0.4450101 ],\n",
       "        [0.61757673, 0.60966674],\n",
       "        [0.22452428, 0.22230054],\n",
       "        [0.60515168, 0.6099233 ]]),\n",
       " array([[0.49203803, 0.49086415],\n",
       "        [0.6552288 , 0.65352921],\n",
       "        [0.24563369, 0.24492131],\n",
       "        [0.65339347, 0.65303921]]),\n",
       " array([[0.47619849, 0.4548721 ],\n",
       "        [0.64384808, 0.62205323],\n",
       "        [0.23790271, 0.22718669],\n",
       "        [0.613368  , 0.58696252]]),\n",
       " array([[0.5006708 , 0.47983307],\n",
       "        [0.6708235 , 0.6429355 ],\n",
       "        [0.24996873, 0.23977453],\n",
       "        [0.63617597, 0.63885898]]),\n",
       " array([[0.47556546, 0.39349513],\n",
       "        [0.65226867, 0.56433299],\n",
       "        [0.23754349, 0.19661748],\n",
       "        [0.62076397, 0.55736042]]),\n",
       " array([[0.48839111, 0.49124537],\n",
       "        [0.67246377, 0.66426705],\n",
       "        [0.24380088, 0.2454327 ],\n",
       "        [0.63641206, 0.6546496 ]]),\n",
       " array([[0.48410156, 0.48003828],\n",
       "        [0.66255012, 0.66282802],\n",
       "        [0.24163352, 0.23926987],\n",
       "        [0.65238333, 0.64866648]]),\n",
       " array([[0.48524232, 0.482678  ],\n",
       "        [0.65647851, 0.65120553],\n",
       "        [0.24242435, 0.24115055],\n",
       "        [0.63775442, 0.63359176]]),\n",
       " array([[0.43580678, 0.46412547],\n",
       "        [0.61410556, 0.63226183],\n",
       "        [0.21771698, 0.23190154],\n",
       "        [0.55532512, 0.61541166]]),\n",
       " array([[0.48692502, 0.48710938],\n",
       "        [0.6521269 , 0.6550746 ],\n",
       "        [0.24331782, 0.24334284],\n",
       "        [0.65135391, 0.65510901]]),\n",
       " array([[0.42932729, 0.44688131],\n",
       "        [0.62100742, 0.62270221],\n",
       "        [0.21399914, 0.22200098],\n",
       "        [0.47401049, 0.5949506 ]]),\n",
       " array([[0.4972637 , 0.48107353],\n",
       "        [0.66656187, 0.6521618 ],\n",
       "        [0.24848   , 0.24022102],\n",
       "        [0.66391796, 0.62752982]]),\n",
       " array([[0.45092489, 0.48884656],\n",
       "        [0.62427452, 0.66856031],\n",
       "        [0.22521263, 0.24390005],\n",
       "        [0.5791    , 0.58760569]]),\n",
       " array([[0.49824286, 0.48016592],\n",
       "        [0.67504072, 0.63502503],\n",
       "        [0.24898213, 0.23973282],\n",
       "        [0.59243986, 0.63550356]]),\n",
       " array([[0.44593765, 0.42471236],\n",
       "        [0.61904762, 0.61800388],\n",
       "        [0.22278982, 0.21194538],\n",
       "        [0.59727949, 0.45973346]]),\n",
       " array([[0.48443529, 0.47712531],\n",
       "        [0.66481228, 0.66658673],\n",
       "        [0.24194933, 0.23836068],\n",
       "        [0.60769304, 0.60517068]]),\n",
       " array([[0.49476562, 0.42353516],\n",
       "        [0.67566414, 0.6187582 ],\n",
       "        [0.24670401, 0.21070193],\n",
       "        [0.6619976 , 0.59504699]]),\n",
       " array([[0.47658345, 0.48841797],\n",
       "        [0.64587   , 0.66222658],\n",
       "        [0.23807216, 0.24397036],\n",
       "        [0.61535549, 0.65629142]]),\n",
       " array([[0.48619067, 0.49177734],\n",
       "        [0.6486966 , 0.66076208],\n",
       "        [0.24295261, 0.24571153],\n",
       "        [0.63402921, 0.65931735]]),\n",
       " array([[0.49409953, 0.47770765],\n",
       "        [0.66983296, 0.65211426],\n",
       "        [0.24671487, 0.23837558],\n",
       "        [0.61578599, 0.63402921]]),\n",
       " array([[0.48550821, 0.46474555],\n",
       "        [0.66394184, 0.64577375],\n",
       "        [0.24249341, 0.23214859],\n",
       "        [0.60130308, 0.58594786]]),\n",
       " array([[0.4932099 , 0.49222065],\n",
       "        [0.66818078, 0.66487551],\n",
       "        [0.24639747, 0.24595234],\n",
       "        [0.62714341, 0.60627178]]),\n",
       " array([[0.45876437, 0.44029154],\n",
       "        [0.62468782, 0.60029895],\n",
       "        [0.22918705, 0.21994864],\n",
       "        [0.60608206, 0.59508554]]),\n",
       " array([[0.49104989, 0.49572972],\n",
       "        [0.65622349, 0.65330855],\n",
       "        [0.24518701, 0.24773925],\n",
       "        [0.6237669 , 0.65544453]]),\n",
       " array([[0.40312599, 0.42381983],\n",
       "        [0.57312052, 0.5898886 ],\n",
       "        [0.20143139, 0.21177319],\n",
       "        [0.56831273, 0.57692789]]),\n",
       " array([[0.49046009, 0.49294465],\n",
       "        [0.65899565, 0.6527116 ],\n",
       "        [0.24480844, 0.24599803],\n",
       "        [0.644947  , 0.64521592]]),\n",
       " array([[0.48633221, 0.41829839],\n",
       "        [0.67599178, 0.587776  ],\n",
       "        [0.24212719, 0.20899699],\n",
       "        [0.5892402 , 0.57284219]]),\n",
       " array([[0.46936146, 0.48045059],\n",
       "        [0.63293338, 0.64227664],\n",
       "        [0.23442395, 0.23998915],\n",
       "        [0.62579849, 0.64160354]]),\n",
       " array([[0.48603516, 0.43986354],\n",
       "        [0.67120701, 0.61410234],\n",
       "        [0.24282367, 0.21974   ],\n",
       "        [0.65413682, 0.58457966]]),\n",
       " array([[0.4892767 , 0.50251826],\n",
       "        [0.67137911, 0.67284835],\n",
       "        [0.24439112, 0.25095412],\n",
       "        [0.62494964, 0.63684771]]),\n",
       " array([[0.46443069, 0.41806831],\n",
       "        [0.63077595, 0.58627708],\n",
       "        [0.23206989, 0.20891721],\n",
       "        [0.62200751, 0.58226726]]),\n",
       " array([[0.48493753, 0.48575081],\n",
       "        [0.65959528, 0.6442931 ],\n",
       "        [0.241951  , 0.24259472],\n",
       "        [0.63099774, 0.63021028]]),\n",
       " array([[0.44680005, 0.45453275],\n",
       "        [0.61686267, 0.61769888],\n",
       "        [0.22315654, 0.22704692],\n",
       "        [0.58854016, 0.61552398]]),\n",
       " array([[0.4810543 , 0.48939232],\n",
       "        [0.6506633 , 0.65134477],\n",
       "        [0.24027898, 0.24448896],\n",
       "        [0.63266124, 0.63477588]]),\n",
       " array([[0.43813518, 0.39789508],\n",
       "        [0.61966689, 0.58171575],\n",
       "        [0.21844952, 0.19806685],\n",
       "        [0.48287306, 0.38707137]]),\n",
       " array([[0.48499916, 0.48739697],\n",
       "        [0.65714367, 0.66532726],\n",
       "        [0.24226052, 0.24346515],\n",
       "        [0.62211876, 0.60780662]]),\n",
       " array([[0.43644119, 0.47982907],\n",
       "        [0.60484756, 0.64625962],\n",
       "        [0.21810256, 0.23972147],\n",
       "        [0.59120051, 0.63262472]]),\n",
       " array([[0.46280304, 0.48750412],\n",
       "        [0.62943807, 0.65098989],\n",
       "        [0.23126673, 0.24348385],\n",
       "        [0.62671995, 0.63178429]]),\n",
       " array([[0.49818359, 0.45700025],\n",
       "        [0.67148423, 0.6313618 ],\n",
       "        [0.24895268, 0.22828123],\n",
       "        [0.66505013, 0.59885336]]),\n",
       " array([[0.49258491, 0.49237881],\n",
       "        [0.6641606 , 0.66851375],\n",
       "        [0.24599089, 0.2455974 ],\n",
       "        [0.65928224, 0.63185741]]),\n",
       " array([[0.45589612, 0.47304535],\n",
       "        [0.62201488, 0.64340405],\n",
       "        [0.22773231, 0.23641857],\n",
       "        [0.60869565, 0.64192783]]),\n",
       " array([[0.48021414, 0.48265989],\n",
       "        [0.64760624, 0.64185861],\n",
       "        [0.23993225, 0.24099529],\n",
       "        [0.63085131, 0.64019653]]),\n",
       " array([[0.46845794, 0.45525284],\n",
       "        [0.62925787, 0.6187201 ],\n",
       "        [0.23398249, 0.22740794],\n",
       "        [0.62472803, 0.6154491 ]]),\n",
       " array([[0.49653287, 0.47847161],\n",
       "        [0.65684707, 0.64315769],\n",
       "        [0.24813138, 0.23893317],\n",
       "        [0.6572605 , 0.63269775]]),\n",
       " array([[0.47806641, 0.48861328],\n",
       "        [0.65259818, 0.66667555],\n",
       "        [0.2389118 , 0.24401536],\n",
       "        [0.64688082, 0.65646772]]),\n",
       " array([[0.48716844, 0.48401048],\n",
       "        [0.66314667, 0.65716222],\n",
       "        [0.24296116, 0.24187183],\n",
       "        [0.65383604, 0.62483885]]),\n",
       " array([[0.41862959, 0.43843172],\n",
       "        [0.58917179, 0.61470246],\n",
       "        [0.20922352, 0.2190371 ],\n",
       "        [0.57554217, 0.57355789]]),\n",
       " array([[0.49033155, 0.48495925],\n",
       "        [0.64792156, 0.6551822 ],\n",
       "        [0.24488237, 0.24222437],\n",
       "        [0.63808054, 0.62154376]]),\n",
       " array([[0.46735416, 0.41546193],\n",
       "        [0.63243796, 0.59201585],\n",
       "        [0.23352839, 0.20763432],\n",
       "        [0.62956866, 0.55012955]]),\n",
       " array([[0.48515298, 0.49034091],\n",
       "        [0.66259628, 0.65605995],\n",
       "        [0.24186675, 0.24502451],\n",
       "        [0.63207673, 0.64126108]]),\n",
       " array([[0.48652344, 0.47070976],\n",
       "        [0.66269387, 0.64233679],\n",
       "        [0.242967  , 0.23514766],\n",
       "        [0.6545789 , 0.62018784]]),\n",
       " array([[0.49097656, 0.478125  ],\n",
       "        [0.67255264, 0.65335753],\n",
       "        [0.24519854, 0.23875345],\n",
       "        [0.65859729, 0.64693446]]),\n",
       " array([[0.47344763, 0.46054857],\n",
       "        [0.64701849, 0.63213315],\n",
       "        [0.23647429, 0.23013628],\n",
       "        [0.61331167, 0.60740902]]),\n",
       " array([[0.48342942, 0.49406358],\n",
       "        [0.64861706, 0.66214212],\n",
       "        [0.24135657, 0.24686795],\n",
       "        [0.62568783, 0.6240258 ]]),\n",
       " array([[0.43029898, 0.39559221],\n",
       "        [0.60205759, 0.57018717],\n",
       "        [0.21498207, 0.19770432],\n",
       "        [0.58647488, 0.55406035]]),\n",
       " array([[0.49199219, 0.48242188],\n",
       "        [0.66320889, 0.65703721],\n",
       "        [0.24548704, 0.24101682],\n",
       "        [0.65951041, 0.65085639]]),\n",
       " array([[0.43047317, 0.31618554],\n",
       "        [0.60941314, 0.48778167],\n",
       "        [0.21502618, 0.15798322],\n",
       "        [0.53553194, 0.40037491]]),\n",
       " array([[0.48490988, 0.47204413],\n",
       "        [0.6703042 , 0.64119094],\n",
       "        [0.24171845, 0.23584541],\n",
       "        [0.57787654, 0.61391231]]),\n",
       " array([[0.43552081, 0.44072981],\n",
       "        [0.60811143, 0.61745844],\n",
       "        [0.21749251, 0.22003515],\n",
       "        [0.55727912, 0.56813256]]),\n",
       " array([[0.48570028, 0.49722827],\n",
       "        [0.65438143, 0.65756817],\n",
       "        [0.24259376, 0.24832727],\n",
       "        [0.63422962, 0.64214393]]),\n",
       " array([[0.44916592, 0.42629458],\n",
       "        [0.61884972, 0.59706505],\n",
       "        [0.22442064, 0.21293445],\n",
       "        [0.6046575 , 0.58479484]]),\n",
       " array([[0.48883796, 0.47864433],\n",
       "        [0.65800223, 0.64517439],\n",
       "        [0.24416807, 0.23914139],\n",
       "        [0.62061533, 0.63512163]]),\n",
       " array([[0.46721721, 0.41148594],\n",
       "        [0.62775293, 0.57736955],\n",
       "        [0.23329902, 0.20557973],\n",
       "        [0.60969682, 0.57166769]]),\n",
       " array([[0.48613955, 0.48597263],\n",
       "        [0.64665033, 0.64567858],\n",
       "        [0.24284002, 0.24274731],\n",
       "        [0.63366469, 0.63970881]]),\n",
       " array([[0.45233172, 0.46973444],\n",
       "        [0.62332073, 0.64751748],\n",
       "        [0.22592119, 0.23468009],\n",
       "        [0.59005604, 0.59439129]]),\n",
       " array([[0.49224187, 0.48445617],\n",
       "        [0.65929155, 0.65502461],\n",
       "        [0.24599041, 0.24206553],\n",
       "        [0.6391484 , 0.63260646]]),\n",
       " array([[0.45665655, 0.40448277],\n",
       "        [0.630285  , 0.57634299],\n",
       "        [0.22807376, 0.20209925],\n",
       "        [0.57710586, 0.54510322]]),\n",
       " array([[0.48638247, 0.46797307],\n",
       "        [0.66078713, 0.64380511],\n",
       "        [0.24300922, 0.23376557],\n",
       "        [0.61998329, 0.59466136]]),\n",
       " array([[0.46177958, 0.45818248],\n",
       "        [0.62786989, 0.61963966],\n",
       "        [0.23075124, 0.22893381],\n",
       "        [0.6168704 , 0.61109227]]),\n",
       " array([[0.48765998, 0.47528397],\n",
       "        [0.65513862, 0.64033894],\n",
       "        [0.2431046 , 0.23728462],\n",
       "        [0.62725384, 0.61237211]]),\n",
       " array([[0.42067864, 0.40249968],\n",
       "        [0.59007402, 0.57794127],\n",
       "        [0.21018488, 0.20111256],\n",
       "        [0.56199972, 0.53662022]]),\n",
       " array([[0.49478808, 0.49594035],\n",
       "        [0.66761595, 0.66441399],\n",
       "        [0.24699098, 0.24782158],\n",
       "        [0.61946235, 0.65044743]]),\n",
       " array([[0.47556471, 0.47844496],\n",
       "        [0.64840222, 0.64502649],\n",
       "        [0.23764409, 0.23909355],\n",
       "        [0.60869565, 0.6313271 ]]),\n",
       " array([[0.49119021, 0.48646097],\n",
       "        [0.66952725, 0.65677868],\n",
       "        [0.2452983 , 0.24295663],\n",
       "        [0.60260102, 0.6138185 ]]),\n",
       " array([[0.4629533 , 0.47637832],\n",
       "        [0.63408969, 0.6481375 ],\n",
       "        [0.23121992, 0.23795387],\n",
       "        [0.58746931, 0.56759176]]),\n",
       " array([[0.48918405, 0.49320192],\n",
       "        [0.67014879, 0.66166768],\n",
       "        [0.24412308, 0.24632723],\n",
       "        [0.59363841, 0.63592162]]),\n",
       " array([[0.44205212, 0.4749468 ],\n",
       "        [0.60963729, 0.64144344],\n",
       "        [0.22091981, 0.23729441],\n",
       "        [0.60401074, 0.63209501]]),\n",
       " array([[0.48373509, 0.49877731],\n",
       "        [0.64781775, 0.66414579],\n",
       "        [0.24163768, 0.24916387],\n",
       "        [0.63831598, 0.66129791]]),\n",
       " array([[0.41965281, 0.32883473],\n",
       "        [0.60383844, 0.49719342],\n",
       "        [0.20905925, 0.16402605],\n",
       "        [0.340975  , 0.25639803]]),\n",
       " array([[0.47655511, 0.49333092],\n",
       "        [0.66116735, 0.68066126],\n",
       "        [0.23807562, 0.2464669 ],\n",
       "        [0.58485351, 0.59768289]]),\n",
       " array([[0.40798471, 0.45442645],\n",
       "        [0.57399547, 0.62348033],\n",
       "        [0.20383326, 0.22707024],\n",
       "        [0.56753165, 0.61180777]]),\n",
       " array([[0.50040672, 0.47944191],\n",
       "        [0.66682023, 0.65196586],\n",
       "        [0.24996006, 0.2393577 ],\n",
       "        [0.64920126, 0.62546646]]),\n",
       " array([[0.471, 0.471],\n",
       "        [0.651, 0.651],\n",
       "        [0.235, 0.235],\n",
       "        [0.642, 0.642]]),\n",
       " array([[0.471, 0.471],\n",
       "        [0.651, 0.651],\n",
       "        [0.235, 0.235],\n",
       "        [0.642, 0.642]]),\n",
       " array([[0.39517908, 0.38137196],\n",
       "        [0.56053021, 0.55209971],\n",
       "        [0.19745458, 0.19054002],\n",
       "        [0.55583449, 0.5404373 ]]),\n",
       " array([[0.49194166, 0.4766218 ],\n",
       "        [0.65674251, 0.63665822],\n",
       "        [0.24574135, 0.23806727],\n",
       "        [0.64584298, 0.64483941]]),\n",
       " array([[0.48455902, 0.46813755],\n",
       "        [0.65837049, 0.63479452],\n",
       "        [0.24207849, 0.23384836],\n",
       "        [0.59261397, 0.62310071]]),\n",
       " array([[0.50067701, 0.49791016],\n",
       "        [0.66954733, 0.66844093],\n",
       "        [0.25001134, 0.24878474],\n",
       "        [0.64559222, 0.66480644]]),\n",
       " array([[0.46853039, 0.41730015],\n",
       "        [0.63972119, 0.59397906],\n",
       "        [0.23411897, 0.20843579],\n",
       "        [0.5854986 , 0.57025174]]),\n",
       " array([[0.49496573, 0.48833861],\n",
       "        [0.66004739, 0.66313238],\n",
       "        [0.24711023, 0.24384798],\n",
       "        [0.62734584, 0.63972688]]),\n",
       " array([[0.45811832, 0.46583941],\n",
       "        [0.64152526, 0.64314724],\n",
       "        [0.2286935 , 0.23225962],\n",
       "        [0.55949132, 0.61033832]]),\n",
       " array([[0.47906958, 0.47665521],\n",
       "        [0.65026451, 0.64796685],\n",
       "        [0.23935035, 0.23794563],\n",
       "        [0.62424764, 0.625448  ]]),\n",
       " array([[0.47735141, 0.47664374],\n",
       "        [0.64634456, 0.64477386],\n",
       "        [0.23850169, 0.23809763],\n",
       "        [0.6178785 , 0.63532171]]),\n",
       " array([[0.47816469, 0.4803626 ],\n",
       "        [0.64144204, 0.63959538],\n",
       "        [0.23882827, 0.23977381],\n",
       "        [0.62631466, 0.64199987]]),\n",
       " array([[0.41019432, 0.37813452],\n",
       "        [0.58535625, 0.54438499],\n",
       "        [0.20464428, 0.18887396],\n",
       "        [0.41444343, 0.49608601]]),\n",
       " array([[0.47119215, 0.47641737],\n",
       "        [0.65207513, 0.64443054],\n",
       "        [0.23535911, 0.23788311],\n",
       "        [0.591956  , 0.63278903]]),\n",
       " array([[0.44832934, 0.40998835],\n",
       "        [0.63642428, 0.59753134],\n",
       "        [0.22333001, 0.20472753],\n",
       "        [0.54297097, 0.46456044]]),\n",
       " array([[0.48364021, 0.46607628],\n",
       "        [0.64964906, 0.64176264],\n",
       "        [0.24153475, 0.23281755],\n",
       "        [0.62596444, 0.55965342]]),\n",
       " array([[0.50185022, 0.47566812],\n",
       "        [0.69344068, 0.67617046],\n",
       "        [0.25065863, 0.23709098],\n",
       "        [0.52392141, 0.51290318]]),\n",
       " array([[0.49325939, 0.47750843],\n",
       "        [0.67743418, 0.65274896],\n",
       "        [0.24638957, 0.23855512],\n",
       "        [0.57453088, 0.61346188]]),\n",
       " array([[0.40277054, 0.46117884],\n",
       "        [0.56994128, 0.62995797],\n",
       "        [0.2011824 , 0.2303838 ],\n",
       "        [0.56363356, 0.62695933]]),\n",
       " array([[0.46786186, 0.48840332],\n",
       "        [0.64217271, 0.6702591 ],\n",
       "        [0.23327186, 0.24297866],\n",
       "        [0.6134431 , 0.63840651]]),\n",
       " array([[0.48641203, 0.46320151],\n",
       "        [0.65846956, 0.62474178],\n",
       "        [0.24303569, 0.23136611],\n",
       "        [0.62887136, 0.63081469]]),\n",
       " array([[0.47889704, 0.48301849],\n",
       "        [0.64433661, 0.64117725],\n",
       "        [0.23921617, 0.24131476],\n",
       "        [0.62435853, 0.64354691]]),\n",
       " array([[0.49849766, 0.4615059 ],\n",
       "        [0.66606001, 0.63315306],\n",
       "        [0.2489673 , 0.23046566],\n",
       "        [0.65289745, 0.50776719]]),\n",
       " array([[0.48856136, 0.47033837],\n",
       "        [0.66440902, 0.64553314],\n",
       "        [0.24402755, 0.23491664],\n",
       "        [0.64068391, 0.55138072]]),\n",
       " array([[0.46828088, 0.44382804],\n",
       "        [0.63677773, 0.61202051],\n",
       "        [0.23389208, 0.22177713],\n",
       "        [0.61334922, 0.60720066]]),\n",
       " array([[0.48314698, 0.47635957],\n",
       "        [0.65471074, 0.64074491],\n",
       "        [0.24141951, 0.238017  ],\n",
       "        [0.63404743, 0.63608514]]),\n",
       " array([[0.48051782, 0.45061877],\n",
       "        [0.64367816, 0.61811067],\n",
       "        [0.23993818, 0.22512518],\n",
       "        [0.61186422, 0.60926253]]),\n",
       " array([[0.47567043, 0.47575067],\n",
       "        [0.63312606, 0.6420492 ],\n",
       "        [0.2375185 , 0.23755775],\n",
       "        [0.62955032, 0.62708819]]),\n",
       " array([[0.45179712, 0.41034555],\n",
       "        [0.62956347, 0.57600611],\n",
       "        [0.22556737, 0.20501494],\n",
       "        [0.54922573, 0.55354974]]),\n",
       " array([[0.48104547, 0.48797244],\n",
       "        [0.65305063, 0.65420693],\n",
       "        [0.24032461, 0.24373405],\n",
       "        [0.61318021, 0.62152521]]),\n",
       " array([[0.44823623, 0.43085385],\n",
       "        [0.61566061, 0.60088791],\n",
       "        [0.2238523 , 0.21522632],\n",
       "        [0.59048301, 0.5892402 ]]),\n",
       " array([[0.49135005, 0.486661  ],\n",
       "        [0.65560709, 0.65231429],\n",
       "        [0.24549405, 0.2431358 ],\n",
       "        [0.6388047 , 0.63907606]]),\n",
       " array([[0.49880859, 0.49378906],\n",
       "        [0.68588693, 0.67128671],\n",
       "        [0.2479765 , 0.24611017],\n",
       "        [0.6656068 , 0.66112288]]),\n",
       " array([[0.50121974, 0.47930024],\n",
       "        [0.68067984, 0.66077387],\n",
       "        [0.25004214, 0.23883362],\n",
       "        [0.59685663, 0.61201475]]),\n",
       " array([[0.41376766, 0.44486039],\n",
       "        [0.58780372, 0.61596838],\n",
       "        [0.20669427, 0.22230904],\n",
       "        [0.53099402, 0.59164615]]),\n",
       " array([[0.48729058, 0.49079332],\n",
       "        [0.65660604, 0.65907791],\n",
       "        [0.24331005, 0.24526527],\n",
       "        [0.53204696, 0.64194584]]),\n",
       " array([[0.48398509, 0.46209614],\n",
       "        [0.70600378, 0.63179045],\n",
       "        [0.23726222, 0.23072067],\n",
       "        [0.57222532, 0.58612358]]),\n",
       " array([[0.47714492, 0.46264259],\n",
       "        [0.66796757, 0.62261372],\n",
       "        [0.23742724, 0.23086319],\n",
       "        [0.55884257, 0.60074882]]),\n",
       " array([[0.45877093, 0.43586533],\n",
       "        [0.63178531, 0.60166634],\n",
       "        [0.22917187, 0.21765996],\n",
       "        [0.59635656, 0.5862407 ]]),\n",
       " array([[0.48045318, 0.49186403],\n",
       "        [0.64976756, 0.66087174],\n",
       "        [0.23996224, 0.24561251],\n",
       "        [0.63140028, 0.63391988]]),\n",
       " array([[0.47735141, 0.47664374],\n",
       "        [0.64634456, 0.64477386],\n",
       "        [0.23856972, 0.23814963],\n",
       "        [0.6178785 , 0.63532171]]),\n",
       " array([[0.48361727, 0.48296933],\n",
       "        [0.64928832, 0.64760143],\n",
       "        [0.24166347, 0.24131665],\n",
       "        [0.63238731, 0.64732768]]),\n",
       " array([[0.4096115 , 0.45550847],\n",
       "        [0.57050638, 0.62668161],\n",
       "        [0.20448754, 0.22757907],\n",
       "        [0.55947106, 0.6079391 ]]),\n",
       " array([[0.49244008, 0.47465113],\n",
       "        [0.65188576, 0.63500243],\n",
       "        [0.24595384, 0.23680297],\n",
       "        [0.64714897, 0.62986205]]),\n",
       " array([[0.37339524, 0.48259778],\n",
       "        [0.55415279, 0.67261748],\n",
       "        [0.18608536, 0.24091662],\n",
       "        [0.37825853, 0.56703051]]),\n",
       " array([[0.4857791 , 0.49372732],\n",
       "        [0.66244312, 0.69465206],\n",
       "        [0.24277265, 0.24513616],\n",
       "        [0.60627178, 0.54230725]]),\n",
       " array([[0.47546875, 0.45212274],\n",
       "        [0.65757273, 0.63783373],\n",
       "        [0.23728318, 0.22564338],\n",
       "        [0.64449857, 0.51147646]]),\n",
       " array([[0.48736328, 0.49289178],\n",
       "        [0.66174287, 0.67994675],\n",
       "        [0.24314012, 0.2456279 ],\n",
       "        [0.65533859, 0.58055752]]),\n",
       " array([[0.47302922, 0.45171157],\n",
       "        [0.64733859, 0.62328116],\n",
       "        [0.23597522, 0.22572291],\n",
       "        [0.61490599, 0.60682168]]),\n",
       " array([[0.47732638, 0.49409369],\n",
       "        [0.64538888, 0.66164286],\n",
       "        [0.2384516 , 0.24686343],\n",
       "        [0.62091257, 0.64298966]]),\n",
       " array([[0.47263672, 0.44998803],\n",
       "        [0.65592389, 0.6159076 ],\n",
       "        [0.23561635, 0.2248073 ],\n",
       "        [0.6418918 , 0.6116572 ]]),\n",
       " array([[0.4781041 , 0.46239041],\n",
       "        [0.66170666, 0.63333913],\n",
       "        [0.23849429, 0.23088968],\n",
       "        [0.44343781, 0.5979325 ]]),\n",
       " array([[0.47786346, 0.41968622],\n",
       "        [0.65789227, 0.59816546],\n",
       "        [0.23849784, 0.20968251],\n",
       "        [0.58307158, 0.50469473]]),\n",
       " array([[0.48946927, 0.48215594],\n",
       "        [0.65589354, 0.64707007],\n",
       "        [0.24455165, 0.24074849],\n",
       "        [0.64720259, 0.63278903]]),\n",
       " array([[0.4792039 , 0.48226751],\n",
       "        [0.65924037, 0.65228716],\n",
       "        [0.23943743, 0.24094613],\n",
       "        [0.59056061, 0.63903989]]),\n",
       " array([[0.48570247, 0.47039461],\n",
       "        [0.65407496, 0.63287436],\n",
       "        [0.24247642, 0.23498288],\n",
       "        [0.60712488, 0.63063159]]),\n",
       " array([[0.46208834, 0.48586403],\n",
       "        [0.63772181, 0.65625969],\n",
       "        [0.23065096, 0.24269646],\n",
       "        [0.56648888, 0.62306368]]),\n",
       " array([[0.48835756, 0.49805405],\n",
       "        [0.65077051, 0.66669561],\n",
       "        [0.24401154, 0.24875433],\n",
       "        [0.65616798, 0.62059675]]),\n",
       " array([[0.38731634, 0.49476562],\n",
       "        [0.55698838, 0.66999921],\n",
       "        [0.19356392, 0.24709884],\n",
       "        [0.51862568, 0.6619976 ]]),\n",
       " array([[0.49362749, 0.47921875],\n",
       "        [0.65853921, 0.66739201],\n",
       "        [0.24669876, 0.23806603],\n",
       "        [0.6468987 , 0.64793493]]),\n",
       " array([[0.43425751, 0.34992682],\n",
       "        [0.59522631, 0.50991412],\n",
       "        [0.21693023, 0.17473703],\n",
       "        [0.59429481, 0.51363709]]),\n",
       " array([[0.49662651, 0.49027393],\n",
       "        [0.65266269, 0.65232937],\n",
       "        [0.24804085, 0.24481526],\n",
       "        [0.65042965, 0.6463621 ]]),\n",
       " array([[0.43379043, 0.48693659],\n",
       "        [0.60974194, 0.65927715],\n",
       "        [0.21668591, 0.24337576],\n",
       "        [0.58181566, 0.63831598]]),\n",
       " array([[0.48734675, 0.47995067],\n",
       "        [0.65718146, 0.64670883],\n",
       "        [0.24344616, 0.23979497],\n",
       "        [0.65270249, 0.64064782]]),\n",
       " array([[0.38206864, 0.44909342],\n",
       "        [0.55754055, 0.61578165],\n",
       "        [0.19090884, 0.22439676],\n",
       "        [0.51905416, 0.61597308]]),\n",
       " array([[0.49926972, 0.48190454],\n",
       "        [0.65874418, 0.64322951],\n",
       "        [0.24936969, 0.24069371],\n",
       "        [0.64929035, 0.6482562 ]]),\n",
       " array([[0.46702944, 0.43951118],\n",
       "        [0.64925395, 0.60812304],\n",
       "        [0.23335977, 0.21962475],\n",
       "        [0.59726027, 0.59090972]]),\n",
       " array([[0.48938006, 0.49416016],\n",
       "        [0.66627513, 0.67300633],\n",
       "        [0.24452824, 0.24634473],\n",
       "        [0.63510343, 0.66145541]]),\n",
       " array([[0.49388361, 0.47091663],\n",
       "        [0.69141692, 0.6425883 ],\n",
       "        [0.24670497, 0.2351967 ],\n",
       "        [0.49703517, 0.5883845 ]]),\n",
       " array([[0.49013036, 0.49437638],\n",
       "        [0.66081725, 0.66349497],\n",
       "        [0.24486568, 0.24696129],\n",
       "        [0.6353399 , 0.6493438 ]]),\n",
       " array([[0.45995131, 0.46672003],\n",
       "        [0.62868746, 0.63323378],\n",
       "        [0.22980014, 0.23310818],\n",
       "        [0.60665106, 0.62590913]]),\n",
       " array([[0.4881864 , 0.49284121],\n",
       "        [0.65247373, 0.65555286],\n",
       "        [0.24392852, 0.24616125],\n",
       "        [0.63546719, 0.64374454]]),\n",
       " array([[0.4013783 , 0.48383816],\n",
       "        [0.56804017, 0.65808625],\n",
       "        [0.20054288, 0.24155424],\n",
       "        [0.55542702, 0.59887253]]),\n",
       " array([[0.47656282, 0.49441629],\n",
       "        [0.65690125, 0.66175781],\n",
       "        [0.23749081, 0.24707761],\n",
       "        [0.618382  , 0.63822544]]),\n",
       " array([[0.4618132 , 0.4825056 ],\n",
       "        [0.6317105 , 0.65710656],\n",
       "        [0.23070637, 0.24107437],\n",
       "        [0.60566449, 0.62509734]]),\n",
       " array([[0.47701928, 0.49075379],\n",
       "        [0.64676175, 0.66003067],\n",
       "        [0.23824938, 0.24521511],\n",
       "        [0.58428613, 0.63233251]]),\n",
       " array([[0.45973538, 0.44234928],\n",
       "        [0.6307833 , 0.62646617],\n",
       "        [0.22950754, 0.2209225 ],\n",
       "        [0.54790907, 0.57095009]]),\n",
       " array([[0.47413901, 0.48600325],\n",
       "        [0.64037234, 0.6701323 ],\n",
       "        [0.23690807, 0.24271484],\n",
       "        [0.61567371, 0.59201408]]),\n",
       " array([[0.46729988, 0.41320119],\n",
       "        [0.62841988, 0.57137375],\n",
       "        [0.23332255, 0.20639497],\n",
       "        [0.62406278, 0.57868584]]),\n",
       " array([[0.48797514, 0.48939683],\n",
       "        [0.64694396, 0.64776976],\n",
       "        [0.24370404, 0.244559  ],\n",
       "        [0.6416576 , 0.64909434]]),\n",
       " array([[0.35558499, 0.4108077 ],\n",
       "        [0.52150162, 0.58053766],\n",
       "        [0.17765913, 0.20525965],\n",
       "        [0.5025737 , 0.57641351]]),\n",
       " array([[0.49154467, 0.49225158],\n",
       "        [0.65540175, 0.65915991],\n",
       "        [0.24557101, 0.24578109],\n",
       "        [0.64266589, 0.65558575]]),\n",
       " array([[0.46629341, 0.43964215],\n",
       "        [0.64612295, 0.62523079],\n",
       "        [0.23275681, 0.21959856],\n",
       "        [0.48536394, 0.53347655]]),\n",
       " array([[0.4841628 , 0.48311332],\n",
       "        [0.66034297, 0.65630277],\n",
       "        [0.24187545, 0.24139136],\n",
       "        [0.60305854, 0.61141245]]),\n",
       " array([[0.45450642, 0.36048697],\n",
       "        [0.6241296 , 0.52890853],\n",
       "        [0.22707495, 0.18006707],\n",
       "        [0.60545561, 0.495843  ]]),\n",
       " array([[0.48096233, 0.48600743],\n",
       "        [0.64708743, 0.65094642],\n",
       "        [0.24024024, 0.2428303 ],\n",
       "        [0.63739188, 0.64457034]]),\n",
       " array([[0.38877641, 0.45619681],\n",
       "        [0.56250398, 0.6363472 ],\n",
       "        [0.19409392, 0.22789115],\n",
       "        [0.51305434, 0.58409037]]),\n",
       " array([[0.49195876, 0.47289411],\n",
       "        [0.6611616 , 0.65556761],\n",
       "        [0.24567078, 0.23629692],\n",
       "        [0.63575806, 0.60805263]]),\n",
       " array([[0.41053722, 0.36543043],\n",
       "        [0.57565743, 0.53206757],\n",
       "        [0.20510781, 0.18254746],\n",
       "        [0.56592676, 0.51583448]]),\n",
       " array([[0.47031816, 0.4816383 ],\n",
       "        [0.63226854, 0.64791741],\n",
       "        [0.23496101, 0.24064082],\n",
       "        [0.62653576, 0.63140028]]),\n",
       " array([[0.45220018, 0.4072133 ],\n",
       "        [0.61326146, 0.57975442],\n",
       "        [0.22589918, 0.20341867],\n",
       "        [0.61531804, 0.55644525]]),\n",
       " array([[0.48615522, 0.47837219],\n",
       "        [0.6503786 , 0.65083546],\n",
       "        [0.2428441 , 0.23898301],\n",
       "        [0.63608514, 0.61959262]]),\n",
       " array([[0.43851076, 0.4922956 ],\n",
       "        [0.60871814, 0.67488145],\n",
       "        [0.21900446, 0.2458389 ],\n",
       "        [0.56201991, 0.53685023]]),\n",
       " array([[0.49301721, 0.4978241 ],\n",
       "        [0.6579261 , 0.68687142],\n",
       "        [0.24634834, 0.24872694],\n",
       "        [0.64349301, 0.61769192]]),\n",
       " array([[0.42566568, 0.43957145],\n",
       "        [0.61658512, 0.62003932],\n",
       "        [0.2126922 , 0.21957903],\n",
       "        [0.50434529, 0.56554506]]),\n",
       " array([[0.4801822 , 0.47968179],\n",
       "        [0.66968748, 0.65711082],\n",
       "        [0.23993882, 0.23958971],\n",
       "        [0.60572144, 0.6172066 ]]),\n",
       " array([[0.47601692, 0.48074891],\n",
       "        [0.63641503, 0.63972196],\n",
       "        [0.23780581, 0.24003482],\n",
       "        [0.63172945, 0.64859515]]),\n",
       " array([[0.49418958, 0.49264071],\n",
       "        [0.65681843, 0.65711219],\n",
       "        [0.24683195, 0.24613449],\n",
       "        [0.64568179, 0.65798199]]),\n",
       " array([[0.48621802, 0.33619281],\n",
       "        [0.65860817, 0.51175976],\n",
       "        [0.24263175, 0.16792935],\n",
       "        [0.61272929, 0.42923103]]),\n",
       " array([[0.4834412 , 0.47163546],\n",
       "        [0.64501772, 0.65042615],\n",
       "        [0.24155646, 0.23558108],\n",
       "        [0.64196385, 0.57087032]]),\n",
       " array([[0.46873158, 0.48237025],\n",
       "        [0.6531644 , 0.66409291],\n",
       "        [0.23387677, 0.24035035],\n",
       "        [0.57524488, 0.58144238]]),\n",
       " array([[0.49256054, 0.49607754],\n",
       "        [0.66879884, 0.67013373],\n",
       "        [0.24606749, 0.24787018],\n",
       "        [0.62193333, 0.63653915]]),\n",
       " array([[0.42904317, 0.4111156 ],\n",
       "        [0.60252542, 0.58654595],\n",
       "        [0.21440213, 0.20544696],\n",
       "        [0.59278804, 0.56867295]]),\n",
       " array([[0.47781255, 0.4801671 ],\n",
       "        [0.64585932, 0.64895819],\n",
       "        [0.23873258, 0.24000337],\n",
       "        [0.63499427, 0.64079216]]),\n",
       " array([[0.45186249, 0.44591176],\n",
       "        [0.64044538, 0.63273145],\n",
       "        [0.22545964, 0.22239819],\n",
       "        [0.5516061 , 0.51219016]]),\n",
       " array([[0.48035493, 0.48579095],\n",
       "        [0.6458644 , 0.65615991],\n",
       "        [0.23979384, 0.24275745],\n",
       "        [0.61096039, 0.63644837]]),\n",
       " array([[0.49738281, 0.42571197],\n",
       "        [0.66271111, 0.60455894],\n",
       "        [0.24844311, 0.21272828],\n",
       "        [0.66433621, 0.56121173]]),\n",
       " array([[0.48864968, 0.48774141],\n",
       "        [0.66356281, 0.65007023],\n",
       "        [0.24396136, 0.24352193],\n",
       "        [0.6563972 , 0.61394984]]),\n",
       " array([[0.4577312 , 0.36712587],\n",
       "        [0.62995098, 0.53262259],\n",
       "        [0.2286393 , 0.18346391],\n",
       "        [0.60769304, 0.52736032]]),\n",
       " array([[0.5006055 , 0.48116761],\n",
       "        [0.67849563, 0.64224044],\n",
       "        [0.25002371, 0.2402139 ],\n",
       "        [0.63786315, 0.6292935 ]]),\n",
       " array([[0.45950387, 0.38219579],\n",
       "        [0.62626649, 0.56175095],\n",
       "        [0.22956609, 0.19079435],\n",
       "        [0.61868019, 0.48637143]]),\n",
       " array([[0.48116531, 0.4728476 ],\n",
       "        [0.65438359, 0.64141287],\n",
       "        [0.24041506, 0.23626191],\n",
       "        [0.62406278, 0.61873609]]),\n",
       " array([[0.42336632, 0.4852009 ],\n",
       "        [0.60112688, 0.66407664],\n",
       "        [0.21144578, 0.24232545],\n",
       "        [0.48587905, 0.5117577 ]]),\n",
       " array([[0.48393591, 0.48721182],\n",
       "        [0.64489988, 0.66191539],\n",
       "        [0.24175719, 0.24343427],\n",
       "        [0.62581693, 0.59417902]]),\n",
       " array([[0.41152958, 0.39341997],\n",
       "        [0.58528652, 0.56610338],\n",
       "        [0.2055653 , 0.1965915 ],\n",
       "        [0.54654876, 0.52500576]]),\n",
       " array([[0.48367744, 0.4844571 ],\n",
       "        [0.66258573, 0.65900968],\n",
       "        [0.24164253, 0.24208502],\n",
       "        [0.62697774, 0.64111683]]),\n",
       " array([[0.43091726, 0.44120085],\n",
       "        [0.59728132, 0.6055565 ],\n",
       "        [0.21531663, 0.22023927],\n",
       "        [0.58004576, 0.58748879]]),\n",
       " array([[0.50077295, 0.47421664],\n",
       "        [0.66385539, 0.64153562],\n",
       "        [0.25017773, 0.23697111],\n",
       "        [0.66086024, 0.63063159]]),\n",
       " array([[0.49105172, 0.46794544],\n",
       "        [0.67207985, 0.63967546],\n",
       "        [0.24508861, 0.23378969],\n",
       "        [0.6546496 , 0.63484869]]),\n",
       " array([[0.49302625, 0.48532231],\n",
       "        [0.67000265, 0.65017791],\n",
       "        [0.24634214, 0.24239458],\n",
       "        [0.66036971, 0.6437625 ]]),\n",
       " array([[0.44458954, 0.34349857],\n",
       "        [0.60885954, 0.50167665],\n",
       "        [0.22212993, 0.17155173],\n",
       "        [0.60347767, 0.50954821]]),\n",
       " array([[0.49579611, 0.4954152 ],\n",
       "        [0.6665293 , 0.65476533],\n",
       "        [0.24739754, 0.24742425],\n",
       "        [0.61329289, 0.65738373]]),\n",
       " array([[0.45272015, 0.46237012],\n",
       "        [0.62248697, 0.62229361],\n",
       "        [0.22617542, 0.23092624],\n",
       "        [0.5960294 , 0.62089399]]),\n",
       " array([[0.47447675, 0.48833422],\n",
       "        [0.64909005, 0.65052072],\n",
       "        [0.23702131, 0.24396673],\n",
       "        [0.59916004, 0.63804432]]),\n",
       " array([[0.46546484, 0.47807672],\n",
       "        [0.62564705, 0.64486642],\n",
       "        [0.23234119, 0.23881886],\n",
       "        [0.6079391 , 0.6329168 ]]),\n",
       " array([[0.47302354, 0.48083911],\n",
       "        [0.63262396, 0.64897924],\n",
       "        [0.23636339, 0.24019443],\n",
       "        [0.62944027, 0.61548654]]),\n",
       " array([[0.47063515, 0.40792747],\n",
       "        [0.63801181, 0.575227  ],\n",
       "        [0.23521435, 0.20379798],\n",
       "        [0.61875472, 0.5685529 ]]),\n",
       " array([[0.48452255, 0.48706205],\n",
       "        [0.66194695, 0.65669121],\n",
       "        [0.24169604, 0.24333972],\n",
       "        [0.6514072 , 0.65411913]]),\n",
       " array([[0.33118854, 0.36501558],\n",
       "        [0.49508484, 0.53914899],\n",
       "        [0.16550817, 0.18234112],\n",
       "        [0.4844897 , 0.4799905 ]]),\n",
       " array([[0.48833211, 0.49130277],\n",
       "        [0.6542702 , 0.66967152],\n",
       "        [0.24396135, 0.24530415],\n",
       "        [0.63362822, 0.59518191]]),\n",
       " array([[0.47556546, 0.39349513],\n",
       "        [0.65226867, 0.56433299],\n",
       "        [0.23733512, 0.19657117],\n",
       "        [0.62076397, 0.55736042]]),\n",
       " array([[0.48029673, 0.48794202],\n",
       "        [0.65570028, 0.64987698],\n",
       "        [0.23960622, 0.24362058],\n",
       "        [0.60873346, 0.63896753]]),\n",
       " array([[0.48471432, 0.44602733],\n",
       "        [0.68998988, 0.63227025],\n",
       "        [0.24215079, 0.22277996],\n",
       "        [0.45314884, 0.4625548 ]]),\n",
       " array([[0.49669447, 0.48074103],\n",
       "        [0.68882872, 0.65339042],\n",
       "        [0.24815621, 0.24018298],\n",
       "        [0.60848768, 0.64304361]]),\n",
       " array([[0.4654153 , 0.50993581],\n",
       "        [0.63289919, 0.98092654],\n",
       "        [0.23247888, 0.01050979],\n",
       "        [0.61966705, 0.655162  ]]),\n",
       " array([[0.48329567, 0.48986513],\n",
       "        [0.65364256, 0.65533255],\n",
       "        [0.2413066 , 0.24481062],\n",
       "        [0.63750067, 0.6482562 ]]),\n",
       " array([[0.42485824, 0.45248761],\n",
       "        [0.59263254, 0.6280055 ],\n",
       "        [0.21230823, 0.22613892],\n",
       "        [0.59009487, 0.61673961]]),\n",
       " array([[0.48839412, 0.48447988],\n",
       "        [0.65422402, 0.65394542],\n",
       "        [0.24380325, 0.24200161],\n",
       "        [0.64261191, 0.63499427]]),\n",
       " array([[0.43890384, 0.45067586],\n",
       "        [0.61658689, 0.61698237],\n",
       "        [0.21930128, 0.22522   ],\n",
       "        [0.57913944, 0.61256012]]),\n",
       " array([[0.4748245 , 0.49187059],\n",
       "        [0.64967698, 0.66304166],\n",
       "        [0.23726035, 0.24567859],\n",
       "        [0.61477483, 0.6351762 ]]),\n",
       " array([[0.44294344, 0.48841616],\n",
       "        [0.6058231 , 0.67540992],\n",
       "        [0.22116456, 0.24275786],\n",
       "        [0.58974536, 0.65622088]]),\n",
       " array([[0.47800398, 0.48807936],\n",
       "        [0.64097076, 0.65248629],\n",
       "        [0.23859483, 0.24388273],\n",
       "        [0.62100543, 0.64113486]]),\n",
       " array([[0.4884375 , 0.42806609],\n",
       "        [0.66737831, 0.60435566],\n",
       "        [0.24392779, 0.21385065],\n",
       "        [0.65630905, 0.54379977]]),\n",
       " array([[0.48349609, 0.48982339],\n",
       "        [0.66454592, 0.65258105],\n",
       "        [0.24158558, 0.24477044],\n",
       "        [0.65183332, 0.65156703]]),\n",
       " array([[0.35773878, 0.44745484],\n",
       "        [0.51531836, 0.61559314],\n",
       "        [0.17870392, 0.22346049],\n",
       "        [0.50748444, 0.59726027]]),\n",
       " array([[0.48479025, 0.48292577],\n",
       "        [0.64330087, 0.63914637],\n",
       "        [0.24221058, 0.24119108],\n",
       "        [0.63309929, 0.64566388]]),\n",
       " array([[0.47069695, 0.41087523],\n",
       "        [0.63386981, 0.57756194],\n",
       "        [0.23509091, 0.20532477],\n",
       "        [0.61849383, 0.57212578]]),\n",
       " array([[0.48526503, 0.48744048],\n",
       "        [0.6427903 , 0.65207697],\n",
       "        [0.24232644, 0.24359152],\n",
       "        [0.63903989, 0.64848813]]),\n",
       " array([[0.40432646, 0.4011167 ],\n",
       "        [0.56953981, 0.57417406],\n",
       "        [0.2017868 , 0.20033952],\n",
       "        [0.56329096, 0.53760247]]),\n",
       " array([[0.48493784, 0.49714478],\n",
       "        [0.66438993, 0.66775704],\n",
       "        [0.24176105, 0.24832482],\n",
       "        [0.61731862, 0.63247863]]),\n",
       " array([[0.49340406, 0.47459358],\n",
       "        [0.66635828, 0.64455956],\n",
       "        [0.24617457, 0.23713159],\n",
       "        [0.65984374, 0.61567371]]),\n",
       " array([[0.48060547, 0.48172427],\n",
       "        [0.65123726, 0.65743893],\n",
       "        [0.23999763, 0.24059206],\n",
       "        [0.64920126, 0.5977405 ]]),\n",
       " array([[0.41115838, 0.45284095],\n",
       "        [0.58080166, 0.61572415],\n",
       "        [0.20540132, 0.22612122],\n",
       "        [0.56389543, 0.62024361]]),\n",
       " array([[0.48295843, 0.48883186],\n",
       "        [0.65439874, 0.65370693],\n",
       "        [0.24132127, 0.24400301],\n",
       "        [0.6383703 , 0.64514422]]),\n",
       " array([[0.47677843, 0.42502568],\n",
       "        [0.6422884 , 0.59121438],\n",
       "        [0.2381883 , 0.21225078],\n",
       "        [0.61372467, 0.57552235]]),\n",
       " array([[0.47134597, 0.48547618],\n",
       "        [0.64053383, 0.64982705],\n",
       "        [0.2354114 , 0.24258473],\n",
       "        [0.60441028, 0.64131516]]),\n",
       " array([[0.39246324, 0.46257039],\n",
       "        [0.56401789, 0.6290927 ],\n",
       "        [0.19608473, 0.23101295],\n",
       "        [0.53689204, 0.61992749]]),\n",
       " array([[0.49066937, 0.47740046],\n",
       "        [0.65651631, 0.64270681],\n",
       "        [0.24513146, 0.23849157],\n",
       "        [0.64172967, 0.64053954]]),\n",
       " array([[0.47646484, 0.48757424],\n",
       "        [0.65361841, 0.66384699],\n",
       "        [0.23807426, 0.24362606],\n",
       "        [0.64541306, 0.65539156]]),\n",
       " array([[0.50146484, 0.48831544],\n",
       "        [0.70002999, 0.66200397],\n",
       "        [0.24933584, 0.24389904],\n",
       "        [0.66796748, 0.65009162]]),\n",
       " array([[0.44239672, 0.42103981],\n",
       "        [0.62303304, 0.59936186],\n",
       "        [0.22095511, 0.21019572],\n",
       "        [0.55928865, 0.50471657]]),\n",
       " array([[0.48692584, 0.48780787],\n",
       "        [0.66525699, 0.65637108],\n",
       "        [0.24302606, 0.2436725 ],\n",
       "        [0.61048918, 0.63623046]]),\n",
       " array([[0.40339677, 0.44482981],\n",
       "        [0.56820868, 0.61541037],\n",
       "        [0.20155931, 0.22228127],\n",
       "        [0.55599741, 0.6022386 ]]),\n",
       " array([[0.48451051, 0.49027306],\n",
       "        [0.65830679, 0.66023989],\n",
       "        [0.24182171, 0.24501185],\n",
       "        [0.65272022, 0.65794682]]),\n",
       " array([[0.48603329, 0.43895452],\n",
       "        [0.65835906, 0.61658193],\n",
       "        [0.24279732, 0.21933498],\n",
       "        [0.62450635, 0.55707582]]),\n",
       " array([[0.49987088, 0.48142484],\n",
       "        [0.67229335, 0.64892126],\n",
       "        [0.2494311 , 0.24042799],\n",
       "        [0.62382239, 0.63121733]]),\n",
       " array([[0.44305281, 0.41567659],\n",
       "        [0.61743757, 0.58478597],\n",
       "        [0.22135043, 0.20766824],\n",
       "        [0.59979216, 0.58567443]]),\n",
       " array([[0.47550503, 0.48513556],\n",
       "        [0.64394296, 0.6610156 ],\n",
       "        [0.23758482, 0.24210034],\n",
       "        [0.62469109, 0.65328722]]),\n",
       " array([[0.4549883 , 0.38724647],\n",
       "        [0.63778897, 0.56538983],\n",
       "        [0.22730702, 0.19348977],\n",
       "        [0.49232174, 0.50088571]]),\n",
       " array([[0.48981718, 0.48537507],\n",
       "        [0.65638265, 0.65060857],\n",
       "        [0.24472788, 0.24253321],\n",
       "        [0.62070823, 0.64120699]]),\n",
       " array([[0.45678742, 0.46006525],\n",
       "        [0.64499903, 0.63076371],\n",
       "        [0.22790735, 0.22988951],\n",
       "        [0.49123324, 0.61705719]]),\n",
       " array([[0.49271643, 0.47809382],\n",
       "        [0.68162299, 0.64556171],\n",
       "        [0.24606046, 0.23885688],\n",
       "        [0.56500231, 0.63406566]]),\n",
       " array([[0.48425781, 0.46656265],\n",
       "        [0.65460978, 0.6443105 ],\n",
       "        [0.24191834, 0.23303581],\n",
       "        [0.6525252 , 0.63143686]]),\n",
       " array([[0.48589844, 0.48836436],\n",
       "        [0.65844427, 0.66923036],\n",
       "        [0.24270393, 0.24400285],\n",
       "        [0.65401299, 0.65569165]]),\n",
       " array([[0.43440563, 0.42604574],\n",
       "        [0.60224418, 0.59894746],\n",
       "        [0.21685758, 0.21286051],\n",
       "        [0.58354198, 0.58055752]]),\n",
       " array([[0.49037996, 0.49318026],\n",
       "        [0.65491421, 0.65627601],\n",
       "        [0.24489612, 0.24636506],\n",
       "        [0.64397802, 0.64627262]]),\n",
       " array([[0.45186249, 0.44591176],\n",
       "        [0.64044538, 0.63273145],\n",
       "        [0.2255889 , 0.2226024 ],\n",
       "        [0.5516061 , 0.51219016]]),\n",
       " array([[0.48674704, 0.48830277],\n",
       "        [0.66393591, 0.66026407],\n",
       "        [0.2431529 , 0.24395669],\n",
       "        [0.60038544, 0.63381052]]),\n",
       " array([[0.39396174, 0.4790104 ],\n",
       "        [0.56448988, 0.64725915],\n",
       "        [0.19681682, 0.23928774],\n",
       "        [0.55711649, 0.63388343]]),\n",
       " array([[0.48969842, 0.48570247],\n",
       "        [0.65781968, 0.64691533],\n",
       "        [0.24479528, 0.24265259],\n",
       "        [0.65456122, 0.65019838]]),\n",
       " array([[0.45178638, 0.40492611],\n",
       "        [0.62222605, 0.5782963 ],\n",
       "        [0.22574835, 0.20232417],\n",
       "        [0.59483492, 0.55628243]]),\n",
       " array([[0.48335472, 0.49295888],\n",
       "        [0.64739853, 0.65734004],\n",
       "        [0.24150587, 0.24630567],\n",
       "        [0.64014236, 0.64861298]]),\n",
       " array([[0.48097656, 0.48945312],\n",
       "        [0.65643076, 0.66378831],\n",
       "        [0.24024083, 0.24403448],\n",
       "        [0.64953974, 0.65722528]]),\n",
       " array([[0.49700404, 0.49312423],\n",
       "        [0.65898697, 0.67186397],\n",
       "        [0.2479721 , 0.2461249 ],\n",
       "        [0.61795311, 0.58051817]]),\n",
       " array([[0.4943105 , 0.49083984],\n",
       "        [0.67906447, 0.67514709],\n",
       "        [0.24701557, 0.24524533],\n",
       "        [0.61389355, 0.65847428]]),\n",
       " array([[0.49327003, 0.50158203],\n",
       "        [0.69050925, 0.68925629],\n",
       "        [0.24640341, 0.25064554],\n",
       "        [0.58918189, 0.66807144]]),\n",
       " array([[0.4475816 , 0.47792969],\n",
       "        [0.61123553, 0.64977827],\n",
       "        [0.22346031, 0.23881392],\n",
       "        [0.61346188, 0.64675565]]),\n",
       " array([[0.47633521, 0.49240234],\n",
       "        [0.63806049, 0.66470681],\n",
       "        [0.23802424, 0.24605912],\n",
       "        [0.64071999, 0.65987881]]),\n",
       " array([[0.33118854, 0.36501558],\n",
       "        [0.49508484, 0.53914899],\n",
       "        [0.1655053 , 0.18238446],\n",
       "        [0.4844897 , 0.4799905 ]]),\n",
       " array([[0.47517137, 0.47715859],\n",
       "        [0.63813958, 0.64074396],\n",
       "        [0.23738327, 0.23834089],\n",
       "        [0.63550356, 0.63035686]]),\n",
       " array([[0.46463956, 0.46467129],\n",
       "        [0.62914316, 0.63063802],\n",
       "        [0.23222522, 0.23216692],\n",
       "        [0.60901694, 0.6212468 ]]),\n",
       " array([[0.48490186, 0.49215533],\n",
       "        [0.64467925, 0.65736208],\n",
       "        [0.24220462, 0.24587517],\n",
       "        [0.62224853, 0.63653915]]),\n",
       " array([[0.45999123, 0.46577954],\n",
       "        [0.63513841, 0.63190796],\n",
       "        [0.22980308, 0.23277581],\n",
       "        [0.58114755, 0.62830199]]),\n",
       " array([[0.49484396, 0.4949881 ],\n",
       "        [0.67532868, 0.66422867],\n",
       "        [0.24702616, 0.24705877],\n",
       "        [0.59868079, 0.63289855]]),\n",
       " array([[0.37245849, 0.47448855],\n",
       "        [0.53998826, 0.63784683],\n",
       "        [0.18609353, 0.23707483],\n",
       "        [0.5285665 , 0.62695933]]),\n",
       " array([[0.49065952, 0.48241196],\n",
       "        [0.65632724, 0.64656885],\n",
       "        [0.24510203, 0.24105141],\n",
       "        [0.64126108, 0.63381052]]),\n",
       " array([[0.46988281, 0.48582031],\n",
       "        [0.66067996, 0.67299784],\n",
       "        [0.23477378, 0.24208621],\n",
       "        [0.63934731, 0.65394221]]),\n",
       " array([[0.48404297, 0.487748  ],\n",
       "        [0.66155037, 0.65436517],\n",
       "        [0.24129118, 0.24355698],\n",
       "        [0.65233013, 0.65053636]]),\n",
       " array([[0.48571884, 0.45977605],\n",
       "        [0.66480656, 0.62990009],\n",
       "        [0.24105094, 0.22967121],\n",
       "        [0.58807308, 0.60594922]]),\n",
       " array([[0.48366271, 0.47393723],\n",
       "        [0.65479737, 0.6462755 ],\n",
       "        [0.24163556, 0.23668077],\n",
       "        [0.62548491, 0.60080618]]),\n",
       " array([[0.45179712, 0.41034555],\n",
       "        [0.62956347, 0.57600611],\n",
       "        [0.22568684, 0.20494327],\n",
       "        [0.54922573, 0.55354974]]),\n",
       " array([[0.49778348, 0.48588121],\n",
       "        [0.67550025, 0.64700162],\n",
       "        [0.2481612 , 0.24275981],\n",
       "        [0.58826773, 0.63742815]]),\n",
       " array([[0.46378193, 0.40517385],\n",
       "        [0.63847096, 0.58034755],\n",
       "        [0.23174197, 0.20250612],\n",
       "        [0.59912171, 0.55033481]]),\n",
       " array([[0.48754106, 0.46574258],\n",
       "        [0.6631325 , 0.63567115],\n",
       "        [0.24359191, 0.23267286],\n",
       "        [0.60615795, 0.61899688]]),\n",
       " array([[0.4877664 , 0.39971976],\n",
       "        [0.6775471 , 0.57664806],\n",
       "        [0.24324343, 0.19958915],\n",
       "        [0.51117347, 0.54334405]]),\n",
       " array([[0.4871468 , 0.48737271],\n",
       "        [0.66845426, 0.66341382],\n",
       "        [0.24337444, 0.24352764],\n",
       "        [0.62566938, 0.63702915]]),\n",
       " array([[0.41633514, 0.3875011 ],\n",
       "        [0.57918716, 0.55810137],\n",
       "        [0.20789485, 0.19344974],\n",
       "        [0.57621557, 0.51344289]]),\n",
       " array([[0.4941419 , 0.49218559],\n",
       "        [0.65564403, 0.66384871],\n",
       "        [0.24685023, 0.24591451],\n",
       "        [0.6420719 , 0.6416576 ]]),\n",
       " array([[0.49327861, 0.47038896],\n",
       "        [0.66336924, 0.64173952],\n",
       "        [0.24652659, 0.23502757],\n",
       "        [0.65403068, 0.62087542]]),\n",
       " array([[0.47581111, 0.48479361],\n",
       "        [0.64206539, 0.65863409],\n",
       "        [0.23769372, 0.24219064],\n",
       "        [0.62094971, 0.63028357]]),\n",
       " array([[0.48759766, 0.48898438],\n",
       "        [0.66607081, 0.66246825],\n",
       "        [0.24335547, 0.24435657],\n",
       "        [0.65555045, 0.65680256]]),\n",
       " array([[0.48739531, 0.47304543],\n",
       "        [0.65344543, 0.64353972],\n",
       "        [0.24355398, 0.23625135],\n",
       "        [0.62723543, 0.61550526]]),\n",
       " array([[0.47344699, 0.47006221],\n",
       "        [0.66767998, 0.64911727],\n",
       "        [0.23632281, 0.23483257],\n",
       "        [0.54809437, 0.57288197]]),\n",
       " array([[0.48800304, 0.49534817],\n",
       "        [0.66972815, 0.67347531],\n",
       "        [0.24362748, 0.24724115],\n",
       "        [0.59731792, 0.57917887]]),\n",
       " array([[0.43325558, 0.41485984],\n",
       "        [0.60250329, 0.60646366],\n",
       "        [0.21646402, 0.20715499],\n",
       "        [0.55546778, 0.34611968]]),\n",
       " array([[0.48760546, 0.50355991],\n",
       "        [0.66153347, 0.70007346],\n",
       "        [0.24332748, 0.25139941],\n",
       "        [0.60914919, 0.52249444]]),\n",
       " array([[0.43980204, 0.46152621],\n",
       "        [0.61054173, 0.63129237],\n",
       "        [0.21965685, 0.23055966],\n",
       "        [0.59502772, 0.62343389]]),\n",
       " array([[0.48764212, 0.48182326],\n",
       "        [0.65459371, 0.64737702],\n",
       "        [0.24360339, 0.24065192],\n",
       "        [0.63240558, 0.64145937]]),\n",
       " array([[0.46812612, 0.45111772],\n",
       "        [0.64079207, 0.62037685],\n",
       "        [0.23391664, 0.22537343],\n",
       "        [0.62130249, 0.60410589]]),\n",
       " array([[0.4771583 , 0.47054298],\n",
       "        [0.64066064, 0.63716863],\n",
       "        [0.23832498, 0.23501542],\n",
       "        [0.62572472, 0.62443244]]),\n",
       " array([[0.40418808, 0.46177249],\n",
       "        [0.56990484, 0.62804632],\n",
       "        [0.20191394, 0.23077939],\n",
       "        [0.55821354, 0.62686727]]),\n",
       " array([[0.48509442, 0.47788628],\n",
       "        [0.64975111, 0.64861978],\n",
       "        [0.24241117, 0.23875854],\n",
       "        [0.64097255, 0.63256994]]),\n",
       " array([[0.48904297, 0.49423828],\n",
       "        [0.67700419, 0.66419066],\n",
       "        [0.24363114, 0.246899  ],\n",
       "        [0.65685542, 0.66152539]]),\n",
       " array([[0.49622334, 0.48478104],\n",
       "        [0.6708343 , 0.64285145],\n",
       "        [0.24780539, 0.24199049],\n",
       "        [0.62226707, 0.64149542]]),\n",
       " array([[0.35814737, 0.35946398],\n",
       "        [0.53016011, 0.5296359 ],\n",
       "        [0.17888495, 0.17936226],\n",
       "        [0.4453992 , 0.42366959]]),\n",
       " array([[0.48616479, 0.48910093],\n",
       "        [0.65323316, 0.66114423],\n",
       "        [0.24285297, 0.24435922],\n",
       "        [0.63191225, 0.62117254]]),\n",
       " array([[0.43256825, 0.42013043],\n",
       "        [0.61064068, 0.59193237],\n",
       "        [0.21610978, 0.20985609],\n",
       "        [0.54359266, 0.5480532 ]]),\n",
       " array([[0.47975806, 0.47255047],\n",
       "        [0.6641376 , 0.65692723],\n",
       "        [0.23961526, 0.23545162],\n",
       "        [0.60036631, 0.59483492]]),\n",
       " array([[0.41379095, 0.49708618],\n",
       "        [0.58957838, 0.66740802],\n",
       "        [0.20657779, 0.24830399],\n",
       "        [0.55890342, 0.65452586]]),\n",
       " array([[0.49124518, 0.47087379],\n",
       "        [0.65683479, 0.64851958],\n",
       "        [0.24536672, 0.23522012],\n",
       "        [0.64162156, 0.62154376]]),\n",
       " array([[0.42392236, 0.46657181],\n",
       "        [0.59900705, 0.63448069],\n",
       "        [0.21178021, 0.2328373 ],\n",
       "        [0.55748236, 0.62515272]]),\n",
       " array([[0.47581491, 0.46751311],\n",
       "        [0.64043114, 0.63158319],\n",
       "        [0.23775693, 0.23345367],\n",
       "        [0.63081469, 0.62971537]]),\n",
       " array([[0.42393606, 0.46373533],\n",
       "        [0.59878559, 0.63426169],\n",
       "        [0.21163186, 0.23175282],\n",
       "        [0.55416243, 0.59583688]]),\n",
       " array([[0.49777542, 0.49991494],\n",
       "        [0.67063424, 0.66995327],\n",
       "        [0.24861606, 0.24979817],\n",
       "        [0.62909164, 0.62936689]]),\n",
       " array([[0.45704831, 0.37433061],\n",
       "        [0.6398878 , 0.54413782],\n",
       "        [0.22831111, 0.18696062],\n",
       "        [0.56789226, 0.49976559]]),\n",
       " array([[0.49487577, 0.49592153],\n",
       "        [0.66432556, 0.664695  ],\n",
       "        [0.24703797, 0.24775666],\n",
       "        [0.61920173, 0.63304455]]),\n",
       " array([[0.41115838, 0.45284095],\n",
       "        [0.58080166, 0.61572415],\n",
       "        [0.20539162, 0.22621583],\n",
       "        [0.56389543, 0.62024361]]),\n",
       " array([[0.49198087, 0.49488068],\n",
       "        [0.654939  , 0.65650186],\n",
       "        [0.24582174, 0.24729705],\n",
       "        [0.64691658, 0.65341118]]),\n",
       " array([[0.4632247 , 0.49050341],\n",
       "        [0.65564447, 0.65222055],\n",
       "        [0.2314499 , 0.24496612],\n",
       "        [0.49223294, 0.58719647]]),\n",
       " array([[0.45380636, 0.48199797],\n",
       "        [0.64132503, 0.66102927],\n",
       "        [0.22664713, 0.24067245],\n",
       "        [0.50274886, 0.5774419 ]]),\n",
       " array([[0.48145938, 0.4389852 ],\n",
       "        [0.65478364, 0.61623924],\n",
       "        [0.24048133, 0.21931071],\n",
       "        [0.6123157 , 0.60359193]]),\n",
       " array([[0.49479654, 0.48731382],\n",
       "        [0.65989861, 0.65939647],\n",
       "        [0.24725747, 0.24337362],\n",
       "        [0.64448063, 0.64329531]]),\n",
       " array([[0.45683883, 0.48289463],\n",
       "        [0.62730183, 0.64437039],\n",
       "        [0.22828627, 0.24116544],\n",
       "        [0.61856838, 0.64483941]]),\n",
       " array([[0.49544619, 0.48725479],\n",
       "        [0.67901822, 0.65382898],\n",
       "        [0.24467681, 0.24335973],\n",
       "        [0.64302563, 0.65418989]]),\n",
       " array([[0.45043744, 0.43422769],\n",
       "        [0.62449211, 0.61091815],\n",
       "        [0.22492731, 0.21686707],\n",
       "        [0.57980944, 0.53387549]]),\n",
       " array([[0.47568043, 0.48808072],\n",
       "        [0.64858932, 0.66248181],\n",
       "        [0.23771185, 0.24384297],\n",
       "        [0.60416297, 0.62398882]]),\n",
       " array([[0.46723739, 0.44617535],\n",
       "        [0.6390677 , 0.61127918],\n",
       "        [0.23308944, 0.22287898],\n",
       "        [0.62054101, 0.6015705 ]]),\n",
       " array([[0.48897884, 0.49181689],\n",
       "        [0.65419158, 0.66092329],\n",
       "        [0.24434653, 0.24567795],\n",
       "        [0.64553848, 0.6433672 ]]),\n",
       " array([[0.48603516, 0.43986354],\n",
       "        [0.67120701, 0.61410234],\n",
       "        [0.24192602, 0.21977383],\n",
       "        [0.65413682, 0.58457966]]),\n",
       " array([[0.49171875, 0.47681142],\n",
       "        [0.65811005, 0.64054861],\n",
       "        [0.24549056, 0.23814058],\n",
       "        [0.65926469, 0.63074146]]),\n",
       " array([[0.48340223, 0.42255679],\n",
       "        [0.65523724, 0.6164695 ],\n",
       "        [0.2412417 , 0.21067362],\n",
       "        [0.62646207, 0.47614512]]),\n",
       " array([[0.48644926, 0.47998184],\n",
       "        [0.65353217, 0.6655376 ],\n",
       "        [0.24291244, 0.23984946],\n",
       "        [0.63858753, 0.60496165]]),\n",
       " array([[0.4139911 , 0.4241694 ],\n",
       "        [0.58116249, 0.59013961],\n",
       "        [0.20680129, 0.21185248],\n",
       "        [0.57850827, 0.59096788]]),\n",
       " array([[0.4917313 , 0.49081641],\n",
       "        [0.66138647, 0.66573381],\n",
       "        [0.24536922, 0.24481521],\n",
       "        [0.63768193, 0.64306159]]),\n",
       " array([[0.42586772, 0.46048561],\n",
       "        [0.60761075, 0.63879255],\n",
       "        [0.21260705, 0.22975073],\n",
       "        [0.54066611, 0.59597165]]),\n",
       " array([[0.4842628 , 0.48408687],\n",
       "        [0.65118094, 0.65119504],\n",
       "        [0.24191156, 0.24186605],\n",
       "        [0.61105459, 0.63722868]]),\n",
       " array([[0.47347508, 0.434969  ],\n",
       "        [0.64940863, 0.60733033],\n",
       "        [0.23644628, 0.21725862],\n",
       "        [0.60873346, 0.55744171]]),\n",
       " array([[0.47902011, 0.48055437],\n",
       "        [0.65272263, 0.65055998],\n",
       "        [0.23929638, 0.24002383],\n",
       "        [0.61983449, 0.61129947]]),\n",
       " array([[0.43774553, 0.41569697],\n",
       "        [0.60947703, 0.58878691],\n",
       "        [0.21871375, 0.20772928],\n",
       "        [0.59802848, 0.57619577]]),\n",
       " array([[0.4929924 , 0.473488  ],\n",
       "        [0.65765979, 0.65975906],\n",
       "        [0.24633381, 0.23590384],\n",
       "        [0.65696111, 0.63608514]]),\n",
       " array([[0.47073077, 0.42501995],\n",
       "        [0.64518572, 0.59806839],\n",
       "        [0.23520683, 0.2123326 ],\n",
       "        [0.60387751, 0.58762517]]),\n",
       " array([[0.48741674, 0.488249  ],\n",
       "        [0.65720294, 0.65592995],\n",
       "        [0.24343558, 0.24393209],\n",
       "        [0.62226707, 0.65124733]]),\n",
       " array([[0.43396104, 0.42308922],\n",
       "        [0.61166788, 0.59065796],\n",
       "        [0.21649298, 0.21137767],\n",
       "        [0.56464025, 0.58500995]]),\n",
       " array([[0.49765342, 0.49048582],\n",
       "        [0.66756603, 0.65408009],\n",
       "        [0.2486656 , 0.24494605],\n",
       "        [0.60619589, 0.63404743]]),\n",
       " array([[0.48742177, 0.47917941],\n",
       "        [0.65577018, 0.64611747],\n",
       "        [0.24353555, 0.23912867],\n",
       "        [0.63524896, 0.6291467 ]]),\n",
       " array([[0.49368894, 0.49337891],\n",
       "        [0.65832052, 0.66213205],\n",
       "        [0.24568317, 0.24655842],\n",
       "        [0.66086024, 0.66075516]]),\n",
       " array([[0.44958386, 0.47009974],\n",
       "        [0.64189262, 0.6118871 ],\n",
       "        [0.2246447 , 0.23476641],\n",
       "        [0.51650103, 0.5839729 ]]),\n",
       " array([[0.49939913, 0.48680646],\n",
       "        [0.68175977, 0.62466934],\n",
       "        [0.24946715, 0.24319338],\n",
       "        [0.65500302, 0.65254293]]),\n",
       " array([[0.45665655, 0.40448277],\n",
       "        [0.630285  , 0.57634299],\n",
       "        [0.22810103, 0.2020953 ],\n",
       "        [0.57710586, 0.54510322]]),\n",
       " array([[0.48434141, 0.48246819],\n",
       "        [0.65423594, 0.65042886],\n",
       "        [0.2418197 , 0.2411126 ],\n",
       "        [0.61961123, 0.63624862]]),\n",
       " array([[0.4869938 , 0.45191115],\n",
       "        [0.65154385, 0.62105003],\n",
       "        [0.24328099, 0.22576336],\n",
       "        [0.63335469, 0.61212762]]),\n",
       " array([[0.47709639, 0.48778589],\n",
       "        [0.64311083, 0.6562928 ],\n",
       "        [0.23831531, 0.2436521 ],\n",
       "        [0.61946235, 0.64623683]]),\n",
       " array([[0.44494976, 0.39124632],\n",
       "        [0.6086261 , 0.57251574],\n",
       "        [0.22230199, 0.19546822],\n",
       "        [0.57274273, 0.49857775]]),\n",
       " array([[0.48526859, 0.4954247 ],\n",
       "        [0.64813098, 0.66523507],\n",
       "        [0.24241221, 0.24749946],\n",
       "        [0.60807155, 0.62714341]]),\n",
       " array([[0.437256  , 0.47039647],\n",
       "        [0.60508834, 0.62556549],\n",
       "        [0.21846312, 0.23475549],\n",
       "        [0.60017498, 0.62422915]]),\n",
       " array([[0.49735476, 0.48854825],\n",
       "        [0.68083822, 0.65305092],\n",
       "        [0.24838978, 0.24395275],\n",
       "        [0.56795234, 0.64859515]]),\n",
       " array([[0.47302922, 0.45171157],\n",
       "        [0.64733859, 0.62328116],\n",
       "        [0.23636301, 0.22565522],\n",
       "        [0.61490599, 0.60682168]]),\n",
       " array([[0.49396484, 0.49113267],\n",
       "        [0.67372599, 0.65918623],\n",
       "        [0.24674641, 0.24540343],\n",
       "        [0.66128041, 0.64198186]]),\n",
       " array([[0.44657957, 0.39851456],\n",
       "        [0.62477819, 0.56653339],\n",
       "        [0.22317068, 0.19901212],\n",
       "        [0.58416868, 0.56423774]]),\n",
       " array([[0.48857329, 0.48217247],\n",
       "        [0.66145474, 0.64325221],\n",
       "        [0.24411139, 0.24086492],\n",
       "        [0.63728308, 0.6459146 ]]),\n",
       " array([[0.46382026, 0.43742601],\n",
       "        [0.64181189, 0.61166455],\n",
       "        [0.23172204, 0.21843165],\n",
       "        [0.58446226, 0.57564124]]),\n",
       " array([[0.49130153, 0.49254905],\n",
       "        [0.66985238, 0.66995102],\n",
       "        [0.24516377, 0.24591344],\n",
       "        [0.58586975, 0.63463026]]),\n",
       " array([[0.47843522, 0.49047416],\n",
       "        [0.64608876, 0.68106056],\n",
       "        [0.23897319, 0.24506188],\n",
       "        [0.60926253, 0.6192762 ]]),\n",
       " array([[0.50048362, 0.48365799],\n",
       "        [0.67525804, 0.68451243],\n",
       "        [0.2500569 , 0.24168297],\n",
       "        [0.61559885, 0.6048286 ]]),\n",
       " array([[0.43702319, 0.48909757],\n",
       "        [0.61649   , 0.6577606 ],\n",
       "        [0.21791602, 0.24422346],\n",
       "        [0.50510949, 0.61936928]]),\n",
       " array([[0.48812599, 0.48793922],\n",
       "        [0.66731722, 0.68878304],\n",
       "        [0.24382199, 0.24258563],\n",
       "        [0.59226571, 0.60894136]]),\n",
       " array([[0.34651899, 0.44260437],\n",
       "        [0.51545802, 0.60987837],\n",
       "        [0.1731584 , 0.22115752],\n",
       "        [0.4808474 , 0.60610103]]),\n",
       " array([[0.4956721 , 0.48970451],\n",
       "        [0.66162603, 0.65885914],\n",
       "        [0.24737405, 0.24432387],\n",
       "        [0.62662786, 0.64124305]]),\n",
       " array([[0.4890237 , 0.42450623],\n",
       "        [0.66806723, 0.60912675],\n",
       "        [0.24422862, 0.21192021],\n",
       "        [0.5057857 , 0.46715766]]),\n",
       " array([[0.48609327, 0.47373438],\n",
       "        [0.6593872 , 0.6494091 ],\n",
       "        [0.24285249, 0.23668101],\n",
       "        [0.60015584, 0.60803371]]),\n",
       " array([[0.45249571, 0.47539066],\n",
       "        [0.6183645 , 0.63744416],\n",
       "        [0.22604063, 0.23750238],\n",
       "        [0.60406783, 0.63764568]]),\n",
       " array([[0.48401157, 0.49457192],\n",
       "        [0.6491299 , 0.65861731],\n",
       "        [0.24186056, 0.24697043],\n",
       "        [0.64005206, 0.65394221]]),\n",
       " array([[0.4601268 , 0.4546593 ],\n",
       "        [0.63665931, 0.62953662],\n",
       "        [0.22980585, 0.22694193],\n",
       "        [0.58830666, 0.58285588]]),\n",
       " array([[0.47426309, 0.48203795],\n",
       "        [0.63912469, 0.64827568],\n",
       "        [0.23692867, 0.24084605],\n",
       "        [0.63313578, 0.64347504]]),\n",
       " array([[0.41842459, 0.44272307],\n",
       "        [0.59873769, 0.62009664],\n",
       "        [0.20901014, 0.22110676],\n",
       "        [0.50848445, 0.57502679]]),\n",
       " array([[0.49441567, 0.48945802],\n",
       "        [0.66789359, 0.65578265],\n",
       "        [0.24687775, 0.24461001],\n",
       "        [0.52719088, 0.63246037]]),\n",
       " array([[0.39617995, 0.46041499],\n",
       "        [0.56928338, 0.62523937],\n",
       "        [0.19793873, 0.23002196],\n",
       "        [0.54431729, 0.61724394]]),\n",
       " array([[0.48591434, 0.48145822],\n",
       "        [0.65047825, 0.63921548],\n",
       "        [0.24265207, 0.24033787],\n",
       "        [0.63346412, 0.63391988]]),\n",
       " array([[0.4420306 , 0.38485553],\n",
       "        [0.6123849 , 0.55367984],\n",
       "        [0.22071313, 0.19224908],\n",
       "        [0.55811203, 0.51755338]]),\n",
       " array([[0.48390959, 0.48300053],\n",
       "        [0.6479298 , 0.64053609],\n",
       "        [0.24183263, 0.24117311],\n",
       "        [0.6355581 , 0.63381052]]),\n",
       " array([[0.453834  , 0.431936  ],\n",
       "        [0.66243974, 0.61871839],\n",
       "        [0.22643752, 0.2154845 ],\n",
       "        [0.39604022, 0.3175881 ]]),\n",
       " array([[0.51112675, 0.47683717],\n",
       "        [0.69145645, 0.66119491],\n",
       "        [0.2554413 , 0.2381576 ],\n",
       "        [0.6244694 , 0.5885207 ]]),\n",
       " array([[0.34651899, 0.44260437],\n",
       "        [0.51545802, 0.60987837],\n",
       "        [0.17315467, 0.22116864],\n",
       "        [0.4808474 , 0.60610103]]),\n",
       " array([[0.4937065 , 0.46862279],\n",
       "        [0.66420881, 0.63695628],\n",
       "        [0.24666471, 0.23413207],\n",
       "        [0.63267949, 0.62465415]]),\n",
       " array([[0.39085669, 0.46952142],\n",
       "        [0.55708539, 0.63378389],\n",
       "        [0.19526272, 0.23452402],\n",
       "        [0.55497855, 0.63074146]]),\n",
       " array([[0.47324286, 0.48501911],\n",
       "        [0.64450636, 0.65351117],\n",
       "        [0.23640244, 0.24237577],\n",
       "        [0.6266647 , 0.63577624]]),\n",
       " array([[0.4656615 , 0.41983712],\n",
       "        [0.63329859, 0.58573811],\n",
       "        [0.23263293, 0.20982419],\n",
       "        [0.61028174, 0.57627496]]),\n",
       " array([[0.49497851, 0.48881642],\n",
       "        [0.65892136, 0.65180065],\n",
       "        [0.24732579, 0.24415208],\n",
       "        [0.64984244, 0.62633309]]),\n",
       " array([[0.49333906, 0.49519602],\n",
       "        [0.65801678, 0.66662817],\n",
       "        [0.24613816, 0.24728749],\n",
       "        [0.66066757, 0.62161798]]),\n",
       " array([[0.48277344, 0.4832834 ],\n",
       "        [0.65797109, 0.64638316],\n",
       "        [0.24118411, 0.24149234],\n",
       "        [0.65117627, 0.64187379]]),\n",
       " array([[0.4168238 , 0.42403958],\n",
       "        [0.58654441, 0.59213888],\n",
       "        [0.20828026, 0.21184497],\n",
       "        [0.55967368, 0.56979245]]),\n",
       " array([[0.49167159, 0.49711562],\n",
       "        [0.65910119, 0.65875523],\n",
       "        [0.24548947, 0.24832518],\n",
       "        [0.62585381, 0.64372657]]),\n",
       " array([[0.4678942 , 0.47289144],\n",
       "        [0.63513588, 0.64256238],\n",
       "        [0.23362081, 0.23623015],\n",
       "        [0.61989029, 0.62367441]]),\n",
       " array([[0.48556701, 0.48372196],\n",
       "        [0.65078198, 0.64680656],\n",
       "        [0.24243179, 0.24167935],\n",
       "        [0.60370618, 0.63795374]]),\n",
       " array([[0.47935331, 0.46944868],\n",
       "        [0.65124968, 0.63477438],\n",
       "        [0.23950537, 0.23441518],\n",
       "        [0.62009487, 0.61627231]]),\n",
       " array([[0.49208323, 0.48708031],\n",
       "        [0.65854944, 0.65357861],\n",
       "        [0.24582259, 0.24341735],\n",
       "        [0.63364646, 0.63925691]]),\n",
       " array([[0.47408666, 0.45436487],\n",
       "        [0.6374411 , 0.64571726],\n",
       "        [0.23686876, 0.22691505],\n",
       "        [0.60718172, 0.50694039]]),\n",
       " array([[0.48914278, 0.50851769],\n",
       "        [0.6573766 , 0.69153629],\n",
       "        [0.24366485, 0.25402679],\n",
       "        [0.59214958, 0.59641428]]),\n",
       " array([[0.39191369, 0.43358513],\n",
       "        [0.56969075, 0.62290082],\n",
       "        [0.19503177, 0.21596682],\n",
       "        [0.37100905, 0.46997475]]),\n",
       " array([[0.47745004, 0.48492951],\n",
       "        [0.66157537, 0.66206758],\n",
       "        [0.23856699, 0.24210763],\n",
       "        [0.59701043, 0.55703516]]),\n",
       " array([[0.46833963, 0.47024636],\n",
       "        [0.63840797, 0.63072339],\n",
       "        [0.23393815, 0.23488755],\n",
       "        [0.61668355, 0.63297155]]),\n",
       " array([[0.49721946, 0.489185  ],\n",
       "        [0.67369546, 0.6553402 ],\n",
       "        [0.24816828, 0.24437794],\n",
       "        [0.63760943, 0.63766381]]),\n",
       " array([[0.39486997, 0.47910238],\n",
       "        [0.56565747, 0.64674222],\n",
       "        [0.19726245, 0.23932666],\n",
       "        [0.53900041, 0.63670252]]),\n",
       " array([[0.49511091, 0.48449075],\n",
       "        [0.68119959, 0.65324217],\n",
       "        [0.24706743, 0.24203487],\n",
       "        [0.59868079, 0.64657679]]),\n",
       " array([[0.42566568, 0.43957145],\n",
       "        [0.61658512, 0.62003932],\n",
       "        [0.21184822, 0.21948614],\n",
       "        [0.50434529, 0.56554506]]),\n",
       " array([[0.48795181, 0.46658355],\n",
       "        [0.65385267, 0.63551584],\n",
       "        [0.24374823, 0.23315454],\n",
       "        [0.62302665, 0.6167583 ]]),\n",
       " array([[0.48095573, 0.4648553 ],\n",
       "        [0.66434397, 0.64264425],\n",
       "        [0.24025878, 0.23221308],\n",
       "        [0.64904087, 0.54502053]]),\n",
       " array([[0.49048531, 0.48081269],\n",
       "        [0.67347158, 0.65650744],\n",
       "        [0.24504772, 0.24023582],\n",
       "        [0.65801717, 0.6115819 ]]),\n",
       " array([[0.4438091 , 0.4439517 ],\n",
       "        [0.62208112, 0.6179264 ],\n",
       "        [0.22148475, 0.22176477],\n",
       "        [0.51871139, 0.5662681 ]]),\n",
       " array([[0.49135072, 0.49040971],\n",
       "        [0.66584165, 0.6610638 ],\n",
       "        [0.24548914, 0.24503973],\n",
       "        [0.62743784, 0.63240558]]),\n",
       " array([[0.47131946, 0.42406992],\n",
       "        [0.64953542, 0.59898477],\n",
       "        [0.23527869, 0.21162136],\n",
       "        [0.51800394, 0.44709665]]),\n",
       " array([[0.4894038 , 0.49452977],\n",
       "        [0.66005918, 0.65931858],\n",
       "        [0.2445492 , 0.24704929],\n",
       "        [0.61949957, 0.63751879]]),\n",
       " array([[0.41643426, 0.45117577],\n",
       "        [0.58479964, 0.62207297],\n",
       "        [0.20809049, 0.22535499],\n",
       "        [0.57393533, 0.56935286]]),\n",
       " array([[0.48728591, 0.49075391],\n",
       "        [0.65440457, 0.66111743],\n",
       "        [0.24351889, 0.24498055],\n",
       "        [0.63954616, 0.60262009]]),\n",
       " array([[0.42058875, 0.46655147],\n",
       "        [0.59793879, 0.63912916],\n",
       "        [0.2094851 , 0.23302926],\n",
       "        [0.54313681, 0.59862326]]),\n",
       " array([[0.50379147, 0.4790967 ],\n",
       "        [0.6688095 , 0.64743702],\n",
       "        [0.25166425, 0.23926946],\n",
       "        [0.64632631, 0.60581636]]),\n",
       " array([[0.37584253, 0.46769531],\n",
       "        [0.54835596, 0.65090108],\n",
       "        [0.18779771, 0.23368335],\n",
       "        [0.52402779, 0.63731935]]),\n",
       " array([[0.47853546, 0.48304025],\n",
       "        [0.64735454, 0.66349973],\n",
       "        [0.23899929, 0.24135856],\n",
       "        [0.63037518, 0.65124733]]),\n",
       " array([[0.47901433, 0.46047105],\n",
       "        [0.65404704, 0.62926803],\n",
       "        [0.23911797, 0.22993298],\n",
       "        [0.6137059 , 0.62846734]]),\n",
       " array([[0.48702679, 0.48442886],\n",
       "        [0.65193118, 0.64847929],\n",
       "        [0.2432802 , 0.24202738],\n",
       "        [0.64351098, 0.65144272]]),\n",
       " array([[0.41261765, 0.33682167],\n",
       "        [0.62456681, 0.50517051],\n",
       "        [0.20610663, 0.16820881],\n",
       "        [0.22493413, 0.45538879]]),\n",
       " array([[0.49114404, 0.48824219],\n",
       "        [0.6702684 , 0.66484043],\n",
       "        [0.24499264, 0.24370673],\n",
       "        [0.65833366, 0.65613271]]),\n",
       " array([[0.48551842, 0.47949416],\n",
       "        [0.65578704, 0.64964503],\n",
       "        [0.24263134, 0.23946045],\n",
       "        [0.61366836, 0.62445092]]),\n",
       " array([[0.48307077, 0.47492758],\n",
       "        [0.64400583, 0.64103976],\n",
       "        [0.24138111, 0.23727752],\n",
       "        [0.62784247, 0.62513426]]),\n",
       " array([[0.50277344, 0.49230469],\n",
       "        [0.68650825, 0.67937038],\n",
       "        [0.25001908, 0.24485484],\n",
       "        [0.66912739, 0.65979112]]),\n",
       " array([[0.4782449 , 0.48464641],\n",
       "        [0.64508492, 0.64739299],\n",
       "        [0.23882878, 0.24203739],\n",
       "        [0.62797117, 0.64324138]]),\n",
       " array([[0.471, 0.471],\n",
       "        [0.651, 0.651],\n",
       "        [0.235, 0.235],\n",
       "        [0.642, 0.642]]),\n",
       " array([[0.471, 0.471],\n",
       "        [0.651, 0.651],\n",
       "        [0.235, 0.235],\n",
       "        [0.642, 0.642]]),\n",
       " array([[0.4410851 , 0.49416016],\n",
       "        [0.61873934, 0.66530805],\n",
       "        [0.22014191, 0.24687513],\n",
       "        [0.5535293 , 0.66145541]]),\n",
       " array([[0.47821737, 0.48580101],\n",
       "        [0.64796927, 0.65420279],\n",
       "        [0.23894839, 0.24272884],\n",
       "        [0.6188665 , 0.63552174]]),\n",
       " array([[0.47614015, 0.43053815],\n",
       "        [0.64219731, 0.59548708],\n",
       "        [0.23777066, 0.21487179],\n",
       "        [0.62786086, 0.58752776]]),\n",
       " array([[0.46797755, 0.47971539],\n",
       "        [0.63328845, 0.6507399 ],\n",
       "        [0.23382943, 0.23967991],\n",
       "        [0.62944027, 0.64561014]]),\n",
       " array([[0.45577495, 0.45200087],\n",
       "        [0.63004813, 0.6362972 ],\n",
       "        [0.2273949 , 0.22571628],\n",
       "        [0.59083215, 0.57967155]]),\n",
       " array([[0.48933596, 0.48788899],\n",
       "        [0.65983629, 0.65935572],\n",
       "        [0.24448824, 0.24382812],\n",
       "        [0.63577624, 0.63920266]]),\n",
       " array([[0.45813922, 0.456917  ],\n",
       "        [0.64593051, 0.62919174],\n",
       "        [0.22822853, 0.22783753],\n",
       "        [0.41904556, 0.57793578]]),\n",
       " array([[0.49590218, 0.48412921],\n",
       "        [0.67439141, 0.6464568 ],\n",
       "        [0.24777479, 0.24193372],\n",
       "        [0.61048918, 0.64062977]]),\n",
       " array([[0.35407498, 0.44343593],\n",
       "        [0.51709465, 0.61209032],\n",
       "        [0.17692723, 0.22155355],\n",
       "        [0.50680976, 0.5913943 ]]),\n",
       " array([[0.49387121, 0.48864515],\n",
       "        [0.65908518, 0.64836915],\n",
       "        [0.24664793, 0.24402608],\n",
       "        [0.62973371, 0.63853323]]),\n",
       " array([[0.41172487, 0.4311325 ],\n",
       "        [0.58137513, 0.59516803],\n",
       "        [0.20578418, 0.21539599],\n",
       "        [0.56310952, 0.58631877]]),\n",
       " array([[0.495368  , 0.47938292],\n",
       "        [0.67862678, 0.64285519],\n",
       "        [0.24666287, 0.23943539],\n",
       "        [0.6237484 , 0.62846734]]),\n",
       " array([[0.47979042, 0.45670598],\n",
       "        [0.65748914, 0.62991757],\n",
       "        [0.23967335, 0.22821614],\n",
       "        [0.64474973, 0.6171319 ]]),\n",
       " array([[0.48160156, 0.49029279],\n",
       "        [0.65930481, 0.66964573],\n",
       "        [0.24056225, 0.24473591],\n",
       "        [0.65010941, 0.65530328]]),\n",
       " array([[0.46262762, 0.47361466],\n",
       "        [0.63094863, 0.65360746],\n",
       "        [0.23106512, 0.23642838],\n",
       "        [0.60151321, 0.60532266]]),\n",
       " array([[0.49234375, 0.49611328],\n",
       "        [0.67847338, 0.68141213],\n",
       "        [0.24481992, 0.24676173],\n",
       "        [0.6598262 , 0.66320283]]),\n",
       " array([[0.461735  , 0.48349337],\n",
       "        [0.62426221, 0.6633418 ],\n",
       "        [0.23070523, 0.24128004],\n",
       "        [0.61903413, 0.58436442]]),\n",
       " array([[0.48374653, 0.48653164],\n",
       "        [0.6436419 , 0.65624141],\n",
       "        [0.24170662, 0.24306911],\n",
       "        [0.63970881, 0.63608514]]),\n",
       " array([[0.34965599, 0.39090774],\n",
       "        [0.51949773, 0.57099011],\n",
       "        [0.17469561, 0.19525802],\n",
       "        [0.4866846 , 0.47193828]]),\n",
       " array([[0.4956629 , 0.50160322],\n",
       "        [0.65434012, 0.68066828],\n",
       "        [0.24749542, 0.25059707],\n",
       "        [0.6546496 , 0.64557431]]),\n",
       " array([[0.44811653, 0.49138672],\n",
       "        [0.62595279, 0.65938933],\n",
       "        [0.22394548, 0.2455428 ],\n",
       "        [0.56915295, 0.6589662 ]]),\n",
       " array([[0.48688714, 0.48625   ],\n",
       "        [0.65897567, 0.65193254],\n",
       "        [0.24323889, 0.24293672],\n",
       "        [0.59864243, 0.65433137]]),\n",
       " array([[0.47478509, 0.48281322],\n",
       "        [0.64163017, 0.65854005],\n",
       "        [0.2369582 , 0.24124621],\n",
       "        [0.57474912, 0.62321179]]),\n",
       " array([[0.49361101, 0.47994852],\n",
       "        [0.6578308 , 0.64770234],\n",
       "        [0.24649009, 0.23974815],\n",
       "        [0.64019653, 0.58627973]]),\n",
       " array([[0.40956274, 0.41522086],\n",
       "        [0.58329484, 0.59260499],\n",
       "        [0.2044097 , 0.20734558],\n",
       "        [0.54004192, 0.51400377]]),\n",
       " array([[0.49428095, 0.47996765],\n",
       "        [0.65551027, 0.64983014],\n",
       "        [0.24697715, 0.23978197],\n",
       "        [0.64268388, 0.6226377 ]]),\n",
       " array([[0.43830474, 0.46761382],\n",
       "        [0.61058584, 0.63692385],\n",
       "        [0.21898581, 0.23364836],\n",
       "        [0.56349251, 0.61700116]]),\n",
       " array([[0.48589215, 0.49464793],\n",
       "        [0.66045083, 0.66430818],\n",
       "        [0.24265172, 0.24696588],\n",
       "        [0.59529754, 0.63211328]]),\n",
       " array([[0.39486997, 0.47910238],\n",
       "        [0.56565747, 0.64674222],\n",
       "        [0.19722805, 0.23931647],\n",
       "        [0.53900041, 0.63670252]]),\n",
       " array([[0.48369141, 0.48755941],\n",
       "        [0.65818849, 0.65210192],\n",
       "        [0.24148227, 0.24361596],\n",
       "        [0.65201079, 0.64578925]]),\n",
       " array([[0.48502393, 0.35636686],\n",
       "        [0.64533251, 0.52919626],\n",
       "        [0.24218508, 0.17803659],\n",
       "        [0.61439996, 0.48670696]]),\n",
       " array([[0.48371925, 0.4886119 ],\n",
       "        [0.66063432, 0.66479144],\n",
       "        [0.24117145, 0.24386221],\n",
       "        [0.58937624, 0.61428745]]),\n",
       " array([[0.47979042, 0.45670598],\n",
       "        [0.65748914, 0.62991757],\n",
       "        [0.23975942, 0.22808656],\n",
       "        [0.64474973, 0.6171319 ]]),\n",
       " array([[0.4925723 , 0.47345946],\n",
       "        [0.66576835, 0.6445049 ],\n",
       "        [0.24601531, 0.23653366],\n",
       "        [0.61022516, 0.62315625]]),\n",
       " array([[0.46874257, 0.45312135],\n",
       "        [0.63802252, 0.6290676 ],\n",
       "        [0.23405522, 0.22567983],\n",
       "        [0.55611957, 0.46485968]]),\n",
       " array([[0.49730909, 0.49579065],\n",
       "        [0.67111772, 0.68744982],\n",
       "        [0.24839044, 0.24761098],\n",
       "        [0.62865102, 0.60606308]]),\n",
       " array([[0.44948691, 0.4775847 ],\n",
       "        [0.61331814, 0.63946481],\n",
       "        [0.22445385, 0.23865108],\n",
       "        [0.61250373, 0.63967267]]),\n",
       " array([[0.48841379, 0.48191001],\n",
       "        [0.65306284, 0.64232265],\n",
       "        [0.24406676, 0.24059448],\n",
       "        [0.65240107, 0.63697472]]),\n",
       " array([[0.4684869 , 0.40989771],\n",
       "        [0.64592588, 0.58616857],\n",
       "        [0.23382256, 0.20465078],\n",
       "        [0.56020022, 0.48408586]]),\n",
       " array([[0.4910018 , 0.49011341],\n",
       "        [0.65726003, 0.6635274 ],\n",
       "        [0.24504842, 0.24462211],\n",
       "        [0.61841928, 0.62458026]]),\n",
       " array([[0.42322553, 0.38489779],\n",
       "        [0.60237705, 0.55882353],\n",
       "        [0.21103816, 0.19200779],\n",
       "        [0.41933841, 0.44313016]]),\n",
       " array([[0.48846633, 0.4747085 ],\n",
       "        [0.66414386, 0.64948242],\n",
       "        [0.24389486, 0.23722559],\n",
       "        [0.59990703, 0.60391558]]),\n",
       " array([[0.45646867, 0.48930976],\n",
       "        [0.62673784, 0.67120793],\n",
       "        [0.22792279, 0.24450692],\n",
       "        [0.56574598, 0.57341878]]),\n",
       " array([[0.49785418, 0.4886858 ],\n",
       "        [0.67514314, 0.65290997],\n",
       "        [0.24842681, 0.2441195 ],\n",
       "        [0.58320881, 0.64711322]]),\n",
       " array([[0.49023114, 0.42778663],\n",
       "        [0.67019731, 0.62335131],\n",
       "        [0.24446886, 0.2136627 ],\n",
       "        [0.5390421 , 0.45384952]]),\n",
       " array([[0.4799039 , 0.4537189 ],\n",
       "        [0.65990247, 0.64760697],\n",
       "        [0.23929863, 0.22538749],\n",
       "        [0.39460688, 0.41176288]]),\n",
       " array([[0.50097609, 0.49120662],\n",
       "        [0.6841053 , 0.66352402],\n",
       "        [0.24914432, 0.24545032],\n",
       "        [0.61214643, 0.65383604]]),\n",
       " array([[0.48474012, 0.48164807],\n",
       "        [0.65485185, 0.65698162],\n",
       "        [0.24210556, 0.24061825],\n",
       "        [0.62579849, 0.61438121]]),\n",
       " array([[0.41176114, 0.4128753 ],\n",
       "        [0.57625343, 0.57725719],\n",
       "        [0.20569767, 0.20619445],\n",
       "        [0.56893299, 0.57381616]]),\n",
       " array([[0.48144678, 0.49277503],\n",
       "        [0.65210402, 0.66040764],\n",
       "        [0.23992831, 0.24599352],\n",
       "        [0.62219292, 0.65067861]]),\n",
       " array([[0.46577285, 0.48636439],\n",
       "        [0.63637164, 0.66193906],\n",
       "        [0.23275274, 0.24300188],\n",
       "        [0.59491204, 0.62863265]]),\n",
       " array([[0.47658566, 0.48869213],\n",
       "        [0.6470453 , 0.65684953],\n",
       "        [0.23807493, 0.24417424],\n",
       "        [0.61080964, 0.61815826]]),\n",
       " array([[0.39712218, 0.46724811],\n",
       "        [0.58007677, 0.63957145],\n",
       "        [0.19830346, 0.23340882],\n",
       "        [0.52949624, 0.61962983]]),\n",
       " array([[0.48596775, 0.49260647],\n",
       "        [0.65563044, 0.66429406],\n",
       "        [0.24273144, 0.24609626],\n",
       "        [0.62819173, 0.64643367]]),\n",
       " array([[0.38407697, 0.45956183],\n",
       "        [0.57954905, 0.62193097],\n",
       "        [0.1916251 , 0.22952281],\n",
       "        [0.44497426, 0.58863743]]),\n",
       " array([[0.47591174, 0.49448672],\n",
       "        [0.6520806 , 0.66000489],\n",
       "        [0.23776477, 0.24707461],\n",
       "        [0.59862326, 0.64381639]]),\n",
       " array([[0.3990471 , 0.43815244],\n",
       "        [0.57611778, 0.62011739],\n",
       "        [0.1991487 , 0.21874761],\n",
       "        [0.54330261, 0.52839733]]),\n",
       " array([[0.48728591, 0.49075391],\n",
       "        [0.65440457, 0.66111743],\n",
       "        [0.24338191, 0.24522076],\n",
       "        [0.63954616, 0.60262009]]),\n",
       " array([[0.48501712, 0.47560091],\n",
       "        [0.67183598, 0.64944908],\n",
       "        [0.24217922, 0.23746353],\n",
       "        [0.56971255, 0.60642352]]),\n",
       " array([[0.49005522, 0.48936777],\n",
       "        [0.66402619, 0.66195178],\n",
       "        [0.24477282, 0.24450697],\n",
       "        [0.61466239, 0.60723855]]),\n",
       " array([[0.4139911 , 0.4241694 ],\n",
       "        [0.58116249, 0.59013961],\n",
       "        [0.20686671, 0.21199698],\n",
       "        [0.57850827, 0.59096788]]),\n",
       " array([[0.49548064, 0.49143219],\n",
       "        [0.66503634, 0.65836073],\n",
       "        [0.2474005 , 0.24534511],\n",
       "        [0.64440885, 0.6532695 ]]),\n",
       " array([[0.47174632, 0.46182332],\n",
       "        [0.64956027, 0.63623548],\n",
       "        [0.23495637, 0.23053956],\n",
       "        [0.39387665, 0.54039569]]),\n",
       " array([[0.48245185, 0.48157383],\n",
       "        [0.6661753 , 0.63837162],\n",
       "        [0.24107504, 0.2405153 ],\n",
       "        [0.59518191, 0.63388343]]),\n",
       " array([[0.43687799, 0.44816912],\n",
       "        [0.60913466, 0.64186542],\n",
       "        [0.21818338, 0.22388304],\n",
       "        [0.5744515 , 0.53456788]]),\n",
       " array([[0.4968895 , 0.47890606],\n",
       "        [0.67923033, 0.66427381],\n",
       "        [0.24796888, 0.23921673],\n",
       "        [0.53818701, 0.55213856]]),\n",
       " array([[0.31282163, 0.3722013 ],\n",
       "        [0.47544243, 0.53943199],\n",
       "        [0.15621441, 0.18596518],\n",
       "        [0.43773838, 0.52843963]]),\n",
       " array([[0.48609375, 0.47017587],\n",
       "        [0.6598791 , 0.63740489],\n",
       "        [0.24284651, 0.23491577],\n",
       "        [0.65418989, 0.6237669 ]]),\n",
       " array([[0.3546016 , 0.42063559],\n",
       "        [0.53089796, 0.59456576],\n",
       "        [0.17719212, 0.21010606],\n",
       "        [0.4830978 , 0.56312968]]),\n",
       " array([[0.49555785, 0.49041593],\n",
       "        [0.66018001, 0.65769252],\n",
       "        [0.24751771, 0.24488672],\n",
       "        [0.6380262 , 0.63455743]]),\n",
       " array([[0.37316824, 0.35719027],\n",
       "        [0.5474389 , 0.52802852],\n",
       "        [0.18644083, 0.17838622],\n",
       "        [0.52519695, 0.47947138]]),\n",
       " array([[0.48649979, 0.49203138],\n",
       "        [0.65784297, 0.65371773],\n",
       "        [0.24302411, 0.24563544],\n",
       "        [0.61507459, 0.63970881]]),\n",
       " array([[0.40941859, 0.48958984],\n",
       "        [0.58876212, 0.65697812],\n",
       "        [0.20455045, 0.24449523],\n",
       "        [0.5453719 , 0.65734853]]),\n",
       " array([[0.49015798, 0.48162109],\n",
       "        [0.66830646, 0.65655786],\n",
       "        [0.24469154, 0.24049734],\n",
       "        [0.61789715, 0.65012721]]),\n",
       " array([[0.39396174, 0.4790104 ],\n",
       "        [0.56448988, 0.64725915],\n",
       "        [0.19685842, 0.23936282],\n",
       "        [0.55711649, 0.63388343]]),\n",
       " array([[0.471, 0.471],\n",
       "        [0.651, 0.651],\n",
       "        [0.235, 0.235],\n",
       "        [0.642, 0.642]]),\n",
       " array([[0.41920936, 0.41738104],\n",
       "        [0.60458634, 0.59197404],\n",
       "        [0.20928841, 0.20839889],\n",
       "        [0.48222094, 0.50582931]]),\n",
       " array([[0.49386126, 0.48740448],\n",
       "        [0.66474784, 0.66399748],\n",
       "        [0.24677711, 0.24353982],\n",
       "        [0.64073804, 0.62398882]]),\n",
       " array([[0.48093229, 0.42357393],\n",
       "        [0.64368908, 0.59601224],\n",
       "        [0.24023976, 0.21160356],\n",
       "        [0.63300805, 0.58258125]]),\n",
       " array([[0.48810154, 0.48445648],\n",
       "        [0.6569321 , 0.64985203],\n",
       "        [0.24378621, 0.24189905],\n",
       "        [0.63751879, 0.6410988 ]]),\n",
       " array([[0.38044888, 0.46318497],\n",
       "        [0.55836614, 0.63760202],\n",
       "        [0.18990805, 0.23134024],\n",
       "        [0.4989519 , 0.58661146]]),\n",
       " array([[0.49444078, 0.48035685],\n",
       "        [0.67122062, 0.65389805],\n",
       "        [0.24708527, 0.23999642],\n",
       "        [0.61062115, 0.63366469]]),\n",
       " array([[0.471, 0.471],\n",
       "        [0.651, 0.651],\n",
       "        [0.235, 0.235],\n",
       "        [0.642, 0.642]]),\n",
       " array([[0.471, 0.471],\n",
       "        [0.651, 0.651],\n",
       "        [0.235, 0.235],\n",
       "        [0.642, 0.642]]),\n",
       " array([[0.48445022, 0.42605559],\n",
       "        [0.65166481, 0.59929565],\n",
       "        [0.24183653, 0.21281648],\n",
       "        [0.61514951, 0.5634119 ]]),\n",
       " array([[0.49188616, 0.47803925],\n",
       "        [0.65901996, 0.64693533],\n",
       "        [0.245732  , 0.23886378],\n",
       "        [0.63180257, 0.63333645]]),\n",
       " array([[0.46841979, 0.46609043],\n",
       "        [0.65304626, 0.63949435],\n",
       "        [0.23370775, 0.23273458],\n",
       "        [0.55354974, 0.55424408]]),\n",
       " array([[0.48478503, 0.48985277],\n",
       "        [0.67387131, 0.66612554],\n",
       "        [0.24190402, 0.24480489],\n",
       "        [0.59629883, 0.64943287]]),\n",
       " array([[0.31041342, 0.44748043],\n",
       "        [0.46953905, 0.61524235],\n",
       "        [0.15501213, 0.22358813],\n",
       "        [0.45636673, 0.60659418]]),\n",
       " array([[0.48814646, 0.48317484],\n",
       "        [0.65360365, 0.65978523],\n",
       "        [0.24393317, 0.2409281 ],\n",
       "        [0.63920266, 0.63426605]]),\n",
       " array([[0.46459931, 0.4658483 ],\n",
       "        [0.62929179, 0.62806781],\n",
       "        [0.23215515, 0.23255612],\n",
       "        [0.6271066 , 0.62622251]]),\n",
       " array([[0.4938582 , 0.4891668 ],\n",
       "        [0.65343187, 0.65291507],\n",
       "        [0.24650156, 0.24410398],\n",
       "        [0.63760943, 0.63788127]]),\n",
       " array([[0.45068764, 0.43870551],\n",
       "        [0.63480165, 0.61971432],\n",
       "        [0.22502725, 0.21924225],\n",
       "        [0.54417242, 0.55565116]]),\n",
       " array([[0.48983598, 0.47562619],\n",
       "        [0.67022801, 0.6702685 ],\n",
       "        [0.24465082, 0.236628  ],\n",
       "        [0.6097157 , 0.57122925]]),\n",
       " array([[0.44933829, 0.44810425],\n",
       "        [0.6195339 , 0.61760688],\n",
       "        [0.22440344, 0.22386124],\n",
       "        [0.54860885, 0.59531681]]),\n",
       " array([[0.48736773, 0.49011422],\n",
       "        [0.65816553, 0.66711757],\n",
       "        [0.24333886, 0.2448022 ],\n",
       "        [0.54652813, 0.61353697]]),\n",
       " array([[0.43547176, 0.43586562],\n",
       "        [0.60133053, 0.61148117],\n",
       "        [0.21758981, 0.21762446],\n",
       "        [0.57935627, 0.52594   ]]),\n",
       " array([[0.49176861, 0.47504697],\n",
       "        [0.65702651, 0.64448569],\n",
       "        [0.24533243, 0.23735395],\n",
       "        [0.63317227, 0.62483885]]),\n",
       " array([[0.48198089, 0.46350213],\n",
       "        [0.66759283, 0.6495404 ],\n",
       "        [0.24057323, 0.23153069],\n",
       "        [0.47243977, 0.56234293]]),\n",
       " array([[0.47891608, 0.4907912 ],\n",
       "        [0.6660746 , 0.6646549 ],\n",
       "        [0.23928187, 0.24512725],\n",
       "        [0.57431257, 0.62408127]]),\n",
       " array([[0.43580678, 0.46412547],\n",
       "        [0.61410556, 0.63226183],\n",
       "        [0.21772641, 0.23184548],\n",
       "        [0.55532512, 0.61541166]]),\n",
       " array([[0.49248047, 0.4870339 ],\n",
       "        [0.66908136, 0.66402842],\n",
       "        [0.24592407, 0.24300677],\n",
       "        [0.65994896, 0.61972287]]),\n",
       " array([[0.48007601, 0.49625   ],\n",
       "        [0.65753461, 0.68623903],\n",
       "        [0.23980592, 0.24760805],\n",
       "        [0.64738128, 0.66332498]]),\n",
       " array([[0.50344073, 0.49292969],\n",
       "        [0.67631379, 0.68061811],\n",
       "        [0.25139338, 0.24628477],\n",
       "        [0.66930034, 0.66035218]]),\n",
       " array([[0.46469632, 0.42368015],\n",
       "        [0.63028983, 0.58983266],\n",
       "        [0.23208341, 0.21170821],\n",
       "        [0.6281366 , 0.58943453]]),\n",
       " array([[0.48289312, 0.49168981],\n",
       "        [0.64644296, 0.65377104],\n",
       "        [0.24121841, 0.24568562],\n",
       "        [0.64516214, 0.64614734]]),\n",
       " array([[0.45565263, 0.48380288],\n",
       "        [0.61463057, 0.64794133],\n",
       "        [0.22750105, 0.24149375],\n",
       "        [0.61312386, 0.62271181]]),\n",
       " array([[0.49417969, 0.49068538],\n",
       "        [0.66066113, 0.66292011],\n",
       "        [0.24692354, 0.24512195],\n",
       "        [0.6614729 , 0.64052149]]),\n",
       " array([[0.47371834, 0.42677418],\n",
       "        [0.63855126, 0.58322954],\n",
       "        [0.23674274, 0.21309908],\n",
       "        [0.62694092, 0.59226571]]),\n",
       " array([[0.49865234, 0.50106571],\n",
       "        [0.66908643, 0.66796226],\n",
       "        [0.24897674, 0.25000211],\n",
       "        [0.66546767, 0.65473798]]),\n",
       " array([[0.44621101, 0.45117989],\n",
       "        [0.62090303, 0.61661224],\n",
       "        [0.22296573, 0.2253566 ],\n",
       "        [0.60025152, 0.56177755]]),\n",
       " array([[0.48170436, 0.4898241 ],\n",
       "        [0.6498311 , 0.65796307],\n",
       "        [0.24054922, 0.24466126],\n",
       "        [0.635649  , 0.62100543]]),\n",
       " array([[0.49930184, 0.47683667],\n",
       "        [0.70185006, 0.65176095],\n",
       "        [0.24950408, 0.23831348],\n",
       "        [0.50213563, 0.6240258 ]]),\n",
       " array([[0.48314739, 0.48907806],\n",
       "        [0.66850829, 0.66296538],\n",
       "        [0.24133632, 0.24441335],\n",
       "        [0.48646092, 0.6447856 ]]),\n",
       " array([[0.46682625, 0.47994141],\n",
       "        [0.63955074, 0.65199395],\n",
       "        [0.23330706, 0.23987189],\n",
       "        [0.60179964, 0.64859515]]),\n",
       " array([[0.47506251, 0.4865625 ],\n",
       "        [0.65004276, 0.66021785],\n",
       "        [0.23731215, 0.24281763],\n",
       "        [0.601876  , 0.65461425]]),\n",
       " array([[0.43045546, 0.43107557],\n",
       "        [0.60793808, 0.61470348],\n",
       "        [0.21484844, 0.21510003],\n",
       "        [0.50294586, 0.53741448]]),\n",
       " array([[0.49226531, 0.47972419],\n",
       "        [0.67153285, 0.66127252],\n",
       "        [0.24580876, 0.23957651],\n",
       "        [0.53255184, 0.64834541]]),\n",
       " array([[0.44100998, 0.44352077],\n",
       "        [0.6032533 , 0.60749301],\n",
       "        [0.22034285, 0.22148481],\n",
       "        [0.59452634, 0.59149118]]),\n",
       " array([[0.47314885, 0.48638351],\n",
       "        [0.63478845, 0.64670435],\n",
       "        [0.23631758, 0.2429048 ],\n",
       "        [0.63156488, 0.64288176]]),\n",
       " array([[0.44187968, 0.42979638],\n",
       "        [0.62539977, 0.60271582],\n",
       "        [0.22058144, 0.2143353 ],\n",
       "        [0.52419797, 0.5412482 ]]),\n",
       " array([[0.49130399, 0.47919635],\n",
       "        [0.66705836, 0.65464405],\n",
       "        [0.24542666, 0.23944083],\n",
       "        [0.63543083, 0.62993538]]),\n",
       " array([[0.47984444, 0.48603516],\n",
       "        [0.65211832, 0.66113177],\n",
       "        [0.23946305, 0.24275097],\n",
       "        [0.61901551, 0.65413682]]),\n",
       " array([[0.48940092, 0.48065383],\n",
       "        [0.65680873, 0.65839848],\n",
       "        [0.24458066, 0.2401722 ],\n",
       "        [0.62668312, 0.6182142 ]]),\n",
       " array([[0.44201109, 0.46146754],\n",
       "        [0.61583406, 0.63564403],\n",
       "        [0.2206403 , 0.23049572],\n",
       "        [0.5407285 , 0.59187855]]),\n",
       " array([[0.48243713, 0.47268873],\n",
       "        [0.65779187, 0.64562107],\n",
       "        [0.24101635, 0.23619473],\n",
       "        [0.58896805, 0.6235079 ]]),\n",
       " array([[0.47593653, 0.45150176],\n",
       "        [0.65635832, 0.61773514],\n",
       "        [0.23748452, 0.22545592],\n",
       "        [0.59679895, 0.60638558]]),\n",
       " array([[0.49006422, 0.46511628],\n",
       "        [0.65517428, 0.62494941],\n",
       "        [0.24483867, 0.23226967],\n",
       "        [0.64306159, 0.62291555]]),\n",
       " array([[0.3632283 , 0.43455585],\n",
       "        [0.53006032, 0.60633803],\n",
       "        [0.181293  , 0.21654395],\n",
       "        [0.48399609, 0.57508627]]),\n",
       " array([[0.48211263, 0.48713759],\n",
       "        [0.65076072, 0.66182832],\n",
       "        [0.24057794, 0.24300603],\n",
       "        [0.59423692, 0.62465415]]),\n",
       " array([[0.40956274, 0.41522086],\n",
       "        [0.58329484, 0.59260499],\n",
       "        [0.2045556 , 0.20728438],\n",
       "        [0.54004192, 0.51400377]]),\n",
       " array([[0.49620172, 0.48983276],\n",
       "        [0.67739114, 0.6669963 ],\n",
       "        [0.24791743, 0.24476817],\n",
       "        [0.59506627, 0.63114414]]),\n",
       " array([[0.49240556, 0.4953125 ],\n",
       "        [0.66736524, 0.67382294],\n",
       "        [0.24599394, 0.24745092],\n",
       "        [0.65893107, 0.66248694]]),\n",
       " array([[0.48174168, 0.49103516],\n",
       "        [0.66045126, 0.67288494],\n",
       "        [0.24057245, 0.24530738],\n",
       "        [0.64937943, 0.65865   ]]),\n",
       " array([[0.465621  , 0.42083265],\n",
       "        [0.63942209, 0.5918001 ],\n",
       "        [0.23250495, 0.21024157],\n",
       "        [0.59762528, 0.57061098]]),\n",
       " array([[0.47792706, 0.4987014 ],\n",
       "        [0.64194215, 0.65958016],\n",
       "        [0.23870787, 0.24904967],\n",
       "        [0.63655731, 0.64766709]]),\n",
       " array([[0.44961464, 0.48010398],\n",
       "        [0.61608403, 0.64270036],\n",
       "        [0.22459461, 0.23992298],\n",
       "        [0.59760607, 0.63847893]]),\n",
       " array([[0.48678686, 0.49405071],\n",
       "        [0.64972667, 0.65266239],\n",
       "        [0.2431533 , 0.24678507],\n",
       "        [0.63196708, 0.65169131]]),\n",
       " array([[0.48652344, 0.47070976],\n",
       "        [0.66269387, 0.64233679],\n",
       "        [0.24287879, 0.23519686],\n",
       "        [0.6545789 , 0.62018784]]),\n",
       " array([[0.47323362, 0.48527526],\n",
       "        [0.66621765, 0.67636544],\n",
       "        [0.2362401 , 0.24221595],\n",
       "        [0.53701746, 0.56713076]]),\n",
       " array([[0.43488826, 0.39931645],\n",
       "        [0.60205151, 0.56501579],\n",
       "        [0.21735277, 0.1995003 ],\n",
       "        [0.5979133 , 0.55900481]]),\n",
       " array([[0.48235387, 0.48307871],\n",
       "        [0.64395564, 0.63858264],\n",
       "        [0.24099603, 0.24107586],\n",
       "        [0.64421142, 0.64001594]]),\n",
       " array([[0.47358763, 0.47238065],\n",
       "        [0.65191111, 0.65131561],\n",
       "        [0.23666494, 0.23601946],\n",
       "        [0.59491204, 0.64162156]]),\n",
       " array([[0.4973593 , 0.49541016],\n",
       "        [0.67681472, 0.66325864],\n",
       "        [0.24836185, 0.24747713],\n",
       "        [0.62997204, 0.66257428]]),\n",
       " array([[0.45646867, 0.48930976],\n",
       "        [0.62673784, 0.67120793],\n",
       "        [0.22786235, 0.24444322],\n",
       "        [0.56574598, 0.57341878]]),\n",
       " array([[0.48078497, 0.48967422],\n",
       "        [0.64234355, 0.65468069],\n",
       "        [0.24021577, 0.2445957 ],\n",
       "        [0.62909164, 0.64675565]]),\n",
       " array([[0.46387218, 0.48423881],\n",
       "        [0.6509431 , 0.65277927],\n",
       "        [0.23177519, 0.24197676],\n",
       "        [0.57524488, 0.64430117]]),\n",
       " array([[0.49028602, 0.48097815],\n",
       "        [0.67194675, 0.65715949],\n",
       "        [0.24475023, 0.23996876],\n",
       "        [0.59710653, 0.61209   ]]),\n",
       " array([[0.48469813, 0.48337455],\n",
       "        [0.64187342, 0.64182022],\n",
       "        [0.24214462, 0.24140954],\n",
       "        [0.6458967 , 0.64953974]]),\n",
       " array([[0.49577115, 0.49604924],\n",
       "        [0.65809359, 0.65919164],\n",
       "        [0.2475214 , 0.24784745],\n",
       "        [0.64401393, 0.65592104]]),\n",
       " array([[0.43930694, 0.39759327],\n",
       "        [0.62885529, 0.58219517],\n",
       "        [0.21947595, 0.19832439],\n",
       "        [0.51128169, 0.48641618]]),\n",
       " array([[0.48054451, 0.48603613],\n",
       "        [0.64844528, 0.6632232 ],\n",
       "        [0.24004732, 0.2428941 ],\n",
       "        [0.62808146, 0.63733749]]),\n",
       " array([[0.41965416, 0.42015774],\n",
       "        [0.5792981 , 0.57848353],\n",
       "        [0.20958557, 0.2098421 ],\n",
       "        [0.58585022, 0.58567443]]),\n",
       " array([[0.48363557, 0.47735983],\n",
       "        [0.64324439, 0.63931737],\n",
       "        [0.24168181, 0.23846433],\n",
       "        [0.64412166, 0.64124305]]),\n",
       " array([[0.43774553, 0.41569697],\n",
       "        [0.60947703, 0.58878691],\n",
       "        [0.21872759, 0.2076662 ],\n",
       "        [0.59802848, 0.57619577]]),\n",
       " array([[0.49406481, 0.48250201],\n",
       "        [0.66910484, 0.65105297],\n",
       "        [0.24669042, 0.24100395],\n",
       "        [0.65569165, 0.63811677]]),\n",
       " array([[0.47779757, 0.4331308 ],\n",
       "        [0.657806  , 0.63845283],\n",
       "        [0.23828314, 0.21586393],\n",
       "        [0.45209662, 0.40433821]]),\n",
       " array([[0.47805621, 0.48748647],\n",
       "        [0.65962322, 0.65538574],\n",
       "        [0.23881278, 0.24355706],\n",
       "        [0.57615618, 0.62758501]]),\n",
       " array([[0.49057826, 0.48874912],\n",
       "        [0.67973021, 0.6566937 ],\n",
       "        [0.2445873 , 0.24399693],\n",
       "        [0.65604452, 0.65655585]]),\n",
       " array([[0.48851206, 0.48027344],\n",
       "        [0.66159989, 0.65364168],\n",
       "        [0.24407228, 0.23998219],\n",
       "        [0.63876851, 0.64889827]]),\n",
       " array([[0.43552081, 0.44072981],\n",
       "        [0.60811143, 0.61745844],\n",
       "        [0.21752009, 0.22025456],\n",
       "        [0.55727912, 0.56813256]]),\n",
       " array([[0.49406773, 0.49524125],\n",
       "        [0.65193971, 0.66789441],\n",
       "        [0.24686642, 0.24747291],\n",
       "        [0.6485238 , 0.63713799]]),\n",
       " array([[0.46546484, 0.47807672],\n",
       "        [0.62564705, 0.64486642],\n",
       "        [0.23227712, 0.23852715],\n",
       "        [0.6079391 , 0.6329168 ]]),\n",
       " array([[0.46619217, 0.48519271],\n",
       "        [0.63226681, 0.63061103],\n",
       "        [0.23292586, 0.24140139],\n",
       "        [0.62583537, 0.64453446]]),\n",
       " array([[0.45677034, 0.48108841],\n",
       "        [0.63024833, 0.64803569],\n",
       "        [0.22802166, 0.24023232],\n",
       "        [0.58348319, 0.64039514]]),\n",
       " array([[0.4935858 , 0.48499961],\n",
       "        [0.6686704 , 0.67545323],\n",
       "        [0.24619471, 0.24147903],\n",
       "        [0.61001765, 0.65089194]]),\n",
       " array([[0.42928127, 0.47721618],\n",
       "        [0.62110166, 0.63754155],\n",
       "        [0.21428454, 0.23816338],\n",
       "        [0.38658852, 0.57609678]]),\n",
       " array([[0.47917188, 0.48789351],\n",
       "        [0.65027756, 0.65173994],\n",
       "        [0.23936072, 0.24376741],\n",
       "        [0.61920173, 0.63644837]]),\n",
       " array([[0.47778672, 0.44066632],\n",
       "        [0.64989343, 0.61697523],\n",
       "        [0.23869295, 0.22021236],\n",
       "        [0.61177013, 0.57238456]]),\n",
       " array([[0.48352951, 0.48171056],\n",
       "        [0.65072346, 0.65406007],\n",
       "        [0.24155029, 0.24068074],\n",
       "        [0.62459873, 0.62955032]]),\n",
       " array([[0.44161663, 0.42031575],\n",
       "        [0.62336813, 0.59262514],\n",
       "        [0.22065479, 0.20988206],\n",
       "        [0.56193914, 0.56650895]]),\n",
       " array([[0.48905005, 0.49523617],\n",
       "        [0.66322205, 0.66193611],\n",
       "        [0.24436898, 0.24732721],\n",
       "        [0.6371924 , 0.64789923]]),\n",
       " array([[0.43073438, 0.44408081],\n",
       "        [0.59847606, 0.60976422],\n",
       "        [0.21522192, 0.22175729],\n",
       "        [0.59491204, 0.60074882]]),\n",
       " array([[0.47895434, 0.49290221],\n",
       "        [0.64429331, 0.66538285],\n",
       "        [0.23926567, 0.24631158],\n",
       "        [0.6359943 , 0.62226707]]),\n",
       " array([[0.34102276, 0.44925254],\n",
       "        [0.50380199, 0.61487887],\n",
       "        [0.17027375, 0.22449095],\n",
       "        [0.48442241, 0.6113183 ]]),\n",
       " array([[0.48105095, 0.48281432],\n",
       "        [0.6543424 , 0.66804732],\n",
       "        [0.24018738, 0.24028163],\n",
       "        [0.60612   , 0.60905473]]),\n",
       " array([[0.48689502, 0.46441622],\n",
       "        [0.66964896, 0.64628609],\n",
       "        [0.24304339, 0.23198816],\n",
       "        [0.57288197, 0.58859852]]),\n",
       " array([[0.50138357, 0.47541899],\n",
       "        [0.66763981, 0.65609062],\n",
       "        [0.25043914, 0.2374594 ],\n",
       "        [0.63019196, 0.60349671]]),\n",
       " array([[0.41607762, 0.42959085],\n",
       "        [0.58901768, 0.59699566],\n",
       "        [0.20771199, 0.2145725 ],\n",
       "        [0.54035408, 0.56879298]]),\n",
       " array([[0.4915683 , 0.48939907],\n",
       "        [0.6579411 , 0.65845219],\n",
       "        [0.24558046, 0.24438112],\n",
       "        [0.63644837, 0.62740104]]),\n",
       " array([[0.4257571 , 0.47509892],\n",
       "        [0.60812248, 0.64275324],\n",
       "        [0.21269247, 0.23719062],\n",
       "        [0.53854168, 0.602887  ]]),\n",
       " array([[0.49085957, 0.49645716],\n",
       "        [0.67133883, 0.67420645],\n",
       "        [0.24511486, 0.24799114],\n",
       "        [0.58692352, 0.59302006]]),\n",
       " array([[0.41566315, 0.45498294],\n",
       "        [0.58408443, 0.62696214],\n",
       "        [0.20764531, 0.22734876],\n",
       "        [0.56359326, 0.60882796]]),\n",
       " array([[0.49035883, 0.49021678],\n",
       "        [0.65362277, 0.65263409],\n",
       "        [0.24502155, 0.24490916],\n",
       "        [0.65388913, 0.64912998]]),\n",
       " array([[0.43644119, 0.47982907],\n",
       "        [0.60484756, 0.64625962],\n",
       "        [0.2180507 , 0.23971858],\n",
       "        [0.59120051, 0.63262472]]),\n",
       " array([[0.47494946, 0.49047303],\n",
       "        [0.6449486 , 0.66475928],\n",
       "        [0.23730669, 0.24489433],\n",
       "        [0.63766381, 0.60469553]]),\n",
       " array([[0.40006228, 0.42066428],\n",
       "        [0.57151754, 0.59590244],\n",
       "        [0.1999205 , 0.21021421],\n",
       "        [0.54692001, 0.56201991]]),\n",
       " array([[0.48230469, 0.48148438],\n",
       "        [0.6589108 , 0.66467147],\n",
       "        [0.2408091 , 0.24018114],\n",
       "        [0.65074973, 0.65000264]]),\n",
       " array([[0.46154277, 0.46849522],\n",
       "        [0.63469458, 0.65714758],\n",
       "        [0.23039085, 0.23400389],\n",
       "        [0.48722116, 0.55941026]]),\n",
       " array([[0.47532716, 0.4580024 ],\n",
       "        [0.65384615, 0.64024315],\n",
       "        [0.23732047, 0.22875066],\n",
       "        [0.45064456, 0.57468961]]),\n",
       " array([[0.46296449, 0.48473754],\n",
       "        [0.63832755, 0.65755146],\n",
       "        [0.23131812, 0.24203418],\n",
       "        [0.60871456, 0.60067233]]),\n",
       " array([[0.49284575, 0.5008002 ],\n",
       "        [0.66728475, 0.67167509],\n",
       "        [0.24583695, 0.25018041],\n",
       "        [0.6401243 , 0.63433891]]),\n",
       " array([[0.44205212, 0.4749468 ],\n",
       "        [0.60963729, 0.64144344],\n",
       "        [0.22090248, 0.2373219 ],\n",
       "        [0.60401074, 0.63209501]]),\n",
       " array([[0.47863504, 0.49306406],\n",
       "        [0.644503  , 0.65425114],\n",
       "        [0.23902336, 0.24625983],\n",
       "        [0.63777255, 0.64129714]]),\n",
       " array([[0.45632511, 0.45412343],\n",
       "        [0.62795246, 0.64084778],\n",
       "        [0.22791337, 0.22691808],\n",
       "        [0.58516635, 0.52647029]]),\n",
       " array([[0.48163995, 0.47237569],\n",
       "        [0.64450836, 0.64398927],\n",
       "        [0.24064535, 0.23589705],\n",
       "        [0.63788127, 0.6341021 ]]),\n",
       " array([[0.42369735, 0.36966041],\n",
       "        [0.59732876, 0.54227017],\n",
       "        [0.21152883, 0.18468719],\n",
       "        [0.55890342, 0.51800394]]),\n",
       " array([[0.47466119, 0.47901147],\n",
       "        [0.6417724 , 0.64446507],\n",
       "        [0.2371752 , 0.23933399],\n",
       "        [0.62210022, 0.64381639]]),\n",
       " array([[0.48504802, 0.48263486],\n",
       "        [0.65533362, 0.64898655],\n",
       "        [0.24234857, 0.24112578],\n",
       "        [0.62235975, 0.60977232]]),\n",
       " array([[0.48959179, 0.49283732],\n",
       "        [0.6519249 , 0.65638419],\n",
       "        [0.24459379, 0.24624245],\n",
       "        [0.64066586, 0.64102666]]),\n",
       " array([[0.44458954, 0.34349857],\n",
       "        [0.60885954, 0.50167665],\n",
       "        [0.22199707, 0.1715846 ],\n",
       "        [0.60347767, 0.50954821]]),\n",
       " array([[0.48997996, 0.48781158],\n",
       "        [0.65009306, 0.65183981],\n",
       "        [0.24468343, 0.24343773],\n",
       "        [0.64639788, 0.65358824]]),\n",
       " array([[0.46603229, 0.41348084],\n",
       "        [0.63218206, 0.57298275],\n",
       "        [0.23277195, 0.20641677],\n",
       "        [0.63022861, 0.5736771 ]]),\n",
       " array([[0.48557502, 0.50133172],\n",
       "        [0.64825543, 0.66422499],\n",
       "        [0.24249799, 0.25040076],\n",
       "        [0.64739915, 0.6534466 ]]),\n",
       " array([[0.42010255, 0.49223184],\n",
       "        [0.59202772, 0.66023896],\n",
       "        [0.20985185, 0.24592748],\n",
       "        [0.56161593, 0.63397455]]),\n",
       " array([[0.49354964, 0.47714387],\n",
       "        [0.67405203, 0.65712978],\n",
       "        [0.24603607, 0.23799604],\n",
       "        [0.61767326, 0.59232377]]),\n",
       " array([[0.47388477, 0.46866874],\n",
       "        [0.65698594, 0.64507563],\n",
       "        [0.23625145, 0.23415862],\n",
       "        [0.60130308, 0.60723855]]),\n",
       " array([[0.49113989, 0.48660916],\n",
       "        [0.66745781, 0.65540802],\n",
       "        [0.24519688, 0.2430506 ],\n",
       "        [0.62106114, 0.63271601]]),\n",
       " array([[0.42010255, 0.49223184],\n",
       "        [0.59202772, 0.66023896],\n",
       "        [0.20986456, 0.24579595],\n",
       "        [0.56161593, 0.63397455]]),\n",
       " array([[0.48327367, 0.50014182],\n",
       "        [0.65439046, 0.66283597],\n",
       "        [0.24135347, 0.2499245 ],\n",
       "        [0.62899987, 0.65037629]]),\n",
       " array([[0.47018976, 0.43170967],\n",
       "        [0.64000113, 0.60731452],\n",
       "        [0.23490205, 0.21566929],\n",
       "        [0.61428745, 0.55593631]]),\n",
       " array([[0.48856879, 0.49405917],\n",
       "        [0.65064077, 0.65961637],\n",
       "        [0.24401627, 0.24678249],\n",
       "        [0.64404984, 0.64639788]]),\n",
       " array([[0.39337378, 0.39309278],\n",
       "        [0.56355404, 0.56340317],\n",
       "        [0.19651342, 0.19642936],\n",
       "        [0.53181544, 0.54265993]]),\n",
       " array([[0.48554901, 0.48640619],\n",
       "        [0.65963925, 0.6526678 ],\n",
       "        [0.24249286, 0.24297017],\n",
       "        [0.61522442, 0.636521  ]]),\n",
       " array([[0.49093608, 0.47951172],\n",
       "        [0.67370791, 0.64985839],\n",
       "        [0.24515455, 0.23957209],\n",
       "        [0.65849185, 0.64820266]]),\n",
       " array([[0.49378553, 0.49120598],\n",
       "        [0.66333305, 0.6516851 ],\n",
       "        [0.24660832, 0.24536451],\n",
       "        [0.62515272, 0.64866648]]),\n",
       " array([[0.46573709, 0.4529375 ],\n",
       "        [0.66664349, 0.66080058],\n",
       "        [0.23212417, 0.22617567],\n",
       "        [0.54419312, 0.44125795]]),\n",
       " array([[0.49289375, 0.49714057],\n",
       "        [0.66958226, 0.67626702],\n",
       "        [0.24623082, 0.24837187],\n",
       "        [0.6178785 , 0.63183913]]),\n",
       " array([[0.49078565, 0.48121299],\n",
       "        [0.65378197, 0.65520002],\n",
       "        [0.24516844, 0.24033117],\n",
       "        [0.64349301, 0.602887  ]]),\n",
       " array([[0.48330893, 0.48423551],\n",
       "        [0.65839412, 0.65085901],\n",
       "        [0.24136389, 0.24198869],\n",
       "        [0.62193333, 0.63588528]]),\n",
       " array([[0.471, 0.471],\n",
       "        [0.651, 0.651],\n",
       "        [0.235, 0.235],\n",
       "        [0.642, 0.642]]),\n",
       " array([[0.50306976, 0.50099609],\n",
       "        [0.67288229, 0.66813399],\n",
       "        [0.25130206, 0.25018706],\n",
       "        [0.66890249, 0.6675515 ]]),\n",
       " array([[0.47404297, 0.47053168],\n",
       "        [0.67186159, 0.65403648],\n",
       "        [0.23609292, 0.23508846],\n",
       "        [0.64318745, 0.52251576]]),\n",
       " array([[0.48460547, 0.47147087],\n",
       "        [0.66375586, 0.66555403],\n",
       "        [0.24204231, 0.23558729],\n",
       "        [0.59754845, 0.58826773]]),\n",
       " array([[0.46689454, 0.48134766],\n",
       "        [0.64157727, 0.66084788],\n",
       "        [0.23320589, 0.24043237],\n",
       "        [0.6035348 , 0.64987804]]),\n",
       " array([[0.50147752, 0.48234375],\n",
       "        [0.66567718, 0.6548926 ],\n",
       "        [0.25053978, 0.24066632],\n",
       "        [0.6582106 , 0.65078529]]),\n",
       " array([[0.38658449, 0.4543252 ],\n",
       "        [0.5585855 , 0.63433933],\n",
       "        [0.19303743, 0.22695853],\n",
       "        [0.50261749, 0.59259463]]),\n",
       " array([[0.49144394, 0.4905914 ],\n",
       "        [0.65889602, 0.66646379],\n",
       "        [0.24550798, 0.2451155 ],\n",
       "        [0.6237484 , 0.59917921]]),\n",
       " array([[0.48166465, 0.41574037],\n",
       "        [0.64817445, 0.58115005],\n",
       "        [0.24074014, 0.20767833],\n",
       "        [0.64980683, 0.57174738]]),\n",
       " array([[0.49299777, 0.48568479],\n",
       "        [0.65357191, 0.64836068],\n",
       "        [0.24623979, 0.24255927],\n",
       "        [0.64352894, 0.64661257]]),\n",
       " array([[0.42687722, 0.45158675],\n",
       "        [0.61066925, 0.62136652],\n",
       "        [0.2131933 , 0.22567189],\n",
       "        [0.56568571, 0.60649937]]),\n",
       " array([[0.48205199, 0.4964184 ],\n",
       "        [0.67182772, 0.66196304],\n",
       "        [0.24034559, 0.2480571 ],\n",
       "        [0.57860692, 0.64539514]]),\n",
       " array([[0.47507355, 0.47893329],\n",
       "        [0.65707915, 0.64474017],\n",
       "        [0.23715472, 0.23924739],\n",
       "        [0.63057666, 0.61810232]]),\n",
       " array([[0.49176213, 0.4891766 ],\n",
       "        [0.67195286, 0.65516194],\n",
       "        [0.24562124, 0.24436692],\n",
       "        [0.61799042, 0.63326348]]),\n",
       " array([[0.46800453, 0.44241513],\n",
       "        [0.63768202, 0.6149022 ],\n",
       "        [0.2338191 , 0.2210483 ],\n",
       "        [0.59151055, 0.5736175 ]]),\n",
       " array([[0.479695  , 0.49385754],\n",
       "        [0.6470254 , 0.65795015],\n",
       "        [0.23952994, 0.24676906],\n",
       "        [0.61572985, 0.65055414]]),\n",
       " array([[0.40715231, 0.42532605],\n",
       "        [0.5742918 , 0.59731803],\n",
       "        [0.20337076, 0.21244785],\n",
       "        [0.55540664, 0.56359326]]),\n",
       " array([[0.48238916, 0.4854486 ],\n",
       "        [0.64218426, 0.65205938],\n",
       "        [0.24094667, 0.24245085],\n",
       "        [0.64068391, 0.63344588]]),\n",
       " array([[0.4858594 , 0.46631951],\n",
       "        [0.67295773, 0.6299708 ],\n",
       "        [0.24277762, 0.23295095],\n",
       "        [0.59562504, 0.6334094 ]]),\n",
       " array([[0.4815418 , 0.50048828],\n",
       "        [0.67838427, 0.66897272],\n",
       "        [0.24041134, 0.24991578],\n",
       "        [0.63737375, 0.66710055]]),\n",
       " array([[0.49765306, 0.45750145],\n",
       "        [0.68315665, 0.62857468],\n",
       "        [0.24841705, 0.22843942],\n",
       "        [0.55611957, 0.60281075]]),\n",
       " array([[0.482832  , 0.48069289],\n",
       "        [0.63996824, 0.64296058],\n",
       "        [0.24119778, 0.2401848 ],\n",
       "        [0.62681203, 0.63780879]]),\n",
       " array([[0.49257812, 0.4984375 ],\n",
       "        [0.66965827, 0.67622354],\n",
       "        [0.24595503, 0.24909278],\n",
       "        [0.66003664, 0.66527633]]),\n",
       " array([[0.49210783, 0.48355469],\n",
       "        [0.66567133, 0.66286479],\n",
       "        [0.24560495, 0.24153561],\n",
       "        [0.65952795, 0.65188657]]),\n",
       " array([[0.45186739, 0.40419162],\n",
       "        [0.61997294, 0.56837254],\n",
       "        [0.22578601, 0.20190473],\n",
       "        [0.59216894, 0.56139365]]),\n",
       " array([[0.48109167, 0.47820104],\n",
       "        [0.6407498 , 0.63821236],\n",
       "        [0.24027011, 0.23890675],\n",
       "        [0.63075977, 0.63788127]]),\n",
       " array([[0.49337818, 0.48031284],\n",
       "        [0.65448968, 0.65622697],\n",
       "        [0.24638451, 0.23989402],\n",
       "        [0.62863265, 0.55348844]]),\n",
       " array([[0.47856792, 0.48628554],\n",
       "        [0.65028849, 0.6723156 ],\n",
       "        [0.23893678, 0.24278485],\n",
       "        [0.58980362, 0.54875283]]),\n",
       " array([[0.48084118, 0.49080564],\n",
       "        [0.64023911, 0.64600555],\n",
       "        [0.23992102, 0.24506868],\n",
       "        [0.64586088, 0.65491468]]),\n",
       " array([[0.4838921 , 0.47579873],\n",
       "        [0.66645994, 0.65089179],\n",
       "        [0.24133725, 0.23716043],\n",
       "        [0.63178429, 0.61705719]]),\n",
       " array([[0.48198089, 0.46350213],\n",
       "        [0.66759283, 0.6495404 ],\n",
       "        [0.24016525, 0.23152158],\n",
       "        [0.47243977, 0.56234293]]),\n",
       " array([[0.48902086, 0.48421507],\n",
       "        [0.66996762, 0.65765011],\n",
       "        [0.24434951, 0.24188739],\n",
       "        [0.65673208, 0.63026525]]),\n",
       " array([[0.47347508, 0.434969  ],\n",
       "        [0.64940863, 0.60733033],\n",
       "        [0.23653163, 0.21724631],\n",
       "        [0.60873346, 0.55744171]]),\n",
       " array([[0.49814907, 0.48302629],\n",
       "        [0.67654286, 0.65525666],\n",
       "        [0.24892495, 0.24136037],\n",
       "        [0.63744628, 0.62614879]]),\n",
       " array([[0.46689454, 0.48134766],\n",
       "        [0.64157727, 0.66084788],\n",
       "        [0.23331049, 0.24018324],\n",
       "        [0.6035348 , 0.64987804]]),\n",
       " array([[0.48298413, 0.48182709],\n",
       "        [0.64875417, 0.64555577],\n",
       "        [0.24136886, 0.2405944 ],\n",
       "        [0.63699287, 0.63096113]]),\n",
       " array([[0.47420182, 0.48268217],\n",
       "        [0.63667678, 0.64984654],\n",
       "        [0.2368636 , 0.24097051],\n",
       "        [0.62530038, 0.6213953 ]]),\n",
       " array([[0.48881535, 0.48964515],\n",
       "        [0.65763075, 0.66344101],\n",
       "        [0.24381603, 0.24449042],\n",
       "        [0.62620408, 0.63697472]]),\n",
       " array([[0.48504802, 0.48263486],\n",
       "        [0.65533362, 0.64898655],\n",
       "        [0.24235677, 0.24115055],\n",
       "        [0.62235975, 0.60977232]]),\n",
       " array([[0.49924699, 0.48180284],\n",
       "        [0.67694507, 0.65583765],\n",
       "        [0.24941512, 0.24051489],\n",
       "        [0.6237484 , 0.60617692]]),\n",
       " array([[0.42432335, 0.45767907],\n",
       "        [0.5935569 , 0.63618325],\n",
       "        [0.21186798, 0.22848036],\n",
       "        [0.58432527, 0.5972987 ]]),\n",
       " array([[0.49020722, 0.48063068],\n",
       "        [0.6520346 , 0.64494572],\n",
       "        [0.24482635, 0.24019154],\n",
       "        [0.65667922, 0.64580716]]),\n",
       " array([[0.47620877, 0.46100668],\n",
       "        [0.65335636, 0.64802009],\n",
       "        [0.23794341, 0.22937922],\n",
       "        [0.60714383, 0.51604956]]),\n",
       " array([[0.47884372, 0.48797174],\n",
       "        [0.65857906, 0.65674472],\n",
       "        [0.23923813, 0.24381185],\n",
       "        [0.59979216, 0.6363939 ]]),\n",
       " array([[0.41159938, 0.40262904],\n",
       "        [0.57908561, 0.56838785],\n",
       "        [0.20562555, 0.20100496],\n",
       "        [0.56306919, 0.56181795]]),\n",
       " array([[0.49741699, 0.48348915],\n",
       "        [0.66833665, 0.6465286 ],\n",
       "        [0.24847233, 0.24159229],\n",
       "        [0.63513982, 0.64010624]]),\n",
       " array([[0.46303696, 0.45891241],\n",
       "        [0.63580247, 0.62038832],\n",
       "        [0.23132013, 0.2293158 ],\n",
       "        [0.60581636, 0.61468113]]),\n",
       " array([[0.48749127, 0.49896846],\n",
       "        [0.65708749, 0.66199307],\n",
       "        [0.24350844, 0.24882451],\n",
       "        [0.63346412, 0.6328803 ]]),\n",
       " array([[0.41962136, 0.40393807],\n",
       "        [0.59176041, 0.57505089],\n",
       "        [0.20967444, 0.20180657],\n",
       "        [0.57320013, 0.55725879]]),\n",
       " array([[0.48938386, 0.49715579],\n",
       "        [0.65850898, 0.66571222],\n",
       "        [0.24435124, 0.24834117],\n",
       "        [0.64607574, 0.63733749]]),\n",
       " array([[0.39743015, 0.44829276],\n",
       "        [0.56107518, 0.61234623],\n",
       "        [0.19848938, 0.22393462],\n",
       "        [0.55197477, 0.60017498]]),\n",
       " array([[0.49471759, 0.4876636 ],\n",
       "        [0.65792851, 0.64588241],\n",
       "        [0.24704362, 0.24344098],\n",
       "        [0.63954616, 0.65026955]]),\n",
       " array([[0.49032288, 0.4776597 ],\n",
       "        [0.66775705, 0.64573153],\n",
       "        [0.24479706, 0.23864629],\n",
       "        [0.58622118, 0.64158552]]),\n",
       " array([[0.4925624 , 0.49746407],\n",
       "        [0.66606057, 0.66164307],\n",
       "        [0.24610216, 0.24849107],\n",
       "        [0.62662786, 0.6511585 ]]),\n",
       " array([[0.39193478, 0.46929735],\n",
       "        [0.56924097, 0.64744497],\n",
       "        [0.19570314, 0.23433667],\n",
       "        [0.52085109, 0.6175053 ]]),\n",
       " array([[0.48211472, 0.49319974],\n",
       "        [0.64794176, 0.66345503],\n",
       "        [0.24097612, 0.24637195],\n",
       "        [0.64686294, 0.64754207]]),\n",
       " array([[0.4577739 , 0.4694427 ],\n",
       "        [0.63697223, 0.63303919],\n",
       "        [0.22875837, 0.23440377],\n",
       "        [0.57097004, 0.63628494]]),\n",
       " array([[0.48550352, 0.47849696],\n",
       "        [0.66511033, 0.64769872],\n",
       "        [0.24236415, 0.23895344],\n",
       "        [0.57773827, 0.64250394]]),\n",
       " array([[0.31878424, 0.43705767],\n",
       "        [0.48388773, 0.60696734],\n",
       "        [0.15927628, 0.21833657],\n",
       "        [0.47225745, 0.57921829]]),\n",
       " array([[0.47981648, 0.4979265 ],\n",
       "        [0.64417128, 0.66461277],\n",
       "        [0.2396728 , 0.24869368],\n",
       "        [0.63546719, 0.64288176]]),\n",
       " array([[0.45303867, 0.4776374 ],\n",
       "        [0.62590031, 0.65117414],\n",
       "        [0.2261732 , 0.23865278],\n",
       "        [0.59749082, 0.61402488]]),\n",
       " array([[0.49169096, 0.49155384],\n",
       "        [0.6637638 , 0.66600664],\n",
       "        [0.24539473, 0.24552531],\n",
       "        [0.63121733, 0.61756129]]),\n",
       " array([[0.47817302, 0.4544978 ],\n",
       "        [0.65906585, 0.62502426],\n",
       "        [0.23878588, 0.22701161],\n",
       "        [0.61468113, 0.61141245]]),\n",
       " array([[0.48723146, 0.4816203 ],\n",
       "        [0.65962409, 0.64733297],\n",
       "        [0.24334247, 0.24063207],\n",
       "        [0.6390218 , 0.63882279]]),\n",
       " array([[0.48419922, 0.48529085],\n",
       "        [0.66000213, 0.67523798],\n",
       "        [0.24179895, 0.24189586],\n",
       "        [0.652472  , 0.59741398]]),\n",
       " array([[0.4761131 , 0.50029548],\n",
       "        [0.65149718, 0.67015196],\n",
       "        [0.23746863, 0.24995602],\n",
       "        [0.51119511, 0.6329168 ]]),\n",
       " array([[0.48016594, 0.39490145],\n",
       "        [0.65753773, 0.58071667],\n",
       "        [0.23991736, 0.19732221],\n",
       "        [0.62485732, 0.51056712]]),\n",
       " array([[0.49171293, 0.47121915],\n",
       "        [0.6647762 , 0.64179357],\n",
       "        [0.24569911, 0.23531407],\n",
       "        [0.63670252, 0.61543038]]),\n",
       " array([[0.48297582, 0.45160613],\n",
       "        [0.66066482, 0.62237782],\n",
       "        [0.24120737, 0.22561209],\n",
       "        [0.59975386, 0.59166552]]),\n",
       " array([[0.4826068 , 0.48233261],\n",
       "        [0.6631724 , 0.65285199],\n",
       "        [0.2407865 , 0.24085812],\n",
       "        [0.60380137, 0.61256012]]),\n",
       " array([[0.4285786 , 0.4233964 ],\n",
       "        [0.60941294, 0.59605015],\n",
       "        [0.21397856, 0.21131464],\n",
       "        [0.49998535, 0.52767793]]),\n",
       " array([[0.47021303, 0.47828836],\n",
       "        [0.66009831, 0.65546461],\n",
       "        [0.2343742 , 0.23838565],\n",
       "        [0.45725047, 0.57025174]]),\n",
       " array([[0.46154156, 0.44879518],\n",
       "        [0.62170454, 0.61501697],\n",
       "        [0.23059723, 0.22419395],\n",
       "        [0.61804637, 0.613368  ]]),\n",
       " array([[0.48704296, 0.47898297],\n",
       "        [0.64903146, 0.64317574],\n",
       "        [0.24329728, 0.23928311],\n",
       "        [0.63932923, 0.63453922]]),\n",
       " array([[0.49193359, 0.46141228],\n",
       "        [0.66253683, 0.6386883 ],\n",
       "        [0.24564562, 0.23022407],\n",
       "        [0.65945776, 0.50202607]]),\n",
       " array([[0.50199416, 0.4895111 ],\n",
       "        [0.66836372, 0.67027222],\n",
       "        [0.25071911, 0.24455688],\n",
       "        [0.64582507, 0.60695435]]),\n",
       " array([[0.34440199, 0.4396009 ],\n",
       "        [0.51663071, 0.61271453],\n",
       "        [0.17208988, 0.21972264],\n",
       "        [0.4772102 , 0.60501866]]),\n",
       " array([[0.49273438, 0.48519531],\n",
       "        [0.67773479, 0.66137749],\n",
       "        [0.24546272, 0.24238186],\n",
       "        [0.6601769 , 0.65337577]]),\n",
       " array([[0.49466946, 0.46974386],\n",
       "        [0.66864291, 0.63376645],\n",
       "        [0.247051  , 0.23459603],\n",
       "        [0.63048508, 0.62126537]]),\n",
       " array([[0.49313491, 0.48005018],\n",
       "        [0.65733233, 0.65013427],\n",
       "        [0.24634312, 0.2397848 ],\n",
       "        [0.61432496, 0.63331821]]),\n",
       " array([[0.45785128, 0.4342627 ],\n",
       "        [0.6426663 , 0.6041175 ],\n",
       "        [0.22868981, 0.2169831 ],\n",
       "        [0.53128899, 0.58651391]]),\n",
       " array([[0.47960667, 0.48730159],\n",
       "        [0.65077155, 0.64655701],\n",
       "        [0.23965247, 0.24346009],\n",
       "        [0.60937585, 0.64275584]]),\n",
       " array([[0.4558952 , 0.45351734],\n",
       "        [0.62803289, 0.62033156],\n",
       "        [0.22781307, 0.22662362],\n",
       "        [0.59963897, 0.61879198]]),\n",
       " array([[0.49494634, 0.47728407],\n",
       "        [0.67033772, 0.64709366],\n",
       "        [0.24721076, 0.23824192],\n",
       "        [0.63441176, 0.61890375]]),\n",
       " array([[0.4350175 , 0.43634506],\n",
       "        [0.62428566, 0.61613668],\n",
       "        [0.21692649, 0.21800803],\n",
       "        [0.50185074, 0.5458883 ]]),\n",
       " array([[0.48779343, 0.48371094],\n",
       "        [0.67216562, 0.66354089],\n",
       "        [0.24340223, 0.24153555],\n",
       "        [0.65503835, 0.65202854]]),\n",
       " array([[0.49026355, 0.43448967],\n",
       "        [0.65781254, 0.60251696],\n",
       "        [0.24496734, 0.2170628 ],\n",
       "        [0.64226995, 0.60336338]]),\n",
       " array([[0.48621538, 0.49184035],\n",
       "        [0.65200205, 0.64856106],\n",
       "        [0.24273076, 0.24550122],\n",
       "        [0.61858702, 0.65643246]]),\n",
       " array([[0.39015168, 0.43821653],\n",
       "        [0.56119337, 0.60972253],\n",
       "        [0.19486305, 0.21898962],\n",
       "        [0.51703813, 0.595548  ]]),\n",
       " array([[0.49621554, 0.50555118],\n",
       "        [0.68473681, 0.67420789],\n",
       "        [0.24722894, 0.25221862],\n",
       "        [0.62137674, 0.64562805]]),\n",
       " array([[0.42320582, 0.40247264],\n",
       "        [0.59848572, 0.57473805],\n",
       "        [0.21145368, 0.20108372],\n",
       "        [0.57599777, 0.54087405]]),\n",
       " array([[0.47258634, 0.49613101],\n",
       "        [0.64216596, 0.66012965],\n",
       "        [0.23609367, 0.24785777],\n",
       "        [0.61052689, 0.64255793]]),\n",
       " array([[0.49031891, 0.4666684 ],\n",
       "        [0.67678038, 0.64386412],\n",
       "        [0.24449179, 0.23289163],\n",
       "        [0.50336159, 0.51913983]]),\n",
       " array([[0.49080239, 0.49225719],\n",
       "        [0.65812969, 0.65659598],\n",
       "        [0.24518876, 0.24593943],\n",
       "        [0.61992749, 0.63541264]]),\n",
       " array([[0.48416016, 0.49853516],\n",
       "        [0.67000919, 0.67190503],\n",
       "        [0.24177296, 0.24904826],\n",
       "        [0.65243654, 0.66536331]]),\n",
       " array([[0.48574219, 0.49134766],\n",
       "        [0.66641657, 0.6640359 ],\n",
       "        [0.24254272, 0.2453153 ],\n",
       "        [0.65387143, 0.65893107]]),\n",
       " array([[0.45087635, 0.36044613],\n",
       "        [0.61572244, 0.52241434],\n",
       "        [0.22526696, 0.18010208],\n",
       "        [0.6093003 , 0.52232388]]),\n",
       " array([[0.48094494, 0.49016669],\n",
       "        [0.64678936, 0.65339017],\n",
       "        [0.24028615, 0.24481763],\n",
       "        [0.63835219, 0.64773853]]),\n",
       " array([[0.46980531, 0.42017747],\n",
       "        [0.65337482, 0.5884952 ],\n",
       "        [0.23464821, 0.20989912],\n",
       "        [0.56917294, 0.57470944]]),\n",
       " array([[0.47908239, 0.47958784],\n",
       "        [0.67804776, 0.65372497],\n",
       "        [0.23837451, 0.2395217 ],\n",
       "        [0.5500269 , 0.64697022]]),\n",
       " array([[0.4244948 , 0.48233658],\n",
       "        [0.5966841 , 0.65055204],\n",
       "        [0.21199985, 0.24102087],\n",
       "        [0.5634522 , 0.64327733]]),\n",
       " array([[0.48674579, 0.48604121],\n",
       "        [0.65070765, 0.64919514],\n",
       "        [0.24317623, 0.24289889],\n",
       "        [0.62991705, 0.65124733]]),\n",
       " array([[0.43441312, 0.44678037],\n",
       "        [0.60652168, 0.61529469],\n",
       "        [0.21709215, 0.22321883],\n",
       "        [0.59581762, 0.61308629]]),\n",
       " array([[0.48023327, 0.49317063],\n",
       "        [0.64500082, 0.9724997 ],\n",
       "        [0.23989729, 0.01123703],\n",
       "        [0.62861428, 0.6391484 ]]),\n",
       " array([[0.47599805, 0.47854535],\n",
       "        [0.64853582, 0.64965333],\n",
       "        [0.23775392, 0.23903115],\n",
       "        [0.59026956, 0.62607506]]),\n",
       " array([[0.48616928, 0.49514761],\n",
       "        [0.65829739, 0.66491444],\n",
       "        [0.24290264, 0.2474036 ],\n",
       "        [0.6065373 , 0.64345706]]),\n",
       " array([[0.46352683, 0.42977755],\n",
       "        [0.63565018, 0.60782211],\n",
       "        [0.23124229, 0.21446579],\n",
       "        [0.49677041, 0.49791703]]),\n",
       " array([[0.48876451, 0.49006334],\n",
       "        [0.65448863, 0.64995275],\n",
       "        [0.24421577, 0.24488931],\n",
       "        [0.63220464, 0.65188657]]),\n",
       " array([[0.42619127, 0.44101392],\n",
       "        [0.60996049, 0.61336614],\n",
       "        [0.21286351, 0.22039378],\n",
       "        [0.51821839, 0.60458144]]),\n",
       " array([[0.47436657, 0.49177475],\n",
       "        [0.64641227, 0.65194921],\n",
       "        [0.23702487, 0.24562497],\n",
       "        [0.57815299, 0.65353513]]),\n",
       " array([[0.48238858, 0.31674443],\n",
       "        [0.66199034, 0.47873911],\n",
       "        [0.24082622, 0.15828027],\n",
       "        [0.65048301, 0.47360105]]),\n",
       " array([[0.48256587, 0.49090801],\n",
       "        [0.6534512 , 0.65588945],\n",
       "        [0.24103887, 0.24529553],\n",
       "        [0.65067861, 0.65137168]]),\n",
       " array([[0.39663949, 0.48381608],\n",
       "        [0.56919553, 0.64804625],\n",
       "        [0.19821313, 0.24131326],\n",
       "        [0.52850307, 0.62583537]]),\n",
       " array([[0.48638436, 0.48061311],\n",
       "        [0.65492558, 0.64822683],\n",
       "        [0.24301889, 0.24011704],\n",
       "        [0.62070823, 0.63464846]]),\n",
       " array([[0.46054525, 0.39229811],\n",
       "        [0.62553546, 0.5611248 ],\n",
       "        [0.23003656, 0.19601702],\n",
       "        [0.59645275, 0.53916715]]),\n",
       " array([[0.4825728 , 0.49319114],\n",
       "        [0.65052083, 0.65751627],\n",
       "        [0.24116401, 0.24642854],\n",
       "        [0.6334094 , 0.63916649]]),\n",
       " array([[0.45523473, 0.4621874 ],\n",
       "        [0.65731854, 0.65146617],\n",
       "        [0.22708063, 0.23078731],\n",
       "        [0.29236567, 0.49696899]]),\n",
       " array([[0.48880082, 0.49784362],\n",
       "        [0.66688943, 0.68266359],\n",
       "        [0.24411841, 0.24873755],\n",
       "        [0.60021325, 0.62156232]]),\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fusion_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8225e3d227641859d68c04f6c4438bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fusion_scores_train = get_fusion_scores(img_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the features to a file\n",
    "# np.savez('temp_data/fusion_scores.npz',\n",
    "#          fusion_scores_train=fusion_scores_train, \n",
    "#          fusion_scores_test=fusion_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features from the file\n",
    "with np.load('temp_data/fusion_scores.npz') as data:\n",
    "    fusion_scores_train = data['fusion_scores_train']\n",
    "    fusion_scores_test = data['fusion_scores_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification by machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "import sklearn.svm as svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"sklearnex\")\n",
    "logger.setLevel(logging.WARNING)  # Set the logger's logging level to WARNING or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "def feature_preprocessing(features_train_a, features_test_a, fusion_scores_train, fusion_scores_test, use_fusion=True):\n",
    "    X_train_final = np.abs(features_train_a - features_train_b)\n",
    "    X_train_final = X_train_final.reshape(X_train_final.shape[0], -1)\n",
    "    \n",
    "    X_test_final = np.abs(features_test_a - features_test_b)\n",
    "    X_test_final = X_test_final.reshape(X_test_final.shape[0], -1)\n",
    "    \n",
    "    if use_fusion:\n",
    "        fusion_train_final = fusion_scores_train.reshape(fusion_scores_train.shape[0], -1)\n",
    "        X_train_final = np.concatenate((X_train_final, fusion_train_final), axis=1)\n",
    "        \n",
    "        fusion_test_final = fusion_scores_test.reshape(fusion_scores_test.shape[0], -1)\n",
    "        X_test_final = np.concatenate((X_test_final, fusion_test_final), axis=1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "    X_test_scaled = scaler.transform(X_test_final)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = feature_preprocessing(features_train_a, features_test_a, fusion_scores_train, fusion_scores_test, use_fusion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_param(X_train_scaled, y_train_final, model, param_grid, refit=True):\n",
    "    # create an SVM classifier\n",
    "    model = model\n",
    "\n",
    "    # define the parameter grid to search over\n",
    "    param_grid = param_grid\n",
    "\n",
    "    # perform the grid search\n",
    "    grid_search = GridSearchCV(model, param_grid, refit=refit, verbose=2)\n",
    "    grid_search.fit(X_train_scaled, y_train_final)\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test_final, y_predict):\n",
    "    # compute the confusion matrix\n",
    "    cm = confusion_matrix(y_test_final, y_predict)\n",
    "\n",
    "    # plot the confusion matrix\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, cmap=plt.cm.Blues, interpolation='nearest', extent=(-0.5, len(np.unique(y_test_final))-0.5, len(np.unique(y_test_final))-0.5, -0.5))\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "    fig.colorbar(im)\n",
    "\n",
    "    # display the number of samples in each cell\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            if cm[i, j] > 1000:\n",
    "                ax.text(j, i, str(cm[i, j]), ha='center', va='center', color='white')\n",
    "            else:\n",
    "                ax.text(j, i, str(cm[i, j]), ha='center', va='center')\n",
    "\n",
    "    # set the x and y axis ticks to display only 1 and 0\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for best hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   6.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12960/4099780449.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gamma'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'kernel'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'poly'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_best_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12960/305412401.py\u001b[0m in \u001b[0;36mget_best_param\u001b[1;34m(X_train_scaled, y_train_final, model, param_grid, refit)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# perform the grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    849\u001b[0m                     )\n\u001b[0;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[1;32m--> 851\u001b[1;33m                         \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m                     )\n\u001b[0;32m    853\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror_score\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearnex\\_device_offload.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0musm_iface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__sycl_usm_array_interface__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0musm_iface\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_copy_to_usm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musm_iface\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'syclobj'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearnex\\svm\\svc.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;34m'onedal'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_onedal_predict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;34m'sklearn'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msklearn_SVC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         }, X)\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msklearn_check_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1.0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearnex\\_device_offload.py\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(obj, method_name, branches, *args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'onedal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbranches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mhostargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhostkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'sklearn'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbranches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mhostargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhostkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearnex\\svm\\svc.py\u001b[0m in \u001b[0;36m_onedal_predict\u001b[1;34m(self, X, queue)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_onedal_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_onedal_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_onedal_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\onedal\\svm\\svm.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, queue)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\onedal\\svm\\svm.py\u001b[0m in \u001b[0;36m_predict\u001b[1;34m(self, X, module, queue)\u001b[0m\n\u001b[0;32m    303\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrom_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid_search = get_best_param(X_train_scaled, y_train_final, svm.SVC(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "Best Score:  0.8922500000000001\n",
      "Best Estimator:  SVC(C=10, gamma=0.01, kernel='poly')\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters and score\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "print(\"Best Estimator: \", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.0001, verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an SVM classifier with a Gaussian kernel\n",
    "clf = svm.SVC(kernel='rbf', C=10, gamma=0.0001, verbose=2)\n",
    "\n",
    "# train the classifier\n",
    "clf.fit(X_train_scaled, y_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(clf, open('Model/svm_VGG16_normal.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open('Model/svm_VGG16_fusion.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open('Model/svm_VGG16_normal.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an SVM classifier with a Gaussian kernel\n",
    "clf = svm.SVC(kernel='rbf', C=10, gamma=0.0001, verbose=2)\n",
    "\n",
    "X = np.concatenate((X_train_scaled, X_test_scaled), axis=0)\n",
    "y = np.concatenate((y_train_final, y_test_final), axis=0)\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro']\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.93325 0.92    0.9325  0.92225 0.90525]\n",
      "Precision: [0.93338272 0.92024206 0.93259733 0.92259325 0.90694298]\n",
      "Recall: [0.93325 0.92    0.9325  0.92225 0.90525]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', scores['test_accuracy'])\n",
    "print('Precision:', scores['test_precision_macro'])\n",
    "print('Recall:', scores['test_recall_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      2000\n",
      "           1       0.95      0.88      0.91      2000\n",
      "\n",
      "    accuracy                           0.92      4000\n",
      "   macro avg       0.92      0.92      0.92      4000\n",
      "weighted avg       0.92      0.92      0.92      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.48      0.60      2000\n",
      "           1       0.63      0.88      0.73      2000\n",
      "\n",
      "    accuracy                           0.68      4000\n",
      "   macro avg       0.71      0.68      0.66      4000\n",
      "weighted avg       0.71      0.68      0.66      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = get_best_param(X_train_scaled, y_train_final, RandomForestClassifier(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9399375000000001\n",
      "Best Estimator:  RandomForestClassifier(min_samples_split=5, n_estimators=200)\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters and score\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "print(\"Best Estimator: \", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=5, n_estimators=200)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Random Forest classifier with 100 trees\n",
    "rfc = RandomForestClassifier(min_samples_split=5, n_estimators=200)\n",
    "\n",
    "# Train the classifier on your data\n",
    "rfc.fit(X_train_scaled, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(rfc, open('Model/rfc_VGG16_fusion.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = pickle.load(open('Model/rfc_VGG16_fusion.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test data\n",
    "y_predict = rfc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      2000\n",
      "           1       0.98      0.89      0.93      2000\n",
      "\n",
      "    accuracy                           0.93      4000\n",
      "   macro avg       0.94      0.93      0.93      4000\n",
      "weighted avg       0.94      0.93      0.93      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEWCAYAAAAQBZBVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiQ0lEQVR4nO3deZwU1b338c93RkUUXFEEFDUKGMWIYnDFfUFjoiZG0VyDxivmqtk0j09MfKLRaG68anJdolFDxF3UGDeCoIYQTZRNguCKC5FNtriCCvh7/qiaSQtDT1czPd0z9X3zqhfdp6pO/YqBH+fUqaqjiMDMLG/qqh2AmVk1OPmZWS45+ZlZLjn5mVkuOfmZWS45+ZlZLjn5tTOSOkp6WNK7ku5dg3q+IWl0S8ZWDZL+JGlIteOw2uPkVyWSTpI0UdIHkuam/0j3bYGqjwO6AptGxNfLrSQi7oiIw1ogns+QdICkkPTASuW7pOVjS6znIkm3N7ddRBwREcPLDNfaMSe/KpB0DvBr4DKSRNUT+A1wdAtUvzXwSkQsb4G6KmUBsJekTQvKhgCvtNQBlPDfb1u9iPDSiguwIfAB8PUi23QgSY5z0uXXQId03QHALOBcYD4wFzg1Xfcz4BNgWXqM04CLgNsL6t4GCGCt9PspwOvA+8AbwDcKyp8q2G9vYALwbvr73gXrxgKXAE+n9YwGuqzm3BrivwE4Ky2rB2YDPwXGFmz7v8BbwHvAJGBgWj5opfP8R0Ecl6ZxLAW2T8v+M11/PXB/Qf2/BJ4AVO2/F15af/H/jK1vL2Bd4IEi2/wE2BPoB+wCDAAuKFi/BUkS7UGS4K6TtHFEXEjSmrwnIjpFxO+KBSJpfeBq4IiI6EyS4KY0sd0mwKPptpsCVwGPrtRyOwk4FdgcWAf4YbFjA7cC30w/Hw5MI0n0hSaQ/BlsAtwJ3Ctp3YgYtdJ57lKwz8nAUKAzMHOl+s4FdpZ0iqSBJH92QyLCz3jmkJNf69sUWBjFu6XfAC6OiPkRsYCkRXdywfpl6fplETGSpPXTp8x4PgX6SuoYEXMjYnoT23wJeDUibouI5RFxF/AS8OWCbX4fEa9ExFJgBEnSWq2I+BuwiaQ+JEnw1ia2uT0iFqXHvJKkRdzced4SEdPTfZatVN8Skj/Hq4Dbge9ExKxm6rN2ysmv9S0Cukhaq8g23flsq2VmWtZYx0rJcwnQKWsgEfEhcALwbWCupEcl7VBCPA0x9Sj4Pq+MeG4DzgYOpImWsKQfSnoxHbl+h6S126WZOt8qtjIiniXp5oskSVtOOfm1vr8DHwPHFNlmDsnARYOerNolLNWHwHoF37coXBkRj0XEoUA3ktbcTSXE0xDT7DJjanAbcCYwMm2VNUq7pecBxwMbR8RGJNcb1RD6auos2oWVdBZJC3JOWr/llJNfK4uId0ku7F8n6RhJ60laW9IRki5PN7sLuEDSZpK6pNs3e1vHakwB9pPUU9KGwPkNKyR1lXR0eu3vY5Lu86dN1DES6J3enrOWpBOAHYFHyowJgIh4A9if5BrnyjoDy0lGhteS9FNgg4L1bwPbZBnRldQb+DnwHyTd3/Mk9SsvemvrnPyqIL1+dQ7JIMYCkq7a2cAf001+DkwEpgLPA5PTsnKONQa4J61rEp9NWHVpHHOAxSSJ6L+aqGMRcBTJgMEikhbTURGxsJyYVqr7qYhoqlX7GDCK5PaXmcBHfLZL23AD9yJJk5s7TnqZ4XbglxHxj4h4FfgxcJukDmtyDtY2yQNdZpZHbvmZWS45+ZlZLjn5mVkuOfmZWS4Vu9G21WmtjqF1Olc7DMtg18/3rHYIlsHMmW+ycOFCNb/l6tVvsHXE8qUlbRtLFzwWEYPW5HiVUlvJb53OdOhzfLXDsAyefvbaaodgGeyzx+5rXEcs/4gOOwwuaduPnrumuSdyqqamkp+ZtQECtEaNx5rg5Gdm2bWDVyU6+ZlZdm75mVn+COrqqx3EGnPyM7NshLu9ZpZHcrfXzHLKLT8zyyW3/Mwsf+SWn5nlkPBor5nlkVt+ZpZXdb7mZ2Z54/v8zCy3PNprZvnjx9vMLK/c7TWz3JEfbzOzvHLLz8xyyS0/M8uf9nGTc9s/AzNrXQ2Pt5WyNFeVNEzSfEnTCsrukTQlXd6UNCUt30bS0oJ1NxTs01/S85JmSLpaar5p6pafmWXUoi2/W4BrgVsbCiLihMYjSVcC7xZs/1pE9GuinuuB04FngZHAIOBPxQ7slp+ZZdcw4tvc0oyIGAcsbvoQEnA8cFfxUNQN2CAinomIIEmkxzR3bCc/M8tOdaUt0EXSxIJlaIajDATejohXC8q2lfScpL9IGpiW9QBmFWwzKy0ryt1eM8uu9NHehRFR7kzpJ/LZVt9coGdELJLUH/ijpJ3KrNvJz8wyUuVHeyWtBXwV6N9QFhEfAx+nnydJeg3oDcwGtizYfcu0rCh3e80sM9XVlbSsgUOAlyKisTsraTNJ9ennzwG9gNcjYi7wnqQ90+uE3wQebO4ATn5mlokASSUtzdYl3QX8HegjaZak09JVg1l1oGM/YGp668t9wLcjomGw5EzgZmAG8BrNjPSCu71mlpXSpQVExImrKT+libL7gftXs/1EoG+WYzv5mVlGpbXqap2Tn5ll5uRnZrlUt2aDGTXByc/MsmnBa37V5ORnZpnI1/zMLK+c/Mwsl5z8zCyXnPzMLH8EqnPyM7Oc8YCHmeWWk5+Z5VPbz31OfmaWkdzyM7OccvIzs9wR8rO9ZpZTbb/h5+RnZhn5mp+Z5ZWTn5nlUntIfm3/qqWZtTrVqaSl2XqkYZLmS5pWUHaRpNmSpqTLkQXrzpc0Q9LLkg4vKB+Uls2Q9KNSzsHJrww3XPgNZj7xCybe++PGsp1792Ds8HOZMOLH3PfrM+i8/rqN6/r26s7Y4ecy6b6fMGHEj+mwTtLgPu6w3Rh/z/lMuu8n/Py7R7f6eRh89NFH7LvXAAbstgu77bITl/zsQgCuv+5adtphezquLRYuXFjlKGtLqTO3ldg6vAUY1ET5ryKiX7qMTI+7I8msbjul+/xGUn06neV1wBHAjsCJ6bZFVTT5lZON24LbHn6Go8+67jNl1//0JC64+kG+ePxlPPTnf/CDIQcDUF9fx7CfD+E7l95N/+Mu5fDT/5dly1ewyYbrc9n3j+HIb19D/+MupWuXDThgQO9qnE6udejQgVFjnmT85H/w7MQpjH5sFM8+8wx77b0PI0c9Ts+tt652iDWppZJfRIwDFje7YeJo4O6I+Dgi3iCZpnJAusyIiNcj4hPg7nTboiqW/MrNxm3B05NfY/G7Sz5Ttn3PzXlq0gwAnnzmJY45uB8Ah+y1A9Nenc3zryQTyC9+90M+/TTYtsemzPjnAhb+64Nkn2f/vY+1Hkl06tQJgGXLlrF82TIk0W/XXdl6m22qG1wNy5D8ukiaWLAMLfEQZ0uamnaLN07LegBvFWwzKy1bXXlRlWz5lZWN26oXX5/Llw/4AgBfPXQ3tuya/Lx69dycCHjourP4253/l3OGHALAa28toPc2m9Oz2ybU19fxlQN3adzHWteKFSvYo38/enbfnIMOOZQBe+xR7ZBqn0pcYGFE7F6w3FhC7dcD2wH9gLnAlS0dPlQ2+ZWUjSUNbfhfIZYvrWA4lXXGRXcw9PiBPH3HeXRarwOfLFsBwFr19ey96+c49Se3cPC3ruIrB+3CAQN68877S/nuZfdw+y+/xRPDfsDMOYv49NNPq3wW+VRfX8+zk6Yw481ZTJwwnunTpjW/U8614DW/VUTE2xGxIiI+BW4iaUgBzAa2Kth0y7RsdeVFVf1Wl/R/ghsB6tbbPKocTtleefNtvnxmch1w+56bc8TAnQCYPf8dnpr8Gove+RCAUU9NZ9cdtmLs+FcYOW4aI8cl/9C+9dV9WLHCya+aNtpoI/Y/4EBGjx7FTn37VjucmiVBXQVfZiqpW0TMTb8eCzT8b/QQcKekq4DuQC9gPEkbs5ekbUmS3mDgpOaOU8mWX1nZuK3abOPkupEkfnT64dx031MAjPnbC+y0fXc6rrs29fV1DOy/PS++Pu8z+2zUuSNDjx/I7x/4e3WCz7EFCxbwzjvvALB06VKeeHwMffrsUN2gal7LjfZKugv4O9BH0ixJpwGXS3pe0lTgQOAHABExHRgBvACMAs5KW4jLgbOBx4AXgRHptkVVsuU3gTKycVsw/BenMLB/L7ps1IkZoy7hkhtG0qljB844YT8AHnxyCrc++AwA77y/lKtvf5Knbj+PiOCxp6Yz6qnk53LFecexc+/kSsAvbhzFjH/Or84J5di8uXM5/VtDWLFiBZ/Gp3ztuOM58ktHcd01V3PVlZfz9rx5fHG3LzBo0JFcf+PN1Q63ZrTUPc4RcWITxb8rsv2lwKVNlI8ERmY5tiIq19NMb078NVAPDEsDX6269TaPDn2Or1g81vL+NeHaaodgGeyzx+5MmjRxjVLXulv0jq2HXFPStq9cPmhSROy+JserlIpe8ysnG5tZjVPLtfyqqeoDHmbWtojKDni0Fic/M8vMyc/M8sfdXjPLI9E+Xmnl5GdmGXnScjPLqXaQ+5z8zCyjCj/e1lqc/MwsE1/zM7Pcage5z8nPzLJzy8/Mcqkd5D4nPzPLyJOWm1keCXm018zyqR00/Jz8zCw7d3vNLH/8YgMzy6P2cpNzJScwMrN2qgUnMBomab6kaQVl/yPppXTS8gckbZSWbyNpqaQp6XJDwT7900mPZki6WiUc3MnPzDKrq1NJSwluAQatVDYG6BsRXwBeAc4vWPdaRPRLl28XlF8PnE4ynWWvJupc9RxKic7MrFF6za+UpTkRMQ5YvFLZ6HQ6SoBnSKa9XX04Ujdgg4h4JpIZ2W4Fjmnu2E5+ZpaJss3b20XSxIJlaMbDfQv4U8H3bSU9J+kvkgamZT2AWQXbzErLivKAh5lllmG8Y2G5U1dK+gmwHLgjLZoL9IyIRZL6A3+UtFM5dYOTn5mVoa7Co72STgGOAg5Ou7JExMfAx+nnSZJeA3oDs/ls13jLtKwod3vNLBOpRQc8mqhfg4DzgK9ExJKC8s0k1aefP0cysPF6RMwF3pO0ZzrK+03gweaOs9qWn6Tdiu0YEZNLOhMza3da6tFeSXcBB5BcG5wFXEgyutsBGJNeN3wmHdndD7hY0jLgU+DbEdEwWHImychxR5JrhIXXCZtUrNt7ZZF1ARzUXOVm1j611E3OEXFiE8W/W8229wP3r2bdRKBvlmOvNvlFxIFZKjKz/GgHD3g0f81P0nqSLpB0Y/q9l6SjKh+amdUikd7uUsKvWlbKgMfvgU+AvdPvs4GfVywiM6t5dSptqWWlJL/tIuJyYBlAOvpS46dlZhWj0kZ6a/2Fp6Xc5/eJpI4kgxxI2o70Xhszyx9R+fv8WkMpye9CYBSwlaQ7gH2AUyoZlJnVtnaQ+5pPfhExRtJkYE+SpP+9iFhY8cjMrGa1h/f5lfp42/7AviRd37WBByoWkZnVtFLf2FLrmk1+kn4DbA/clRadIemQiDiropGZWc2qbwfZr5SW30HA5xseLpY0HJhe0ajMrKa1h25vKbe6zAB6FnzfKi0zsxxKRnvb/n1+xV5s8DDJNb7OwIuSxqff9wDGt054ZlZzSpyfo9YV6/Ze0WpRmFmb0g5yX9EXG/ylNQMxs7ajPbT8SnmxwZ6SJkj6QNInklZIeq81gjOz2iOgvk4lLbWslAGPa4ETgVdJXhT4n8B1lQzKzGqbSlxqWUmvsY+IGUB9RKyIiN9TwpyYZtY+ScmzvaUstayU+/yWSFoHmCLpcpIZlDz3h1mO1XheK0kpSezkdLuzgQ9J7vP7aiWDMrPalmHe3prVbPKLiJkR8VFEvBcRP4uIc4DLWiE2M6tRDc/3Nrc0X4+GSZovaVpB2SaSxkh6Nf1947Rckq6WNEPS1MJJ1iQNSbd/VdKQUs6h3O7rXmXuZ2ZtnFTaSG+Jo723sOoYwo+AJyKiF/BE+h3gCJLpKnsBQ4Hr03g2IXn13h7AAODChoRZjK/dmVlmLdXtjYhxwOKVio8GhqefhwPHFJTfGolngI0kdQMOB8ZExOKI+BcwhhIGZcuZt1ckr7VqcX17b8WjTxSbMdNqzcZHX1PtECyDj2fMb5F6MrSaukiaWPD9xoi4sZl9uqYTkQPMA7qmn3sAbxVsNystW115UeXO2/tScxWbWfskMj3hsTAidi/3WBERkqLc/YvxvL1mllmFH954W1K3iJibdmsbmquzSe42abBlWjYbOGCl8rHNHcTX/MwsE6nij7c9BDSM2A4BHiwo/2Y66rsn8G7aPX4MOEzSxulAx2FpWVGlvsbezKxRS7X8JN1F0mrrImkWyajtfwMjJJ0GzASOTzcfCRxJ8j7RJcCpABGxWNIlwIR0u4sjYuVBlFU4+ZlZZi11/3JEnLiaVQc3sW0ATU6fERHDgGFZjl3KW10k6T8k/TT93lPSgCwHMbP2o2He3rb+bG8p1/x+Q3JTc0OGfh+/1cUs1+pKXGpZKd3ePSJiN0nPAUTEv9IXHZhZTtV4o64kpSS/ZZLqSebvQNJmwKcVjcrMalbD421tXSnJ72qSSco3l3QpcBxwQUWjMrOa1g5yX/PJLyLukDSJZPRFwDER8WLFIzOzmtQw4NHWNZv8JPUkuafm4cKyiPhnJQMzs9rVDnJfSd3eR0mu9wlYF9gWeBnYqYJxmVmtagMTkpeilG7vzoXf07e9nFmxiMys5qnmpydqXuYnPCJisqQ9KhGMmdU+AWvV+k18JSjlmt85BV/rgN2AORWLyMxqXq3Pz1GKUlp+nQs+Lye5Bnh/ZcIxs1qXjPZWO4o1VzT5pTc3d46IH7ZSPGZW60qcnKjWFXuN/VoRsVzSPq0ZkJnVvvZ+n994kut7UyQ9BNxLMm8vABHxhwrHZmY1SEB9HgY8SO7tWwQcxL/v9wvAyc8sl0RdO7/VZfN0pHca/056DSoyoYiZ1b5kAqNqR7HmiiW/eqATNJninfzM8ioHT3jMjYiLWy0SM2sz2sOAR7HLlm3/7MysxTV0e0tZitYj9ZE0pWB5T9L3JV0kaXZB+ZEF+5wvaYaklyUdvibnUazlt8oEImZmQIu8zDQiXgb6QeM9xbNJ3h16KvCriLiicHtJOwKDSV6q0h14XFLviFhRzvFX2/IrZeo3M8sfUZE5PA4GXouImUW2ORq4OyI+jog3SKawLHsytXZwt46ZtSolz/aWspDMxzuxYBm6mloHA3cVfD9b0lRJw9KJyAF6AG8VbDMrLSuLk5+ZZaYSF2BhROxesNy4Sl3JhGhfIXmQAuB6YDuSLvFc4MpKnIMnLTezTCrwGvsjgMkR8TZAw+8Akm4CHkm/zga2Kthvy7SsLG75mVlmGVp+pTiRgi6vpG4F644ledAC4CFgsKQOkrYFepE8hlsWt/zMLCNR10J3OUtaHzgUOKOg+HJJ/UgepnizYV1ETJc0AniB5PV6Z5U70gtOfmaWUcNob0uIiA+BTVcqO7nI9pcCl7bEsZ38zCyzvLzJ2czsM9p+6nPyM7Os5JafmeWQgHonPzPLo7af+pz8zKwM7aDh5+RnZtkkt7q0/ezn5GdmmbnlZ2Y5JOSWn5nljUd7zSyfSnhFfVvg5GdmmTn5mVku+ZqfmeVO8jLTakex5pz8zCyz9jBvr5OfmWXmbq8xZ/Zb/ODM01gwfz6SOGnIaZx2xtlccdlFjP7TI9TV1bFpl8248tqb2KJbdyKCC88/lz8/PoqOHdfjymtvYudddq32abR7N3zvYI4YsA0L3lnK7mfdCcBt/3cQvbbcCICN1u/AOx9+zJ7fuZvBB/Tm+1/brXHfnbfpwl7fu5upry9k1+0348YfHELHddbisYkzOfe346pxOlXlbm8zJA0DjgLmR0TfSh2n2urr1+KCi3/Jzrvsygfvv8+XDt6LgfsfzBlnn8MPf3wRAMN+ex3/e8Vl/OLKa/nz44/x5uszGDdhOs9NHM9PfvhdHhrz1+qeRA7c9viL3PDIVG4+59DGspN/Oarx83+fti/vLvkYgLvHvsLdY18BYKetN2XE//sSU19fCMDVZx7IWVc/yfiX3+aPP/sKh/XfmtGTik012x61j5ucKzmB0S3AoArWXxO6btGtseXWqXNntu+1A/PmzqbzBhs0brNkyYeNf1lG/+lhvnbCN5DEbl/cg/fefYe3582tSux58vT0OSx+/6PVrv/awO0Z8ZdXVik/fv/e3DsuKd9i4/XovN46jH85mVzszidf5Mt7fa4yAdey9D6/UpZaVrHkFxHjgMWVqr8WvfXPN5n+/BR27Z9MIn/5z3/KHjtvxx/vu5tzz/8pAPPmzqFbjy0b99miew/mzZ1TlXgtsc9O3Xn7nSW8NufdVdYdt1+vxqTYfdNOzF70QeO62Qs/pPum67danLWkpWZvk/SmpOclTZE0MS3bRNIYSa+mv2+clkvS1ZJmpBOa71a89uKqPnWlpKENs7kvXrSg2uGU7cMPPuCMU07kwkuvaGz1nXfBxTz7/Gscc9xgbrn5+ipHaKtz/P69ufcvr65S/sU+XVny8TJemJmr/8Ob1fB4WylLiQ6MiH4RsXv6/UfAExHRC3gi/Q7J/L690mUoyeTmZat68ouIGxtmc99k082qHU5Zli1bxhmnDObY4wZzxJePWWX9sV8fzJ8e/iMAW3TrztzZsxrXzZszmy26dW+lSG1l9XXi6L23475xq3Z5v75fL0YUJMU5iz6gx6adGr/36LI+cxZ92Cpx1pwWnrh3JUcDw9PPw4FjCspvjcQzwEYrzfGbSdWTX1sXEfyf757B9r134PQzv9dY/sZrMxo/jx75CNv16gPAoYOO4v577iAimDzhWTpvsCFdtyj752dr6KBdt+KVWf9i9kpJTIKv7dur8XofwLx/LeH9JZ8woE9XAE466PM88szrrRpvrVCJv4AuDT27dBm6UlUBjJY0qWBd14houBA+D+iafu4BvFWw76y0rCy+1WUNTXj2b/xhxJ3ssGNfBu2fXOs774KLuef2W3htxivU1dXRY6ue/OKKawA46NBB/HnMKAbuviMdO67HFdfcWM3wc2P4eYczcOcedNlgXWYMP5VL7niW4aNf4Ov79W5yoGPfvj2YtfAD3pz33mfKv/ebscmtLh3WYvTEmTw2MW8jvYkMgxkLC7qzTdk3ImZL2hwYI+mlwpUREZKizDCLUkRF6kXSXcABQBfgbeDCiPhdsX2+0K9/PPrk3yoSj1VG75OdvNuSj5/6Hz59959rNA77+Z13jVsfHFvStgO222hSM8mvkaSLgA+A04EDImJu2q0dGxF9JP02/XxXuv3LDduVcRoVHe09MSK6RcTaEbFlc4nPzNqQFrjmJ2l9SZ0bPgOHAdOAh4Ah6WZDgAfTzw8B30xHffcE3i038YG7vWaWkdRiz/Z2BR5I5wBeC7gzIkZJmgCMkHQaMBM4Pt1+JHAkMANYApy6Jgd38jOzzFoi9UXE68AuTZQvAg5uojyAs1rg0ICTn5mVo8af3iiFk5+ZZdQ+nu118jOzzGr9ud1SOPmZWSbCyc/McsrdXjPLJbf8zCyX2kHuc/Izs4zW7I0tNcPJz8wy8zU/M8sdT2BkZvnl5GdmeeRur5nlkm91MbNcage5z8nPzMrQDrKfk5+ZZdKCLzOtKic/M8us7ac+Jz8zK0c7yH5OfmaWUft4maknLTezzKTSluJ1aCtJf5b0gqTpkr6Xll8kabakKelyZME+50uaIellSYevyTm45WdmmbTgy0yXA+dGxOR0CstJksak634VEVd85rjSjsBgYCegO/C4pN4RsaKcg7vlZ2aZqcRfxUTE3IiYnH5+H3gR6FFkl6OBuyPi44h4g2QKywHlnoOTn5lllqHb20XSxIJlaNP1aRtgV+DZtOhsSVMlDZO0cVrWA3irYLdZFE+WRTn5mVlmKnEBFkbE7gXLjavUJXUC7ge+HxHvAdcD2wH9gLnAlZU4B1/zM7NsShjMKLkqaW2SxHdHRPwBICLeLlh/E/BI+nU2sFXB7lumZWVxy8/MypCh7be6GiQBvwNejIirCsq7FWx2LDAt/fwQMFhSB0nbAr2A8eWegVt+ZpZJC77MdB/gZOB5SVPSsh8DJ0rqBwTwJnAGQERMlzQCeIFkpPisckd6wcnPzMrQEt3eiHiKppuHI4vscylw6Zof3cnPzMrQHp7wcPIzs+zafu5z8jOz7NpB7nPyM7NsSnluty1w8jOzzNQOsp+Tn5ll1vZTn5OfmZWhHTT8nPzMLKv28TJTJz8zy6QF3+dXVU5+ZpaZk5+Z5ZK7vWaWP77Pz8zyqPmXVbUNTn5mll07yH5OfmaWma/5mVkutdDLTKvKyc/MsnPyM7M8crfXzHKnvTzhoYiodgyNJC0AZlY7jgroAiysdhCWSXv9mW0dEZutSQWSRpH8+ZRiYUQMWpPjVUpNJb/2StLEiNi92nFY6fwza/88b6+Z5ZKTn5nlkpNf67ix2gFYZv6ZtXO+5mdmueSWn5nlkpOfmeWSk18FSRok6WVJMyT9qNrxWPMkDZM0X9K0asdileXkVyGS6oHrgCOAHYETJe1Y3aisBLcANXlTrrUsJ7/KGQDMiIjXI+IT4G7g6CrHZM2IiHHA4mrHYZXn5Fc5PYC3Cr7PSsvMrAY4+ZlZLjn5Vc5sYKuC71umZWZWA5z8KmcC0EvStpLWAQYDD1U5JjNLOflVSEQsB84GHgNeBEZExPTqRmXNkXQX8Hegj6RZkk6rdkxWGX68zcxyyS0/M8slJz8zyyUnPzPLJSc/M8slJz8zyyUnvzZC0gpJUyRNk3SvpPXWoK5bJB2Xfr652AsXJB0gae8yjvGmpFVm+Fpd+WrqOEXStS1xXLOVOfm1HUsjol9E9AU+Ab5duFJSWXMwR8R/RsQLRTY5AMic/MxqnZNf2/RXYPu0VfZXSQ8BL0iql/Q/kiZImirpDAAlrk3fLfg4sHlDRZLGSto9/TxI0mRJ/5D0hKRtSJLsD9JW50BJm0m6Pz3GBEn7pPtuKmm0pOmSbiaZ27okkgZI+ruk5yT9TVKfgtVbpTG+KunCgn3+Q9L4NK7fpq8QMytZWa0Fq560hXcEMCot2g3oGxFvSBoKvBsRX5TUAXha0mhgV6APyXsFuwIvAMNWqncz4CZgv7SuTSJisaQbgA8i4op0uzuBX0XEU5J6kjzB8nngQuCpiLhY0peALE9GvAQMjIjlkg4BLgO+lq4bAPQFlgATJD0KfAicAOwTEcsk/Qb4BnBrhmNazjn5tR0dJU1JP/8V+B1Jd3R8RLyRlh8GfKHheh6wIdAL2A+4KyJWAHMkPdlE/XsC4xrqiojVvdPuEGBHqbFht4GkTukxvpru+6ikf2U4tw2B4ZJ6AQGsXbBuTEQsApD0B2BfYDnQnyQZAnQE5mc4npmTXxuyNCL6FRak//A/LCwCvhMRj6203ZEtGEcdsGdEfNRELOW6BPhzRBybdrXHFqxb+fnLIDnP4RFx/poc1PLN1/zal8eA/5K0NoCk3pLWB8YBJ6TXBLsBBzax7zPAfpK2TffdJC1/H+hcsN1o4DsNXyT1Sz+OA05Ky44ANs4Q94b8+3Vfp6y07lBJm0jqCBwDPA08ARwnafOGWCVtneF4Zk5+7czNJNfzJqcT8PyWpHX/APBquu5WkreWfEZELACGAn+Q9A/gnnTVw8CxDQMewHeB3dMBlRf496jzz0iS53SS7u8/i8Q5NX1jyixJVwGXA7+Q9Byr9kbGA/cDU4H7I2JiOjp9ATBa0lRgDNCtxD8jM8BvdTGznHLLz8xyycnPzHLJyc/McsnJz8xyycnPzHLJyc/McsnJz8xy6f8Dw6ePs0wSLTUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   4.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   4.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   4.3s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   4.4s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  57.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  56.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  56.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  57.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  56.6s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  21.7s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  17.8s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  21.5s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  17.8s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  20.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  40.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  40.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  40.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  40.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  41.8s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  18.9s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  19.5s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  11.4s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  18.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  50.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  50.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  50.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  50.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  50.2s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=  32.1s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=  33.4s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=  27.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=  28.2s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=  28.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  40.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  37.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  40.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  40.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  37.8s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.9min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.0min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 3.7min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.1min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  52.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  52.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  52.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  52.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  51.6s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  27.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  29.5s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  27.4s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  29.4s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  32.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  38.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  38.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  39.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  38.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  38.4s\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "grid_search = get_best_param(X_train_scaled, y_train_final, LogisticRegression(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9376874999999998\n",
      "Best Estimator:  LogisticRegression(C=0.1, penalty='l1', solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters and score\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "print(\"Best Estimator: \", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Logistic Regression classifier\n",
    "lr = LogisticRegression(C=0.1, penalty='l1', solver='liblinear')\n",
    "\n",
    "# Train the classifier on your data\n",
    "lr.fit(X_train_scaled, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(lr, open('Model/lr_VGG16_fusion.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pickle.load(open('Model/lr_VGG16_fusion.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test data\n",
    "y_predict = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2000\n",
      "           1       0.93      0.92      0.92      2000\n",
      "\n",
      "    accuracy                           0.93      4000\n",
      "   macro avg       0.93      0.93      0.93      4000\n",
      "weighted avg       0.93      0.93      0.93      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_final,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test_final, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification by CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 64, 128, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 64, 128, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " vgg16 (Functional)             (None, 2, 4, 512)    14714688    ['input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 4096)         0           ['vgg16[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 4096)         0           ['vgg16[1][0]']                  \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 1)            0           ['flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2           ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,714,690\n",
      "Trainable params: 14,714,690\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(64,128,3))\n",
    "\n",
    "input_dim = X_train_pair.shape[2:]\n",
    "\n",
    "img_a = Input(shape=input_dim)\n",
    "img_b = Input(shape=input_dim)\n",
    "\n",
    "feat_vecs_a = model_vgg(img_a)\n",
    "feat_vecs_b = model_vgg(img_b)\n",
    "\n",
    "flatten_a = Flatten()(feat_vecs_a)\n",
    "flatten_b = Flatten()(feat_vecs_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance)([flatten_a, flatten_b])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model_vgg = Model(inputs=[img_a, img_b], outputs=outputs)\n",
    "\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model_vgg.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 73s 146ms/step - loss: 0.6932 - accuracy: 0.4972\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 0.6932 - accuracy: 0.4972\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 74s 149ms/step - loss: 0.6932 - accuracy: 0.4909\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 0.6932 - accuracy: 0.4951\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 0.6932 - accuracy: 0.4936\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4959\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4921\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4970\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4984\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.6932 - accuracy: 0.4936\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4989\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4985\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.6932 - accuracy: 0.4984\n",
      "Epoch 15/100\n",
      "326/500 [==================>...........] - ETA: 26s - loss: 0.6932 - accuracy: 0.4975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28180/1909033650.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mX_train_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_b\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_final\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# reducing batch size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \"\"\"\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \"\"\"\n\u001b[0;32m   1156\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model_vgg.fit(\n",
    "\t[X_train_a, X_train_b], y_train_final,\n",
    "\tbatch_size=32, # reducing batch size\n",
    "\tepochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model(inputShape, embeddingDim=48):\n",
    "\t# specify the inputs for the feature extractor network\n",
    "\tinputs = Input(inputShape)\n",
    "\t# define the first set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
    "\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\tx = Dropout(0.3)(x)\n",
    "\t# second set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "\tx = MaxPooling2D(pool_size=2)(x)\n",
    "\tx = Dropout(0.3)(x)\n",
    " \t# prepare the final outputs\n",
    "\tpooledOutput = GlobalAveragePooling2D()(x)\n",
    "\toutputs = Dense(embeddingDim)(pooledOutput)\n",
    "\t# build the model\n",
    "\tmodel = Model(inputs, outputs)\n",
    "\t# return the model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgA = Input(shape=X_train_pair.shape[2:])\n",
    "imgB = Input(shape=X_train_pair.shape[2:])\n",
    "featureExtractor = build_siamese_model(X_train_pair.shape[2:])\n",
    "featsA = featureExtractor(imgA)\n",
    "featsB = featureExtractor(imgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    X_train_a = tf.convert_to_tensor(X_train_pair[:, 0], np.float32)\n",
    "    X_train_b = tf.convert_to_tensor(X_train_pair[:, 1], np.float32)\n",
    "    y_train_final = tf.convert_to_tensor(y_train_pair.reshape(-1,1), np.float32)\n",
    "    \n",
    "    X_test_a = tf.convert_to_tensor(X_test_pair[:, 0], np.float32)\n",
    "    X_test_b = tf.convert_to_tensor(X_test_pair[:, 1], np.float32)\n",
    "    y_test_final = tf.convert_to_tensor(y_test_pair.reshape(-1,1), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 14s 26ms/step - loss: 0.7163 - accuracy: 0.4863 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6934 - accuracy: 0.4931 - val_loss: 0.6950 - val_accuracy: 0.4970\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6934 - accuracy: 0.4963 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4945 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4934 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6933 - val_accuracy: 0.4988\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6934 - val_accuracy: 0.4978\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4972 - val_loss: 0.6933 - val_accuracy: 0.4983\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4939 - val_loss: 0.6937 - val_accuracy: 0.4460\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6934 - accuracy: 0.5021 - val_loss: 0.6933 - val_accuracy: 0.4985\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6937 - val_accuracy: 0.4995\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4945 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4956 - val_loss: 0.6939 - val_accuracy: 0.3473\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6933 - accuracy: 0.4939 - val_loss: 0.6932 - val_accuracy: 0.4602\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.4950\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4905 - val_loss: 0.6946 - val_accuracy: 0.2918\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6941 - val_accuracy: 0.3918\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6933 - val_accuracy: 0.4692\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6943 - val_accuracy: 0.2965\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6937 - val_accuracy: 0.3670\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6936 - val_accuracy: 0.4565\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6933 - val_accuracy: 0.4248\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6934 - val_accuracy: 0.4692\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6935 - val_accuracy: 0.3620\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6933 - val_accuracy: 0.3915\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.4437\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.4297\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6932 - val_accuracy: 0.4902\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4954 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6935 - val_accuracy: 0.3957\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6937 - val_accuracy: 0.3285\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6935 - val_accuracy: 0.4588\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6935 - val_accuracy: 0.4958\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6933 - val_accuracy: 0.4365\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6937 - val_accuracy: 0.3803\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6940 - val_accuracy: 0.3100\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6937 - val_accuracy: 0.3877\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6935 - val_accuracy: 0.4720\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4954 - val_loss: 0.6944 - val_accuracy: 0.3860\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6947 - val_accuracy: 0.3828\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6936 - val_accuracy: 0.4515\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6949 - val_accuracy: 0.4182\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6936 - val_accuracy: 0.4510\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6934 - val_accuracy: 0.4850\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6931 - accuracy: 0.5003 - val_loss: 0.6938 - val_accuracy: 0.4245\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6969 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6946 - val_accuracy: 0.3970\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6981 - val_accuracy: 0.2915\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6931 - accuracy: 0.4996 - val_loss: 0.6985 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6977 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6956 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6962 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4936 - val_loss: 0.6963 - val_accuracy: 0.3638\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6971 - val_accuracy: 0.3640\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6964 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6978 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6968 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "439/500 [=========================>....] - ETA: 1s - loss: 0.6932 - accuracy: 0.4968"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28180/948365459.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_b\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \tepochs=100)\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \"\"\"\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \"\"\"\n\u001b[0;32m   1156\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(\n",
    "\t[X_train_a, X_train_b], y_train_final,\n",
    "\tvalidation_data=([X_test_a, X_test_b], y_test_final),\n",
    "\tbatch_size=32, \n",
    "\tepochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test_a, X_test_b, y_test_final):\n",
    "    # evaluate the model on the test data\n",
    "    print(\"[INFO] evaluating model...\")\n",
    "    loss, accuracy = model.evaluate([X_test_a, X_test_b], y_test_final, verbose=0)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "    # make predictions on the test data\n",
    "    print(\"[INFO] making predictions...\")\n",
    "    y_pred = model.predict([X_test_a, X_test_b])\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # print the classification report\n",
    "    print(\"[INFO] classification report...\")\n",
    "    print(classification_report(y_test_final, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating model...\n",
      "Test Loss: 3.5463\n",
      "Test Accuracy: 50.00%\n",
      "[INFO] making predictions...\n",
      "125/125 [==============================] - 1s 9ms/step\n",
      "[INFO] classification report...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      2000\n",
      "         1.0       0.50      1.00      0.67      2000\n",
      "\n",
      "    accuracy                           0.50      4000\n",
      "   macro avg       0.25      0.50      0.33      4000\n",
      "weighted avg       0.25      0.50      0.33      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_model(model, X_test_a, X_test_b, y_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Iris_recognition import *\n",
    "from Periocular_recognition import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_num = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(img_folder, fold):\n",
    "\n",
    "    test_data=[]\n",
    "    test_label=[]\n",
    "    fold_list=[i for i in range(fold - 1, fold + 3)]\n",
    "   \n",
    "    for dir1 in tqdm(os.listdir(img_folder)):\n",
    "        for eye in os.listdir(os.path.join(img_folder, dir1)):\n",
    "            for file in list(os.listdir(os.path.join(img_folder, dir1, eye))[i] for i in fold_list): # 2 4 6 8\n",
    "                image_path= os.path.join(img_folder, dir1, eye, file)\n",
    "                if image_path.endswith(\".jpg\") == False:\n",
    "                    continue\n",
    "                img = image.load_img(image_path, target_size=(64, 64))\n",
    "                img = image.img_to_array(img)\n",
    "                test_data.append(img)\n",
    "                test_label.append(dir1+'0' if eye == 'L' else dir1+'1')\n",
    "    \n",
    "    np.save(f'temp_data/Fusion_x_fold{fold}.npy', test_data)\n",
    "    np.save(f'temp_data/Fusion_y_fold{fold}.npy', test_label)         \n",
    "    return np.array(test_data), np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d4d1ba1a6a4271b7425819653a8882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test, y_test = create_dataset('Iris-Dataset/CASIA-Iris-Thousand', fold_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(fold):\n",
    "    Fusion_X, Fusion_y = combine_LR(np.load(f'temp_data/Fusion_x_fold{fold}.npy'), \n",
    "                                    np.load(f'temp_data/Fusion_y_fold{fold}.npy'), \n",
    "                                    1000, 4)\n",
    "    \n",
    "    model = VGG16(weights='imagenet', include_top=False,\n",
    "                  input_shape=(64, 128, 3))\n",
    "    with tf.device('GPU:0'):\n",
    "        features_test = model.predict(Fusion_X)\n",
    "\n",
    "    return features_test, Fusion_X, Fusion_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 14s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "features_test, Fusion_X, Fusion_y = load_dataset(fold_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16412/1602385618.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0miris_norm_L\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'temp_data/iris_norm_L_all.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0miris_norm_R\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'temp_data/iris_norm_R_all.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[1;32m--> 441\u001b[1;33m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[0;32m    442\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# Try a pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jimyj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# We can use the fast fromfile() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# This is not a real file. We have to read it the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iris_norm_L = np.load('temp_data/iris_norm_L_all.npy')\n",
    "iris_norm_R = np.load('temp_data/iris_norm_R_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fold_norm(fold):\n",
    "    iris_norm_L_fold = []\n",
    "    iris_norm_R_fold = []\n",
    "    for fol in range(1000):\n",
    "        for item in range(4):\n",
    "            iris_norm_L_fold.append(iris_norm_L[fol*10+item+fold])\n",
    "            iris_norm_R_fold.append(iris_norm_R[fol*10+item+fold])\n",
    "    return np.array(iris_norm_L_fold), np.array(iris_norm_R_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_norm_L_fold, iris_norm_R_fold = create_fold_norm(fold_num-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from functools import partial\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_multi_thread(ref_num, test_num, same_num=2):\n",
    "    # features_test, Fusion_X, Fusion_y = load_dataset()\n",
    "\n",
    "    def process_images(args):\n",
    "        img_1_fol, img_1_item, img_2_fol, img_2_item = args\n",
    "        tar = 0\n",
    "        trr = 0\n",
    "        far = 0\n",
    "        frr = 0\n",
    "        predict = []\n",
    "        ground_truth = []\n",
    "\n",
    "        if img_1_fol == img_2_fol:\n",
    "            ground_truth.append(1)\n",
    "        else:\n",
    "            ground_truth.append(0)\n",
    "\n",
    "        img_1_L = iris_norm_L_fold[(img_1_fol) * 4 + img_1_item]\n",
    "        img_1_R = iris_norm_R_fold[(img_1_fol) * 4 + img_1_item]\n",
    "        img_2_L = iris_norm_L_fold[(img_2_fol) * 4 + img_2_item]\n",
    "        img_2_R = iris_norm_R_fold[(img_2_fol) * 4 + img_2_item]\n",
    "\n",
    "        iris_score = iris_match_preload(img_1_L, img_1_R, img_2_L, img_2_R)\n",
    "\n",
    "        if iris_score == \"Match\":\n",
    "            predict.append(1)\n",
    "            if img_2_fol == img_1_fol:\n",
    "                tar += 1\n",
    "            else:\n",
    "                far += 1\n",
    "        elif iris_score == \"Not Sure\" or iris_score == \"No Iris\":\n",
    "            peri_score = predict_image(features_test, str(img_1_fol).zfill(3), img_2_item + 4 * img_2_fol, fold_num)\n",
    "            if peri_score == \"Match\":\n",
    "                predict.append(1)\n",
    "                if img_2_fol == img_1_fol:\n",
    "                    tar += 1\n",
    "                else:\n",
    "                    far += 1\n",
    "            else:\n",
    "                predict.append(0)\n",
    "                if img_2_fol == img_1_fol:\n",
    "                    frr += 1\n",
    "                else:\n",
    "                    trr += 1\n",
    "        else:\n",
    "            predict.append(0)\n",
    "            if img_2_fol == img_1_fol:\n",
    "                frr += 1\n",
    "            else:\n",
    "                trr += 1\n",
    "\n",
    "        return tar, trr, far, frr, predict, ground_truth\n",
    "\n",
    "    tar = 0\n",
    "    trr = 0\n",
    "    far = 0\n",
    "    frr = 0\n",
    "    predict = []\n",
    "    ground_truth = []\n",
    "    \n",
    "    max_workers = 2 * os.cpu_count()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        image_combinations = product(\n",
    "            range(ref_num), range(0,1), range(test_num), range(1,same_num)\n",
    "        )\n",
    "        for t, true, f, false, p, g in tqdm(executor.map(process_images, image_combinations), total=ref_num*test_num*(same_num-1)):\n",
    "            tar += t\n",
    "            trr += true\n",
    "            far += f\n",
    "            frr += false\n",
    "            predict.extend(p)\n",
    "            ground_truth.extend(g)\n",
    "\n",
    "    return [[trr, far], [frr, tar]], predict, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confu(ground_truth, predict):\n",
    "    # compute the confusion matrix\n",
    "    cm = confusion_matrix(ground_truth, predict)\n",
    "\n",
    "    # plot the confusion matrix\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, ['0', '1'])\n",
    "    plt.yticks(tick_marks, ['0', '1'])\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, str(cm[i,j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > cm.max() / 2 else \"black\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(ground_truth, confu):\n",
    "    # calculate the true acceptance rate (TAR), true rejection rate (TRR), false acceptance rate (FAR), and false rejection rate (FRR)\n",
    "    total_positive = np.sum(ground_truth)\n",
    "    total_negative = len(ground_truth) - total_positive\n",
    "    confu = np.array(confu)\n",
    "    true_positive = confu[1, 1]\n",
    "    true_negative = confu[0, 0]\n",
    "    false_positive = confu[0, 1]\n",
    "    false_negative = confu[1, 0]\n",
    "\n",
    "    tar = true_positive / total_positive\n",
    "    trr = true_negative / total_negative\n",
    "    far = false_positive / total_negative\n",
    "    frr = false_negative / total_positive\n",
    "    # print the accuracy and error rates\n",
    "    accuracy = (true_positive + true_negative) / len(ground_truth)\n",
    "    error_rate = 1 - accuracy\n",
    "    print(f'True Acceptance Rate (TAR): {tar*100}%')\n",
    "    print(f'True Rejection Rate (TRR): {trr*100}%')\n",
    "    print(f'False Acceptance Rate (FAR): {far*100}%')\n",
    "    print(f'False Rejection Rate (FRR): {frr*100}%')\n",
    "    print(f'Accuracy: {accuracy*100}%')\n",
    "    print(f'Error Rate: {error_rate*100}%')\n",
    "    # print(f'Recongition Rate: {(1-far-frr)*100}%')\n",
    "    # print(f'Error: {(far+frr)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d80743496b4c5daec337d1911c0c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confu, predict, ground_truth = accuracy_score_multi_thread(200, 200, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confu(ground_truth, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy(ground_truth, confu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
